<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://xuetongyao.github.io</id>
    <title>tongyao&apos;s blog</title>
    <updated>2022-07-30T04:22:39.463Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://xuetongyao.github.io"/>
    <link rel="self" href="https://xuetongyao.github.io/atom.xml"/>
    <subtitle>距离之所以可怕，因为根本不知道对方是把你想念，还是把你忘记</subtitle>
    <logo>https://xuetongyao.github.io/images/avatar.png</logo>
    <icon>https://xuetongyao.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, tongyao&apos;s blog</rights>
    <entry>
        <title type="html"><![CDATA[OpenFegin 进行远程服务调用]]></title>
        <id>https://xuetongyao.github.io/post/mgAe6A0Cx/</id>
        <link href="https://xuetongyao.github.io/post/mgAe6A0Cx/">
        </link>
        <updated>2022-07-30T04:04:50.000Z</updated>
        <content type="html"><![CDATA[<h2 id="feign与openfeign">Feign与OpenFeign</h2>
<p>Feign 是一种声明式服务调用组件，是在服务消费者（客户端）定义服务绑定接口并通过注解的方式进行配置，以实现远程服务的调用。它在 RestTemplate 的基础上做了进一步的封装。通过 Feign，我们只需要声明一个接口并通过注解进行简单的配置（类似于 Dao 接口上面的 Mapper 注解一样）即可实现对 HTTP 接口的绑定。</p>
<p>通过 Feign，我们可以像调用本地方法一样来调用远程服务，而完全感觉不到这是在进行远程调用。</p>
<p>使用 OpenFegin 进行远程服务调用时，常用注解如下表。</p>
<figure data-type="image" tabindex="1"><img src="https://xuetongyao-1309021253.cos.ap-shanghai.myqcloud.com/img/Thinkpad/image-20220730111856771.png" alt="image-20220730111856771" loading="lazy"></figure>
<h2 id="openfeign-实现远程服务调用">OpenFeign 实现远程服务调用</h2>
<p>下面通过一个实例，来演示下通过 OpenFeign 是如何实现远程服务调用的。</p>
<ol>
<li>
<p>在 spring-cloud-demo2 下创建一个名为 micro-service-cloud-consumer-dept-feign 的 Spring Boot 模块，并在 pom.xml 中添加以下依赖。<br>
<?xml version="1.0" encoding="UTF-8"?><br>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"><br>
<modelVersion>4.0.0</modelVersion><br>
<parent><br>
<artifactId>spring-cloud-demo2</artifactId><br>
<groupId>net.biancheng.c</groupId><br>
<version>0.0.1-SNAPSHOT</version><br>
</parent></p>
<pre><code>    &lt;groupId&gt;net.biancheng.c&lt;/groupId&gt;
    &lt;artifactId&gt;micro-service-cloud-consumer-dept-feign&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;micro-service-cloud-consumer-dept-feign&lt;/name&gt;
    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;
    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;net.biancheng.c&lt;/groupId&gt;
            &lt;artifactId&gt;micro-service-cloud-api&lt;/artifactId&gt;
            &lt;version&gt;${project.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;!--Eureka Client 依赖--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- Ribbon 依赖--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!--添加 OpenFeign 依赖--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;exclude&gt;
                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
                        &lt;/exclude&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>
<ol start="2">
<li>在 micro-service-cloud-consumer-dept-feign 下的类路径（即 /resources 目录）下，添加一个 application.yml，配置内容如下。</li>
</ol>
<p>server:<br>
port: 80</p>
<p>eureka:<br>
client:<br>
register-with-eureka: false #服务消费者可以不向服务注册中心注册服务<br>
service-url:<br>
defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/<br>
fetch-registry: true  #服务消费者客户端需要去检索服务</p>
</li>
<li>
<p>在 net.biancheng.c.service 包下创建一个名为 DeptFeignService 的接口，并在该接口上使用 @FeignClient 注解实现对服务接口的绑定，代码如下。</p>
<p>package net.biancheng.c.service;</p>
<p>import net.biancheng.c.entity.Dept;<br>
import org.springframework.cloud.openfeign.FeignClient;<br>
import org.springframework.stereotype.Component;<br>
import org.springframework.web.bind.annotation.PathVariable;<br>
import org.springframework.web.bind.annotation.RequestMapping;<br>
import org.springframework.web.bind.annotation.RequestMethod;</p>
<p>import java.util.List;</p>
<p>//添加为容器内的一个组件<br>
@Component<br>
// 服务提供者提供的服务名称，即 application.name<br>
@FeignClient(value = &quot;MICROSERVICECLOUDPROVIDERDEPT&quot;)<br>
public interface DeptFeignService {<br>
//对应服务提供者（8001、8002、8003）Controller 中定义的方法<br>
@RequestMapping(value = &quot;/dept/get/{id}&quot;, method = RequestMethod.GET)<br>
public Dept get(@PathVariable(&quot;id&quot;) int id);</p>
<pre><code> @RequestMapping(value = &quot;/dept/list&quot;, method = RequestMethod.GET)
 public List&lt;Dept&gt; list();
</code></pre>
<p>}</p>
</li>
</ol>
<p>在编写服务绑定接口时，需要注意以下 2 点：</p>
<ul>
<li>在 @FeignClient 注解中，value 属性的取值为：服务提供者的服务名，即服务提供者配置文件（application.yml）中 spring.application.name 的取值。</li>
<li>接口中定义的每个方法都与服务提供者（即 micro-service-cloud-provider-dept-8001 等）中 Controller 定义的服务方法对应。</li>
</ul>
<ol start="4">
<li>
<p>在 net.biancheng.c.controller 包下，创建一个名为 DeptController_Consumer 的 Controller 类，代码如下。</p>
<p>package net.biancheng.c.controller;</p>
<p>import net.biancheng.c.entity.Dept;<br>
import net.biancheng.c.service.DeptFeignService;<br>
import org.springframework.web.bind.annotation.PathVariable;<br>
import org.springframework.web.bind.annotation.RequestMapping;<br>
import org.springframework.web.bind.annotation.RestController;</p>
<p>import javax.annotation.Resource;<br>
import java.util.List;</p>
<p>@RestController<br>
public class DeptController_Consumer {</p>
<pre><code> @Resource
 private DeptFeignService deptFeignService;

 @RequestMapping(value = &quot;/consumer/dept/get/{id}&quot;)
 public Dept get(@PathVariable(&quot;id&quot;) Integer id) {
     return deptFeignService.get(id);
 }

 @RequestMapping(value = &quot;/consumer/dept/list&quot;)
 public List&lt;Dept&gt; list() {
     return deptFeignService.list();
 }
</code></pre>
<p>}</p>
</li>
<li>
<p>在主启动类上添加 @EnableFeignClients 注解开启 OpenFeign 功能，代码如下。</p>
<p>package net.biancheng.c;</p>
<p>import org.springframework.boot.SpringApplication;<br>
import org.springframework.boot.autoconfigure.SpringBootApplication;<br>
import org.springframework.cloud.openfeign.EnableFeignClients;</p>
<p>@SpringBootApplication<br>
@EnableFeignClients //开启 OpenFeign 功能<br>
public class MicroServiceCloudConsumerDeptFeignApplication {</p>
<pre><code> public static void main(String[] args) {
     SpringApplication.run(MicroServiceCloudConsumerDeptFeignApplication.class, args);
 }
</code></pre>
<p>}</p>
</li>
</ol>
<p>Spring Cloud 应用在启动时，OpenFeign 会扫描标有 @FeignClient 注解的接口生成代理，并注人到 Spring 容器中。</p>
<ol start="6">
<li>依次启动服务注册中心集群、服务提供者以及 micro-service-cloud-consumer-dept-feign，启动完成后，使用浏览器访问“http://eureka7001.com/consumer/dept/list”，结果如下图。<br>
<img src="https://xuetongyao-1309021253.cos.ap-shanghai.myqcloud.com/img/Thinkpad/1014296212-0.png" alt="OpenFeign 实现服务调用" loading="lazy"></li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HashMap]]></title>
        <id>https://xuetongyao.github.io/post/hashmap/</id>
        <link href="https://xuetongyao.github.io/post/hashmap/">
        </link>
        <updated>2022-07-27T13:02:48.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>title:  HashMap源码&amp;底层数据结构分析<br>
category: Java<br>
tag:</p>
<ul>
<li>Java集合</li>
</ul>
<hr>
<blockquote>
<p>感谢 <a href="https://github.com/changfubai">changfubai</a> 对本文的改进做出的贡献！</p>
</blockquote>
<h2 id="hashmap-简介">HashMap 简介</h2>
<p>HashMap 主要用来存放键值对，它基于哈希表的 Map 接口实现，是常用的 Java 集合之一，是非线程安全的。</p>
<p><code>HashMap</code> 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个</p>
<p>JDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。 JDK1.8 以后的 <code>HashMap</code> 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。</p>
<p><code>HashMap</code> 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。并且， <code>HashMap</code> 总是使用 2 的幂作为哈希表的大小。</p>
<h2 id="底层数据结构分析">底层数据结构分析</h2>
<h3 id="jdk18-之前">JDK1.8 之前</h3>
<p>JDK1.8 之前 HashMap 底层是 <strong>数组和链表</strong> 结合在一起使用也就是 <strong>链表散列</strong>。</p>
<p>HashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，然后通过 <code>(n - 1) &amp; hash</code> 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。</p>
<p>所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法也就是扰动函数是为了防止一些实现比较差的 hashCode() 方法 换句话说使用扰动函数之后可以减少碰撞。</p>
<p><strong>JDK 1.8 HashMap 的 hash 方法源码:</strong></p>
<p>JDK 1.8 的 hash 方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。</p>
<pre><code class="language-java">    static final int hash(Object key) {
      int h;
      // key.hashCode()：返回散列值也就是hashcode
      // ^ ：按位异或
      // &gt;&gt;&gt;:无符号右移，忽略符号位，空位都以0补齐
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);
  }
</code></pre>
<p>对比一下 JDK1.7 的 HashMap 的 hash 方法源码.</p>
<pre><code class="language-java">static int hash(int h) {
    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).

    h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);
    return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);
}
</code></pre>
<p>相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。</p>
<p>所谓 <strong>“拉链法”</strong> 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。</p>
<figure data-type="image" tabindex="1"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/jdk1.8%E4%B9%8B%E5%89%8D%E7%9A%84%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84.png" alt="jdk1.8之前的内部结构" loading="lazy"></figure>
<h3 id="jdk18-之后">JDK1.8 之后</h3>
<p>相比于之前的版本，JDK1.8 以后在解决哈希冲突时有了较大的变化。</p>
<p>当链表长度大于阈值（默认为 8）时，会首先调用 <code>treeifyBin()</code>方法。这个方法会根据 HashMap 数组来决定是否转换为红黑树。只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，以减少搜索时间。否则，就是只是执行 <code>resize()</code> 方法对数组扩容。相关源码这里就不贴了，重点关注 <code>treeifyBin()</code>方法即可！</p>
<img src="https://oscimg.oschina.net/oscnet/up-bba283228693dae74e78da1ef7a9a04c684.png" referrerpolicy="no-referrer" style="margin: auto;" />
<p><strong>类的属性：</strong></p>
<pre><code class="language-java">public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable {
    // 序列号
    private static final long serialVersionUID = 362498820763181265L;
    // 默认的初始容量是16
    static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;
    // 最大容量
    static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;
    // 默认的填充因子
    static final float DEFAULT_LOAD_FACTOR = 0.75f;
    // 当桶(bucket)上的结点数大于这个值时会转成红黑树
    static final int TREEIFY_THRESHOLD = 8;
    // 当桶(bucket)上的结点数小于这个值时树转链表
    static final int UNTREEIFY_THRESHOLD = 6;
    // 桶中结构转化为红黑树对应的table的最小容量
    static final int MIN_TREEIFY_CAPACITY = 64;
    // 存储元素的数组，总是2的幂次倍
    transient Node&lt;k,v&gt;[] table;
    // 存放具体元素的集
    transient Set&lt;map.entry&lt;k,v&gt;&gt; entrySet;
    // 存放元素的个数，注意这个不等于数组的长度。
    transient int size;
    // 每次扩容和更改map结构的计数器
    transient int modCount;
    // 临界值(容量*填充因子) 当实际大小超过临界值时，会进行扩容
    int threshold;
    // 加载因子
    final float loadFactor;
}
</code></pre>
<ul>
<li>
<p><strong>loadFactor 加载因子</strong></p>
<p>loadFactor 加载因子是控制数组存放数据的疏密程度，loadFactor 越趋近于 1，那么 数组中存放的数据(entry)也就越多，也就越密，也就是会让链表的长度增加，loadFactor 越小，也就是趋近于 0，数组中存放的数据(entry)也就越少，也就越稀疏。</p>
<p><strong>loadFactor 太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。loadFactor 的默认值为 0.75f 是官方给出的一个比较好的临界值</strong>。</p>
<p>给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量达到了 16 * 0.75 = 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。</p>
</li>
<li>
<p><strong>threshold</strong></p>
<p><strong>threshold = capacity * loadFactor</strong>，<strong>当 Size&gt;=threshold</strong>的时候，那么就要考虑对数组的扩增了，也就是说，这个的意思就是 <strong>衡量数组是否需要扩增的一个标准</strong>。</p>
</li>
</ul>
<p><strong>Node 节点类源码:</strong></p>
<pre><code class="language-java">// 继承自 Map.Entry&lt;K,V&gt;
static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
       final int hash;// 哈希值，存放元素到hashmap中时用来与其他元素hash值比较
       final K key;//键
       V value;//值
       // 指向下一个节点
       Node&lt;K,V&gt; next;
       Node(int hash, K key, V value, Node&lt;K,V&gt; next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }
        public final K getKey()        { return key; }
        public final V getValue()      { return value; }
        public final String toString() { return key + &quot;=&quot; + value; }
        // 重写hashCode()方法
        public final int hashCode() {
            return Objects.hashCode(key) ^ Objects.hashCode(value);
        }

        public final V setValue(V newValue) {
            V oldValue = value;
            value = newValue;
            return oldValue;
        }
        // 重写 equals() 方法
        public final boolean equals(Object o) {
            if (o == this)
                return true;
            if (o instanceof Map.Entry) {
                Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;
                if (Objects.equals(key, e.getKey()) &amp;&amp;
                    Objects.equals(value, e.getValue()))
                    return true;
            }
            return false;
        }
}
</code></pre>
<p><strong>树节点类源码:</strong></p>
<pre><code class="language-java">static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; {
        TreeNode&lt;K,V&gt; parent;  // 父
        TreeNode&lt;K,V&gt; left;    // 左
        TreeNode&lt;K,V&gt; right;   // 右
        TreeNode&lt;K,V&gt; prev;    // needed to unlink next upon deletion
        boolean red;           // 判断颜色
        TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) {
            super(hash, key, val, next);
        }
        // 返回根节点
        final TreeNode&lt;K,V&gt; root() {
            for (TreeNode&lt;K,V&gt; r = this, p;;) {
                if ((p = r.parent) == null)
                    return r;
                r = p;
       }
</code></pre>
<h2 id="hashmap-源码分析">HashMap 源码分析</h2>
<h3 id="构造方法">构造方法</h3>
<p>HashMap 中有四个构造方法，它们分别如下：</p>
<pre><code class="language-java">    // 默认构造函数。
    public HashMap() {
        this.loadFactor = DEFAULT_LOAD_FACTOR; // all   other fields defaulted
     }

     // 包含另一个“Map”的构造函数
     public HashMap(Map&lt;? extends K, ? extends V&gt; m) {
         this.loadFactor = DEFAULT_LOAD_FACTOR;
         putMapEntries(m, false);//下面会分析到这个方法
     }

     // 指定“容量大小”的构造函数
     public HashMap(int initialCapacity) {
         this(initialCapacity, DEFAULT_LOAD_FACTOR);
     }

     // 指定“容量大小”和“加载因子”的构造函数
     public HashMap(int initialCapacity, float loadFactor) {
         if (initialCapacity &lt; 0)
             throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity);
         if (initialCapacity &gt; MAXIMUM_CAPACITY)
             initialCapacity = MAXIMUM_CAPACITY;
         if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))
             throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor);
         this.loadFactor = loadFactor;
         this.threshold = tableSizeFor(initialCapacity);
     }
</code></pre>
<p><strong>putMapEntries 方法：</strong></p>
<pre><code class="language-java">final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) {
    int s = m.size();
    if (s &gt; 0) {
        // 判断table是否已经初始化
        if (table == null) { // pre-size
            // 未初始化，s为m的实际元素个数
            float ft = ((float)s / loadFactor) + 1.0F;
            int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ?
                    (int)ft : MAXIMUM_CAPACITY);
            // 计算得到的t大于阈值，则初始化阈值
            if (t &gt; threshold)
                threshold = tableSizeFor(t);
        }
        // 已初始化，并且m元素个数大于阈值，进行扩容处理
        else if (s &gt; threshold)
            resize();
        // 将m中的所有元素添加至HashMap中
        for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) {
            K key = e.getKey();
            V value = e.getValue();
            putVal(hash(key), key, value, false, evict);
        }
    }
}
</code></pre>
<h3 id="put-方法">put 方法</h3>
<p>HashMap 只提供了 put 用于添加元素，putVal 方法只是给 put 方法调用的一个方法，并没有提供给用户使用。</p>
<p><strong>对 putVal 方法添加元素的分析如下：</strong></p>
<ol>
<li>如果定位到的数组位置没有元素 就直接插入。</li>
<li>如果定位到的数组位置有元素就和要插入的 key 比较，如果 key 相同就直接覆盖，如果 key 不相同，就判断 p 是否是一个树节点，如果是就调用<code>e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value)</code>将元素添加进入。如果不是就遍历链表插入(插入的是链表尾部)。<br>
<img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/put方法.png" referrerpolicy="no-referrer" style="margin: auto;" /></li>
</ol>
<p>说明:上图有两个小问题：</p>
<ul>
<li>直接覆盖之后应该就会 return，不会有后续操作。参考 JDK8 HashMap.java 658 行（<a href="https://github.com/Snailclimb/JavaGuide/issues/608">issue#608</a>）。</li>
<li>当链表长度大于阈值（默认为 8）并且 HashMap 数组长度超过 64 的时候才会执行链表转红黑树的操作，否则就只是对数组扩容。参考 HashMap 的 <code>treeifyBin()</code> 方法（<a href="https://github.com/Snailclimb/JavaGuide/issues/1087">issue#1087</a>）。</li>
</ul>
<pre><code class="language-java">public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;
    // table未初始化或者长度为0，进行扩容
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // (n - 1) &amp; hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)
    if ((p = tab[i = (n - 1) &amp; hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    // 桶中已经存在元素
    else {
        Node&lt;K,V&gt; e; K k;
        // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等
        if (p.hash == hash &amp;&amp;
            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
                // 将第一个元素赋值给e，用e来记录
                e = p;
        // hash值不相等，即key不相等；为红黑树结点
        else if (p instanceof TreeNode)
            // 放入树中
            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);
        // 为链表结点
        else {
            // 在链表最末插入结点
            for (int binCount = 0; ; ++binCount) {
                // 到达链表的尾部
                if ((e = p.next) == null) {
                    // 在尾部插入新结点
                    p.next = newNode(hash, key, value, null);
                    // 结点数量达到阈值(默认为 8 )，执行 treeifyBin 方法
                    // 这个方法会根据 HashMap 数组来决定是否转换为红黑树。
                    // 只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，以减少搜索时间。否则，就是只是对数组扩容。
                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    // 跳出循环
                    break;
                }
                // 判断链表中结点的key值与插入的元素的key值是否相等
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    // 相等，跳出循环
                    break;
                // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表
                p = e;
            }
        }
        // 表示在桶中找到key值、hash值与插入元素相等的结点
        if (e != null) {
            // 记录e的value
            V oldValue = e.value;
            // onlyIfAbsent为false或者旧值为null
            if (!onlyIfAbsent || oldValue == null)
                //用新值替换旧值
                e.value = value;
            // 访问后回调
            afterNodeAccess(e);
            // 返回旧值
            return oldValue;
        }
    }
    // 结构性修改
    ++modCount;
    // 实际大小大于阈值则扩容
    if (++size &gt; threshold)
        resize();
    // 插入后回调
    afterNodeInsertion(evict);
    return null;
}
</code></pre>
<p><strong>我们再来对比一下 JDK1.7 put 方法的代码</strong></p>
<p><strong>对于 put 方法的分析如下：</strong></p>
<ul>
<li>① 如果定位到的数组位置没有元素 就直接插入。</li>
<li>② 如果定位到的数组位置有元素，遍历以这个元素为头结点的链表，依次和插入的 key 比较，如果 key 相同就直接覆盖，不同就采用头插法插入元素。</li>
</ul>
<pre><code class="language-java">public V put(K key, V value)
    if (table == EMPTY_TABLE) {
    inflateTable(threshold);
}
    if (key == null)
        return putForNullKey(value);
    int hash = hash(key);
    int i = indexFor(hash, table.length);
    for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { // 先遍历
        Object k;
        if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    }

    modCount++;
    addEntry(hash, key, value, i);  // 再插入
    return null;
}
</code></pre>
<h3 id="get-方法">get 方法</h3>
<pre><code class="language-java">public V get(Object key) {
    Node&lt;K,V&gt; e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}

final Node&lt;K,V&gt; getNode(int hash, Object key) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
        (first = tab[(n - 1) &amp; hash]) != null) {
        // 数组元素相等
        if (first.hash == hash &amp;&amp; // always check first node
            ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))
            return first;
        // 桶中不止一个节点
        if ((e = first.next) != null) {
            // 在树中get
            if (first instanceof TreeNode)
                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);
            // 在链表中get
            do {
                if (e.hash == hash &amp;&amp;
                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
</code></pre>
<h3 id="resize-方法">resize 方法</h3>
<p>进行扩容，会伴随着一次重新 hash 分配，并且会遍历 hash 表中所有的元素，是非常耗时的。在编写程序中，要尽量避免 resize。</p>
<pre><code class="language-java">final Node&lt;K,V&gt;[] resize() {
    Node&lt;K,V&gt;[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap &gt; 0) {
        // 超过最大值就不再扩充了，就只好随你碰撞去吧
        if (oldCap &gt;= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 没超过最大值，就扩充为原来的2倍
        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr &lt;&lt; 1; // double threshold
    }
    else if (oldThr &gt; 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else {
        // signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    // 计算新的resize上限
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;})
        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        // 把每个bucket都移动到新的buckets中
        for (int j = 0; j &lt; oldCap; ++j) {
            Node&lt;K,V&gt; e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    newTab[e.hash &amp; (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);
                else {
                    Node&lt;K,V&gt; loHead = null, loTail = null;
                    Node&lt;K,V&gt; hiHead = null, hiTail = null;
                    Node&lt;K,V&gt; next;
                    do {
                        next = e.next;
                        // 原索引
                        if ((e.hash &amp; oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        // 原索引+oldCap
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    // 原索引放到bucket里
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    // 原索引+oldCap放到bucket里
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
</code></pre>
<h2 id="hashmap-常用方法测试">HashMap 常用方法测试</h2>
<pre><code class="language-java">package map;

import java.util.Collection;
import java.util.HashMap;
import java.util.Set;

public class HashMapDemo {

    public static void main(String[] args) {
        HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();
        // 键不能重复，值可以重复
        map.put(&quot;san&quot;, &quot;张三&quot;);
        map.put(&quot;si&quot;, &quot;李四&quot;);
        map.put(&quot;wu&quot;, &quot;王五&quot;);
        map.put(&quot;wang&quot;, &quot;老王&quot;);
        map.put(&quot;wang&quot;, &quot;老王2&quot;);// 老王被覆盖
        map.put(&quot;lao&quot;, &quot;老王&quot;);
        System.out.println(&quot;-------直接输出hashmap:-------&quot;);
        System.out.println(map);
        /**
         * 遍历HashMap
         */
        // 1.获取Map中的所有键
        System.out.println(&quot;-------foreach获取Map中所有的键:------&quot;);
        Set&lt;String&gt; keys = map.keySet();
        for (String key : keys) {
            System.out.print(key+&quot;  &quot;);
        }
        System.out.println();//换行
        // 2.获取Map中所有值
        System.out.println(&quot;-------foreach获取Map中所有的值:------&quot;);
        Collection&lt;String&gt; values = map.values();
        for (String value : values) {
            System.out.print(value+&quot;  &quot;);
        }
        System.out.println();//换行
        // 3.得到key的值的同时得到key所对应的值
        System.out.println(&quot;-------得到key的值的同时得到key所对应的值:-------&quot;);
        Set&lt;String&gt; keys2 = map.keySet();
        for (String key : keys2) {
            System.out.print(key + &quot;：&quot; + map.get(key)+&quot;   &quot;);

        }
        /**
         * 如果既要遍历key又要value，那么建议这种方式，因为如果先获取keySet然后再执行map.get(key)，map内部会执行两次遍历。
         * 一次是在获取keySet的时候，一次是在遍历所有key的时候。
         */
        // 当我调用put(key,value)方法的时候，首先会把key和value封装到
        // Entry这个静态内部类对象中，把Entry对象再添加到数组中，所以我们想获取
        // map中的所有键值对，我们只要获取数组中的所有Entry对象，接下来
        // 调用Entry对象中的getKey()和getValue()方法就能获取键值对了
        Set&lt;java.util.Map.Entry&lt;String, String&gt;&gt; entrys = map.entrySet();
        for (java.util.Map.Entry&lt;String, String&gt; entry : entrys) {
            System.out.println(entry.getKey() + &quot;--&quot; + entry.getValue());
        }

        /**
         * HashMap其他常用方法
         */
        System.out.println(&quot;after map.size()：&quot;+map.size());
        System.out.println(&quot;after map.isEmpty()：&quot;+map.isEmpty());
        System.out.println(map.remove(&quot;san&quot;));
        System.out.println(&quot;after map.remove()：&quot;+map);
        System.out.println(&quot;after map.get(si)：&quot;+map.get(&quot;si&quot;));
        System.out.println(&quot;after map.containsKey(si)：&quot;+map.containsKey(&quot;si&quot;));
        System.out.println(&quot;after containsValue(李四)：&quot;+map.containsValue(&quot;李四&quot;));
        System.out.println(map.replace(&quot;si&quot;, &quot;李四2&quot;));
        System.out.println(&quot;after map.replace(si, 李四2):&quot;+map);
    }

}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mapreduce]]></title>
        <id>https://xuetongyao.github.io/post/mapreduce/</id>
        <link href="https://xuetongyao.github.io/post/mapreduce/">
        </link>
        <updated>2022-07-27T13:01:07.000Z</updated>
        <content type="html"><![CDATA[<p>Hadoop解决大规模数据分布式计算的方案是MapReduce。MapReduce既是一个编程模型，又是一个计算框架。也就是说，开发人员必须基于MapReduce编程模型进行编程开发，然后将程序通过MapReduce计算框架分发到Hadoop集群中运行。我们先看一下作为编程模型的MapReduce。</p>
<h3 id="mapreduce编程模型">MapReduce编程模型</h3>
<p>MapReduce是一种非常简单又非常强大的编程模型。</p>
<p>简单在于其编程模型只包含map和reduce两个过程，map的主要输入是一对&lt;key , value&gt;值，经过map计算后输出一对&lt;key , value&gt;值；然后将相同key合并，形成&lt;key , value集合&gt;；再将这个&lt;key , value集合&gt;输入reduce，经过计算输出零个或多个&lt;key , value&gt;对。</p>
<p>但是MapReduce同时又是非常强大的，不管是关系代数运算（SQL计算），还是矩阵运算（图计算），大数据领域几乎所有的计算需求都可以通过MapReduce编程来实现。</p>
<p>我们以WordCount程序为例。WordCount主要解决文本处理中的词频统计问题，就是统计文本中每一个单词出现的次数。如果只是统计一篇文章的词频，几十K到几M的数据，那么写一个程序，将数据读入内存，建一个Hash表记录每个词出现的次数就可以了，如下图。</p>
<figure data-type="image" tabindex="1"><img src="MapReduce%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%92%8C%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86.resources/9BC09734-6728-4F29-A798-AE7684F1C04E.png" alt="1cf32673aae43e61a75847b066884057" loading="lazy"></figure>
<p>但是如果想统计全世界互联网所有网页（数万亿计）的词频数（这正是google这样的搜索引擎典型需求），你不可能写一个程序把全世界的网页都读入内存，这时候就需要用MapReduce编程来解决。</p>
<p>WordCount的MapReduce程序如下。</p>
<pre><code>public class WordCount {

public static class TokenizerMapper
extends Mapper&lt;Object, Text, Text, IntWritable&gt;{

private final static IntWritable one = new IntWritable(1);
private Text word = new Text();

public void map(Object key, Text value, Context context
) throws IOException, InterruptedException {
StringTokenizer itr = new StringTokenizer(value.toString());
while (itr.hasMoreTokens()) {
word.set(itr.nextToken());
context.write(word, one);
}
}
}

public static class IntSumReducer
extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {
private IntWritable result = new IntWritable();

public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
Context context
) throws IOException, InterruptedException {
int sum = 0;
for (IntWritable val : values) {
sum += val.get();
}
result.set(sum);
context.write(key, result);
}
}
}
</code></pre>
<p>其核心是一个map函数，一个reduce函数。</p>
<p>map函数的输入主要是一个&lt;key , value&gt;对，在这个例子里，value是要统计的所有文本中的一行数据，key在这里不重要，我们忽略。</p>
<pre><code>public void map(Object key, Text value, Context context)
</code></pre>
<p>map函数的计算过程就是，将这行文本中的单词提取出来，针对每个单词输出一个&lt;word , 1&gt;这样的&lt;key , value&gt;对。</p>
<p>MapReduce计算框架会将这些&lt;word , 1&gt;收集起来，将相同的word放在一起，形成&lt;word , &lt;1,1,1,1,1,1,1.....&gt;&gt;这样的&lt;key , value集合&gt;数据，然后将其输入给reduce函数。</p>
<pre><code>public void reduce(Text key, Iterable&lt;IntWritable&gt; values,Context context)
</code></pre>
<p>这里的reduce的输入参数values就是由很多个1组成的集合，而key就是具体的单词word。</p>
<p>reduce函数的计算过程就是，将这个集合里的1求和，再将单词（word）和这个和（sum）组成一个&lt;key , value&gt;(&lt;word , sum&gt;)输出。每一个输出就是一个单词和它的词频统计总和。</p>
<p>假设有两个block的文本数据需要进行词频统计，MapReduce计算过程如下图。<br>
<img src="resources/80C38BAC-B7B6-413A-9504-44AF99C5FB27.png" referrerpolicy="no-referrer" style="margin: auto;" /></p>
<h3 id="mapreduce计算过程">MapReduce计算过程</h3>
<p>一个map函数可以针对一部分数据进行运算，这样就可以将一个大数据切分成很多块（这也正是HDFS所做的），MapReduce计算框架为每个块分配一个map函数去计算，从而实现大数据的分布式计算。</p>
<p>上面提到MapReduce编程模型将大数据计算过程切分为map和reduce两个阶段，在map阶段为每个数据块分配一个map计算任务，然后将所有map输出的key进行合并，相同的key及其对应的value发送给同一个reduce任务去处理。</p>
<p>这个过程有两个关键问题需要处理</p>
<ul>
<li>
<p>如何为每个数据块分配一个map计算任务，代码是如何发送数据块所在服务器的，发送过去是如何启动的，启动以后又如何知道自己需要计算的数据在文件什么位置（数据块id是什么）</p>
</li>
<li>
<p>处于不同服务器的map输出的&lt;key , value&gt; ，如何把相同的key聚合在一起发送给reduce任务</p>
</li>
<li>
<p>这两个关键问题正好对应文章中“MapReduce计算过程”一图中两处“MapReduce框架处理”。</p>
</li>
</ul>
<figure data-type="image" tabindex="2"><img src="MapReduce%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%92%8C%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86.resources/0EAF1DCB-D641-4F33-A093-41B6AFE34EE2.png" alt="fe3a4f4e8603397638a92d67964c8b0e" loading="lazy"></figure>
<p>我们先看下MapReduce是如何启动处理一个大数据计算应用作业的。</p>
<h4 id="mapreduce作业启动和运行机制">MapReduce作业启动和运行机制</h4>
<p>我们以Hadoop1为例，MapReduce运行过程涉及以下几类关键进程：</p>
<ul>
<li>
<p>大数据应用进程：启动用户MapReduce程序的主入口，主要指定Map和Reduce类、输入输出文件路径等，并提交作业给Hadoop集群。</p>
</li>
<li>
<p>JobTracker进程：根据要处理的输入数据量启动相应数量的map和reduce进程任务，并管理整个作业生命周期的任务调度和监控。JobTracker进程在整个Hadoop集群全局唯一。</p>
</li>
<li>
<p>TaskTracker进程：负责启动和管理map进程以及reduce进程。因为需要每个数据块都有对应的map函数，TaskTracker进程通常和HDFS的DataNode进程启动在同一个服务器，也就是说，Hadoop集群中绝大多数服务器同时运行DataNode进程和TaskTacker进程。</p>
</li>
</ul>
<p>如下图所示。</p>
<figure data-type="image" tabindex="3"><img src="MapReduce%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%92%8C%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86.resources/011912DD-397C-4C64-B978-F932E333E232.png" alt="56113971e19e97cdacc9f4b4f9993b76" loading="lazy"></figure>
<p>具体作业启动和计算过程如下：</p>
<ul>
<li>应用进程将用户作业jar包存储在HDFS中，将来这些jar包会分发给Hadoop集群中的服务器执行MapReduce计算。</li>
<li>应用程序提交job作业给JobTracker。</li>
<li>JobTacker根据作业调度策略创建JobInProcess树，每个作业都会有一个自己的JobInProcess树。</li>
<li>JobInProcess根据输入数据分片数目（通常情况就是数据块的数目）和设置的reduce数目创建相应数量的TaskInProcess。</li>
<li>TaskTracker进程和JobTracker进程进行定时通信。</li>
<li>如果TaskTracker有空闲的计算资源（空闲CPU核），JobTracker就会给他分配任务。分配任务的时候会根据TaskTracker的服务器名字匹配在同一台机器上的数据块计算任务给它，使启动的计算任务正好处理本机上的数据。</li>
<li>TaskRunner收到任务后根据任务类型（map还是reduce），任务参数（作业jar包路径，输入数据文件路径，要处理的数据在文件中的起始位置和偏移量，数据块多个备份的DataNode主机名等）启动相应的map或者reduce进程。</li>
<li>map或者reduce程序启动后，检查本地是否有要执行任务的jar包文件，如果没有，就去HDFS上下载，然后加载map或者reduce代码开始执行。</li>
<li>如果是map进程，从HDFS读取数据（通常要读取的数据块正好存储在本机）。如果是reduce进程，将结果数据写出到HDFS。</li>
</ul>
<p>通过以上过程，MapReduce可以将大数据作业计算任务分布在整个Hadoop集群中运行，每个map计算任务要处理的数据通常都能从本地磁盘上读取到。而用户要做的仅仅是编写一个map函数和一个reduce函数就可以了，根本不用关心这两个函数是如何被分布启动到集群上的，数据块又是如何分配给计算任务的。这一切都由MapReduce计算框架完成。</p>
<h4 id="mapreduce数据合并与连接机制">MapReduce数据合并与连接机制</h4>
<p>在WordCount例子中，要统计相同单词在所有输入数据中出现的次数，而一个map只能处理一部分数据，一个热门单词几乎会出现在所有的map中，这些单词必须要合并到一起进行统计才能得到正确的结果。</p>
<p>事实上，几乎所有的大数据计算场景都需要处理数据关联的问题，简单如WordCount只要对key进行合并就可以了，复杂如数据库的join操作，需要对两种类型（或者更多类型）的数据根据key进行连接。</p>
<p>MapReduce计算框架处理数据合并与连接的操作就在map输出与reduce输入之间，这个过程有个专门的词汇来描述，叫做shuffle。</p>
<h4 id="mapreduce-shuffle过程">MapReduce shuffle过程</h4>
<p>每个map任务的计算结果都会写入到本地文件系统，等map任务快要计算完成的时候，MapReduce计算框架会启动shuffle过程，在map端调用一个Partitioner接口，对map产生的每个&lt;key , value&gt;进行reduce分区选择，然后通过http通信发送给对应的reduce进程。这样不管map位于哪个服务器节点，相同的key一定会被发送给相同的reduce进程。reduce端对收到的&lt;key , value&gt;进行排序和合并，相同的key放在一起，组成一个&lt;key , value集合&gt;传递给reduce执行。</p>
<p>MapReduce框架缺省的Partitioner用key的哈希值对reduce任务数量取模，相同的key一定会落在相同的reduce任务id上，实现上，这样的Partitioner代码只需要一行，如下所示。</p>
<pre><code>/** Use {@link Object#hashCode()} to partition. */ 
public int getPartition(K2 key, V2 value, int numReduceTasks) { 
return (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks; 
}
</code></pre>
<p>shuffle是大数据计算过程中发生奇迹的地方，不管是MapReduce还是Spark，只要是大数据批处理计算，一定会有shuffle过程，让数据关联起来，数据的内在关系和价值才会呈现出来。不理解shuffle，就会在map和reduce编程中产生困惑，不知道该如何正确设计map的输出和reduce的输入。shuffle也是整个MapReduce过程中最难最消耗性能的地方，在MapReduce早期代码中，一半代码都是关于shuffle处理的。</p>
<figure data-type="image" tabindex="4"><img src="MapReduce%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%92%8C%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86.resources/8DB07269-807E-435E-B65D-3A0A16E05D07.png" alt="e0eb09bb5187517b530feb90ab55f767" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JVM]]></title>
        <id>https://xuetongyao.github.io/post/jvm/</id>
        <link href="https://xuetongyao.github.io/post/jvm/">
        </link>
        <updated>2022-07-27T12:58:27.000Z</updated>
        <content type="html"><![CDATA[<hr>
<p>category: Java<br>
tag:</p>
<ul>
<li>JVM</li>
</ul>
<hr>
<h1 id="大白话带你认识jvm">大白话带你认识JVM</h1>
<p>原文地址：https://juejin.im/post/5e1505d0f265da5d5d744050#heading-28</p>
<h2 id="前言">前言</h2>
<p>如果在文中用词或者理解方面出现问题，欢迎指出。此文旨在提及而不深究，但会尽量效率地把知识点都抛出来</p>
<h2 id="一-jvm的基本介绍">一、JVM的基本介绍</h2>
<p>JVM 是 Java Virtual Machine 的缩写，它是一个虚构出来的计算机，一种规范。通过在实际的计算机上仿真模拟各类计算机功能实现···</p>
<p>好，其实抛开这么专业的句子不说，就知道JVM其实就类似于一台小电脑运行在windows或者linux这些操作系统环境下即可。它直接和操作系统进行交互，与硬件不直接交互，而操作系统可以帮我们完成和硬件进行交互的工作。</p>
<figure data-type="image" tabindex="1"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/d947f91e44c44c6c80222b49c2dee859-new-image19a36451-d673-486e-9c8e-3c7d8ab66929.png" alt="" loading="lazy"></figure>
<h3 id="11-java文件是如何被运行的">1.1 Java文件是如何被运行的</h3>
<p>比如我们现在写了一个 HelloWorld.java 好了，那这个 HelloWorld.java 抛开所有东西不谈，那是不是就类似于一个文本文件，只是这个文本文件它写的都是英文，而且有一定的缩进而已。</p>
<p>那我们的 <strong>JVM</strong> 是不认识文本文件的，所以它需要一个 <strong>编译</strong> ，让其成为一个它会读二进制文件的 <strong>HelloWorld.class</strong></p>
<h4 id="1-类加载器">① 类加载器</h4>
<p>如果 <strong>JVM</strong> 想要执行这个 <strong>.class</strong> 文件，我们需要将其装进一个 <strong>类加载器</strong> 中，它就像一个搬运工一样，会把所有的 <strong>.class</strong> 文件全部搬进JVM里面来。</p>
<figure data-type="image" tabindex="2"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/81f1813f371c40ffa1c1f6d78bc49ed9-new-image28314ec8-066f-451e-8373-4517917d6bf7.png" alt="" loading="lazy"></figure>
<h4 id="2-方法区">② 方法区</h4>
<p><strong>方法区</strong> 是用于存放类似于元数据信息方面的数据的，比如类信息，常量，静态变量，编译后代码···等</p>
<p>类加载器将 .class 文件搬过来就是先丢到这一块上</p>
<h4 id="3-堆">③ 堆</h4>
<p><strong>堆</strong> 主要放了一些存储的数据，比如对象实例，数组···等，它和方法区都同属于 <strong>线程共享区域</strong> 。也就是说它们都是 <strong>线程不安全</strong> 的</p>
<h4 id="4-栈">④ 栈</h4>
<p><strong>栈</strong> 这是我们的代码运行空间。我们编写的每一个方法都会放到 <strong>栈</strong> 里面运行。</p>
<p>我们会听说过 本地方法栈 或者 本地方法接口 这两个名词，不过我们基本不会涉及这两块的内容，它俩底层是使用C来进行工作的，和Java没有太大的关系。</p>
<h4 id="5-程序计数器">⑤ 程序计数器</h4>
<p>主要就是完成一个加载工作，类似于一个指针一样的，指向下一行我们需要执行的代码。和栈一样，都是 <strong>线程独享</strong> 的，就是说每一个线程都会有自己对应的一块区域而不会存在并发和多线程的问题。</p>
<figure data-type="image" tabindex="3"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/897863ee5ecb4d92b9119d065f468262-new-imagef7287f0b-c9f0-4f22-9eb4-6968bbaa5a82.png" alt="" loading="lazy"></figure>
<h4 id="小总结">小总结</h4>
<ol>
<li>Java文件经过编译后变成 .class 字节码文件</li>
<li>字节码文件通过类加载器被搬运到 JVM 虚拟机中</li>
<li>虚拟机主要的5大块：方法区，堆都为线程共享区域，有线程安全问题，栈和本地方法栈和计数器都是独享区域，不存在线程安全问题，而 JVM 的调优主要就是围绕堆，栈两大块进行</li>
</ol>
<h3 id="12-简单的代码例子">1.2 简单的代码例子</h3>
<p>一个简单的学生类</p>
<figure data-type="image" tabindex="4"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/29046a721c2548e0a0680ec5baf4ea95-new-imageb0b42e5e-8e25-409e-b7b9-6586a39a0b8d.png" alt="" loading="lazy"></figure>
<p>一个main方法</p>
<figure data-type="image" tabindex="5"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/a3d34d33eab74f6f8743ecf62807445c-new-image08506a9e-5101-4f30-b0bc-3abbcb8f1894.png" alt="" loading="lazy"></figure>
<p>执行main方法的步骤如下:</p>
<ol>
<li>编译好 App.java 后得到 App.class 后，执行 App.class，系统会启动一个 JVM 进程，从 classpath 路径中找到一个名为 App.class 的二进制文件，将 App 的类信息加载到运行时数据区的方法区内，这个过程叫做 App 类的加载</li>
<li>JVM 找到 App 的主程序入口，执行main方法</li>
<li>这个main中的第一条语句为 Student student = new Student(&quot;tellUrDream&quot;) ，就是让 JVM 创建一个Student对象，但是这个时候方法区中是没有 Student 类的信息的，所以 JVM 马上加载 Student 类，把 Student 类的信息放到方法区中</li>
<li>加载完 Student 类后，JVM 在堆中为一个新的 Student 实例分配内存，然后调用构造函数初始化 Student 实例，这个 Student 实例持有 <strong>指向方法区中的 Student 类的类型信息</strong> 的引用</li>
<li>执行student.sayName();时，JVM 根据 student 的引用找到 student 对象，然后根据 student 对象持有的引用定位到方法区中 student 类的类型信息的方法表，获得 sayName() 的字节码地址。</li>
<li>执行sayName()</li>
</ol>
<p>其实也不用管太多，只需要知道对象实例初始化时会去方法区中找类信息，完成后再到栈那里去运行方法。找方法就在方法表中找。</p>
<h2 id="二-类加载器的介绍">二、类加载器的介绍</h2>
<p>之前也提到了它是负责加载.class文件的，它们在文件开头会有特定的文件标示，将class文件字节码内容加载到内存中，并将这些内容转换成方法区中的运行时数据结构，并且ClassLoader只负责class文件的加载，而是否能够运行则由 Execution Engine 来决定</p>
<h3 id="21-类加载器的流程">2.1 类加载器的流程</h3>
<p>从类被加载到虚拟机内存中开始，到释放内存总共有7个步骤：加载，验证，准备，解析，初始化，使用，卸载。其中<strong>验证，准备，解析三个部分统称为连接</strong></p>
<h4 id="211-加载">2.1.1 加载</h4>
<ol>
<li>将class文件加载到内存</li>
<li>将静态数据结构转化成方法区中运行时的数据结构</li>
<li>在堆中生成一个代表这个类的 java.lang.Class对象作为数据访问的入口</li>
</ol>
<h4 id="212-链接">2.1.2 链接</h4>
<ol>
<li>验证：确保加载的类符合 JVM 规范和安全，保证被校验类的方法在运行时不会做出危害虚拟机的事件，其实就是一个安全检查</li>
<li>准备：为static变量在方法区中分配内存空间，设置变量的初始值，例如 static int a = 3 （注意：准备阶段只设置类中的静态变量（方法区中），不包括实例变量（堆内存中），实例变量是对象初始化时赋值的）</li>
<li>解析：虚拟机将常量池内的符号引用替换为直接引用的过程（符号引用比如我现在import java.util.ArrayList这就算符号引用，直接引用就是指针或者对象地址，注意引用对象一定是在内存进行）</li>
</ol>
<h4 id="213-初始化">2.1.3 初始化</h4>
<p>初始化其实就是执行类构造器方法的<code>&lt;clinit&gt;()</code>的过程，而且要保证执行前父类的<code>&lt;clinit&gt;()</code>方法执行完毕。这个方法由编译器收集，顺序执行所有类变量（static修饰的成员变量）显式初始化和静态代码块中语句。此时准备阶段时的那个 <code>static int a</code> 由默认初始化的0变成了显式初始化的3。 由于执行顺序缘故，初始化阶段类变量如果在静态代码块中又进行了更改，会覆盖类变量的显式初始化，最终值会为静态代码块中的赋值。</p>
<blockquote>
<p>注意：字节码文件中初始化方法有两种，非静态资源初始化的<code>&lt;init&gt;</code>和静态资源初始化的<code>&lt;clinit&gt;</code>，类构造器方法<code>&lt;clinit&gt;()</code>不同于类的构造器，这些方法都是字节码文件中只能给JVM识别的特殊方法。</p>
</blockquote>
<h4 id="214-卸载">2.1.4 卸载</h4>
<p>GC将无用对象从内存中卸载</p>
<h3 id="22-类加载器的加载顺序">2.2 类加载器的加载顺序</h3>
<p>加载一个Class类的顺序也是有优先级的，类加载器从最底层开始往上的顺序是这样的</p>
<ol>
<li>BootStrap ClassLoader：rt.jar</li>
<li>Extension ClassLoader: 加载扩展的jar包</li>
<li>App ClassLoader：指定的classpath下面的jar包</li>
<li>Custom ClassLoader：自定义的类加载器</li>
</ol>
<h3 id="23-双亲委派机制">2.3 双亲委派机制</h3>
<p>当一个类收到了加载请求时，它是不会先自己去尝试加载的，而是委派给父类去完成，比如我现在要 new 一个 Person，这个 Person 是我们自定义的类，如果我们要加载它，就会先委派 App ClassLoader ，只有当父类加载器都反馈自己无法完成这个请求（也就是父类加载器都没有找到加载所需的 Class）时，子类加载器才会自行尝试加载。</p>
<p>这样做的好处是，加载位于 rt.jar 包中的类时不管是哪个加载器加载，最终都会委托到 BootStrap ClassLoader 进行加载，这样保证了使用不同的类加载器得到的都是同一个结果。</p>
<p>其实这个也是一个隔离的作用，避免了我们的代码影响了 JDK 的代码，比如我现在自己定义一个 <code>java.lang.String</code> ：</p>
<pre><code class="language-java">package java.lang;
public class String {
    public static void main(String[] args) {
        System.out.println();
    }
}
</code></pre>
<p>尝试运行当前类的 <code>main</code> 函数的时候，我们的代码肯定会报错。这是因为在加载的时候其实是找到了 rt.jar 中的<code>java.lang.String</code>，然而发现这个里面并没有 <code>main</code> 方法。</p>
<h2 id="三-运行时数据区">三、运行时数据区</h2>
<h3 id="31-本地方法栈和程序计数器">3.1 本地方法栈和程序计数器</h3>
<p>比如说我们现在点开Thread类的源码，会看到它的start0方法带有一个native关键字修饰，而且不存在方法体，这种用native修饰的方法就是本地方法，这是使用C来实现的，然后一般这些方法都会放到一个叫做本地方法栈的区域。</p>
<p>程序计数器其实就是一个指针，它指向了我们程序中下一句需要执行的指令，它也是内存区域中唯一一个不会出现OutOfMemoryError的区域，而且占用内存空间小到基本可以忽略不计。这个内存仅代表当前线程所执行的字节码的行号指示器，字节码解析器通过改变这个计数器的值选取下一条需要执行的字节码指令。</p>
<p>如果执行的是native方法，那这个指针就不工作了。</p>
<h3 id="32-方法区">3.2 方法区</h3>
<p>方法区主要的作用是存放类的元数据信息，常量和静态变量···等。当它存储的信息过大时，会在无法满足内存分配时报错。</p>
<h3 id="33-虚拟机栈和虚拟机堆">3.3 虚拟机栈和虚拟机堆</h3>
<p>一句话便是：栈管运行，堆管存储。则虚拟机栈负责运行代码，而虚拟机堆负责存储数据。</p>
<h4 id="331-虚拟机栈的概念">3.3.1 虚拟机栈的概念</h4>
<p>它是Java方法执行的内存模型。里面会对局部变量，动态链表，方法出口，栈的操作（入栈和出栈）进行存储，且线程独享。同时如果我们听到局部变量表，那也是在说虚拟机栈</p>
<pre><code class="language-java">public class Person{
    int a = 1;
    
    public void doSomething(){
        int b = 2;
    }
}
</code></pre>
<h4 id="332-虚拟机栈存在的异常">3.3.2 虚拟机栈存在的异常</h4>
<p>如果线程请求的栈的深度大于虚拟机栈的最大深度，就会报 <strong>StackOverflowError</strong> （这种错误经常出现在递归中）。Java虚拟机也可以动态扩展，但随着扩展会不断地申请内存，当无法申请足够内存时就会报错 <strong>OutOfMemoryError</strong>。</p>
<h4 id="333-虚拟机栈的生命周期">3.3.3 虚拟机栈的生命周期</h4>
<p>对于栈来说，不存在垃圾回收。只要程序运行结束，栈的空间自然就会释放了。栈的生命周期和所处的线程是一致的。</p>
<p>这里补充一句：8种基本类型的变量+对象的引用变量+实例方法都是在栈里面分配内存。</p>
<h4 id="334-虚拟机栈的执行">3.3.4 虚拟机栈的执行</h4>
<p>我们经常说的栈帧数据，说白了在JVM中叫栈帧，放到Java中其实就是方法，它也是存放在栈中的。</p>
<p>栈中的数据都是以栈帧的格式存在，它是一个关于方法和运行期数据的数据集。比如我们执行一个方法a，就会对应产生一个栈帧A1，然后A1会被压入栈中。同理方法b会有一个B1，方法c会有一个C1，等到这个线程执行完毕后，栈会先弹出C1，后B1,A1。它是一个先进后出，后进先出原则。</p>
<h4 id="335-局部变量的复用">3.3.5 局部变量的复用</h4>
<p>局部变量表用于存放方法参数和方法内部所定义的局部变量。它的容量是以Slot为最小单位，一个slot可以存放32位以内的数据类型。</p>
<p>虚拟机通过索引定位的方式使用局部变量表，范围为[0,局部变量表的slot的数量]。方法中的参数就会按一定顺序排列在这个局部变量表中，至于怎么排的我们可以先不关心。而为了节省栈帧空间，这些slot是可以复用的，当方法执行位置超过了某个变量，那么这个变量的slot可以被其它变量复用。当然如果需要复用，那我们的垃圾回收自然就不会去动这些内存。</p>
<h4 id="336-虚拟机堆的概念">3.3.6 虚拟机堆的概念</h4>
<p>JVM内存会划分为堆内存和非堆内存，堆内存中也会划分为<strong>年轻代</strong>和<strong>老年代</strong>，而非堆内存则为<strong>永久代</strong>。年轻代又会分为<strong>Eden</strong>和<strong>Survivor</strong>区。Survivor也会分为<strong>FromPlace</strong>和<strong>ToPlace</strong>，toPlace的survivor区域是空的。Eden，FromPlace和ToPlace的默认占比为 <strong>8:1:1</strong>。当然这个东西其实也可以通过一个 -XX:+UsePSAdaptiveSurvivorSizePolicy 参数来根据生成对象的速率动态调整</p>
<p>堆内存中存放的是对象，垃圾收集就是收集这些对象然后交给GC算法进行回收。非堆内存其实我们已经说过了，就是方法区。在1.8中已经移除永久代，替代品是一个元空间(MetaSpace)，最大区别是metaSpace是不存在于JVM中的，它使用的是本地内存。并有两个参数</p>
<pre><code>MetaspaceSize：初始化元空间大小，控制发生GC
MaxMetaspaceSize：限制元空间大小上限，防止占用过多物理内存。
</code></pre>
<p>移除的原因可以大致了解一下：融合HotSpot JVM和JRockit VM而做出的改变，因为JRockit是没有永久代的，不过这也间接性地解决了永久代的OOM问题。</p>
<h4 id="337-eden年轻代的介绍">3.3.7 Eden年轻代的介绍</h4>
<p>当我们new一个对象后，会先放到Eden划分出来的一块作为存储空间的内存，但是我们知道对堆内存是线程共享的，所以有可能会出现两个对象共用一个内存的情况。这里JVM的处理是每个线程都会预先申请好一块连续的内存空间并规定了对象存放的位置，而如果空间不足会再申请多块内存空间。这个操作我们会称作TLAB，有兴趣可以了解一下。</p>
<p>当Eden空间满了之后，会触发一个叫做Minor GC（就是一个发生在年轻代的GC）的操作，存活下来的对象移动到Survivor0区。Survivor0区满后触发 Minor GC，就会将存活对象移动到Survivor1区，此时还会把from和to两个指针交换，这样保证了一段时间内总有一个survivor区为空且to所指向的survivor区为空。经过多次的 Minor GC后仍然存活的对象（<strong>这里的存活判断是15次，对应到虚拟机参数为 -XX:MaxTenuringThreshold 。为什么是15，因为HotSpot会在对象投中的标记字段里记录年龄，分配到的空间仅有4位，所以最多只能记录到15</strong>）会移动到老年代。老年代是存储长期存活的对象的，占满时就会触发我们最常听说的Full GC，期间会停止所有线程等待GC的完成。所以对于响应要求高的应用应该尽量去减少发生Full GC从而避免响应超时的问题。</p>
<p>而且当老年区执行了full gc之后仍然无法进行对象保存的操作，就会产生OOM，这时候就是虚拟机中的堆内存不足，原因可能会是堆内存设置的大小过小，这个可以通过参数-Xms、-Xmx来调整。也可能是代码中创建的对象大且多，而且它们一直在被引用从而长时间垃圾收集无法收集它们。</p>
<figure data-type="image" tabindex="6"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/c02ecba3c33f43429a765987b928e423-new-image93b46f3d-33f9-46f9-a825-ec7129b004f6.png" alt="" loading="lazy"></figure>
<p>补充说明：关于-XX:TargetSurvivorRatio参数的问题。其实也不一定是要满足-XX:MaxTenuringThreshold才移动到老年代。可以举个例子：如对象年龄5的占30%，年龄6的占36%，年龄7的占34%，加入某个年龄段（如例子中的年龄6）后，总占用超过Survivor空间*TargetSurvivorRatio的时候，从该年龄段开始及大于的年龄对象就要进入老年代（即例子中的年龄6对象，就是年龄6和年龄7晋升到老年代），这时候无需等到MaxTenuringThreshold中要求的15</p>
<h4 id="338-如何判断一个对象需要被干掉">3.3.8 如何判断一个对象需要被干掉</h4>
<figure data-type="image" tabindex="7"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/1c1d85b5fb8b47239af2a5c0436eb2d7-new-image0cd10827-2f96-433c-9b16-93d4fe491d88.png" alt="" loading="lazy"></figure>
<p>图中程序计数器、虚拟机栈、本地方法栈，3个区域随着线程的生存而生存的。内存分配和回收都是确定的。随着线程的结束内存自然就被回收了，因此不需要考虑垃圾回收的问题。而Java堆和方法区则不一样，各线程共享，内存的分配和回收都是动态的。因此垃圾收集器所关注的都是堆和方法这部分内存。</p>
<p>在进行回收前就要判断哪些对象还存活，哪些已经死去。下面介绍两个基础的计算方法</p>
<p>1.引用计数器计算：给对象添加一个引用计数器，每次引用这个对象时计数器加一，引用失效时减一，计数器等于0时就是不会再次使用的。不过这个方法有一种情况就是出现对象的循环引用时GC没法回收。</p>
<p>2.可达性分析计算：这是一种类似于二叉树的实现，将一系列的GC ROOTS作为起始的存活对象集，从这个节点往下搜索，搜索所走过的路径成为引用链，把能被该集合引用到的对象加入到集合中。搜索当一个对象到GC Roots没有使用任何引用链时，则说明该对象是不可用的。主流的商用程序语言，例如Java，C#等都是靠这招去判定对象是否存活的。</p>
<p>（了解一下即可）在Java语言汇总能作为GC Roots的对象分为以下几种：</p>
<ol>
<li>虚拟机栈（栈帧中的本地方法表）中引用的对象（局部变量）</li>
<li>方法区中静态变量所引用的对象（静态变量）</li>
<li>方法区中常量引用的对象</li>
<li>本地方法栈（即native修饰的方法）中JNI引用的对象（JNI是Java虚拟机调用对应的C函数的方式，通过JNI函数也可以创建新的Java对象。且JNI对于对象的局部引用或者全局引用都会把它们指向的对象都标记为不可回收）</li>
<li>已启动的且未终止的Java线程</li>
</ol>
<p>这种方法的优点是能够解决循环引用的问题，可它的实现需要耗费大量资源和时间，也需要GC（它的分析过程引用关系不能发生变化，所以需要停止所有进程）</p>
<h4 id="339-如何宣告一个对象的真正死亡">3.3.9 如何宣告一个对象的真正死亡</h4>
<p>首先必须要提到的是一个名叫 <strong>finalize()</strong> 的方法</p>
<p>finalize()是Object类的一个方法、一个对象的finalize()方法只会被系统自动调用一次，经过finalize()方法逃脱死亡的对象，第二次不会再调用。</p>
<p>补充一句：并不提倡在程序中调用finalize()来进行自救。建议忘掉Java程序中该方法的存在。因为它执行的时间不确定，甚至是否被执行也不确定（Java程序的不正常退出），而且运行代价高昂，无法保证各个对象的调用顺序（甚至有不同线程中调用）。在Java9中已经被标记为 <strong>deprecated</strong> ，且 <code>java.lang.ref.Cleaner</code>（也就是强、软、弱、幻象引用的那一套）中已经逐步替换掉它，会比 <code>finalize</code> 来的更加的轻量及可靠。<br>
　　<br>
<img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/c807dab33f8b42329c1910d609e7ed21-new-image565aeab2-6d3e-4c2c-80f6-7a7b0f629fda.png" alt="" loading="lazy"></p>
<p>判断一个对象的死亡至少需要两次标记</p>
<ol>
<li>如果对象进行可达性分析之后没发现与GC Roots相连的引用链，那它将会第一次标记并且进行一次筛选。判断的条件是决定这个对象是否有必要执行finalize()方法。如果对象有必要执行finalize()方法，则被放入F-Queue队列中。</li>
<li>GC对F-Queue队列中的对象进行二次标记。如果对象在finalize()方法中重新与引用链上的任何一个对象建立了关联，那么二次标记时则会将它移出“即将回收”集合。如果此时对象还没成功逃脱，那么只能被回收了。</li>
</ol>
<p>如果确定对象已经死亡，我们又该如何回收这些垃圾呢</p>
<h3 id="34-垃圾回收算法">3.4 垃圾回收算法</h3>
<p>不会非常详细的展开，常用的有标记清除，复制，标记整理和分代收集算法</p>
<h4 id="341-标记清除算法">3.4.1 标记清除算法</h4>
<p>标记清除算法就是分为“标记”和“清除”两个阶段。标记出所有需要回收的对象，标记结束后统一回收。这个套路很简单，也存在不足，后续的算法都是根据这个基础来加以改进的。</p>
<p>其实它就是把已死亡的对象标记为空闲内存，然后记录在一个空闲列表中，当我们需要new一个对象时，内存管理模块会从空闲列表中寻找空闲的内存来分给新的对象。</p>
<p>不足的方面就是标记和清除的效率比较低下。且这种做法会让内存中的碎片非常多。这个导致了如果我们需要使用到较大的内存块时，无法分配到足够的连续内存。比如下图</p>
<figure data-type="image" tabindex="8"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/01605d96d85f4daab9bfa5e7000f0d31-new-image78e03b85-fbef-4df9-b41e-2b63d78d119f.png" alt="" loading="lazy"></figure>
<p>此时可使用的内存块都是零零散散的，导致了刚刚提到的大内存对象问题</p>
<h4 id="342-复制算法">3.4.2 复制算法</h4>
<p>为了解决效率问题，复制算法就出现了。它将可用内存按容量划分成两等分，每次只使用其中的一块。和survivor一样也是用from和to两个指针这样的玩法。fromPlace存满了，就把存活的对象copy到另一块toPlace上，然后交换指针的内容。这样就解决了碎片的问题。</p>
<p>这个算法的代价就是把内存缩水了，这样堆内存的使用效率就会变得十分低下了</p>
<figure data-type="image" tabindex="9"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/fc349fbb9b204495a5321febe27818d4-new-image45920a9a-552c-4656-94d6-e3ca45ff9b76.png" alt="" loading="lazy"></figure>
<p>不过它们分配的时候也不是按照1:1这样进行分配的，就类似于Eden和Survivor也不是等价分配是一个道理。</p>
<h4 id="343-标记整理算法">3.4.3 标记整理算法</h4>
<p>复制算法在对象存活率高的时候会有一定的效率问题，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉边界以外的内存</p>
<figure data-type="image" tabindex="10"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/2599e9f722074d34a3f7fd9f0076f121-new-imagec76192ec-b63a-43e3-a6d6-cf01f749953f.png" alt="" loading="lazy"></figure>
<h4 id="344-分代收集算法">3.4.4 分代收集算法</h4>
<p>这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或者“标记-整理”算法来进行回收。</p>
<p>说白了就是八仙过海各显神通，具体问题具体分析了而已。</p>
<h3 id="35-了解各种各样的垃圾回收器">3.5 （了解）各种各样的垃圾回收器</h3>
<p>HotSpot VM中的垃圾回收器，以及适用场景</p>
<figure data-type="image" tabindex="11"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/11e9dcd0f1ee4f25836e6f1c47104c51-new-image69e1c56a-1d40-493a-9901-6efc647a01f3.png" alt="" loading="lazy"></figure>
<p>到jdk8为止，默认的垃圾收集器是Parallel Scavenge 和 Parallel Old</p>
<p>从jdk9开始，G1收集器成为默认的垃圾收集器<br>
目前来看，G1回收器停顿时间最短而且没有明显缺点，非常适合Web应用。在jdk8中测试Web应用，堆内存6G，新生代4.5G的情况下，Parallel Scavenge 回收新生代停顿长达1.5秒。G1回收器回收同样大小的新生代只停顿0.2秒。</p>
<h3 id="36-了解jvm的常用参数">3.6 （了解）JVM的常用参数</h3>
<p>JVM的参数非常之多，这里只列举比较重要的几个，通过各种各样的搜索引擎也可以得知这些信息。</p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>含义</th>
<th>默认值</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-Xms</td>
<td>初始堆大小</td>
<td>物理内存的1/64(&lt;1GB)</td>
<td>默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制.</td>
</tr>
<tr>
<td>-Xmx</td>
<td>最大堆大小</td>
<td>物理内存的1/4(&lt;1GB)</td>
<td>默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制</td>
</tr>
<tr>
<td>-Xmn</td>
<td>年轻代大小(1.4or later)</td>
<td></td>
<td>注意：此处的大小是（eden+ 2 survivor space).与jmap -heap中显示的New gen是不同的。整个堆大小=年轻代大小 + 老年代大小 + 持久代（永久代）大小.增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8</td>
</tr>
<tr>
<td>-XX:NewSize</td>
<td>设置年轻代大小(for 1.3/1.4)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>-XX:MaxNewSize</td>
<td>年轻代最大值(for 1.3/1.4)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>-XX:PermSize</td>
<td>设置持久代(perm gen)初始值</td>
<td>物理内存的1/64</td>
<td></td>
</tr>
<tr>
<td>-XX:MaxPermSize</td>
<td>设置持久代最大值</td>
<td>物理内存的1/4</td>
<td></td>
</tr>
<tr>
<td>-Xss</td>
<td>每个线程的堆栈大小</td>
<td></td>
<td>JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K.根据应用的线程所需内存大小进行 调整.在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右一般小的应用， 如果栈不是很深， 应该是128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。（校长）和threadstacksize选项解释很类似,官方文档似乎没有解释,在论坛中有这样一句话:-Xss is translated in a VM flag named ThreadStackSize”一般设置这个值就可以了</td>
</tr>
<tr>
<td>-XX:NewRatio</td>
<td>年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代)</td>
<td></td>
<td>-XX:NewRatio=4表示年轻代与年老代所占比值为1:4,年轻代占整个堆栈的1/5Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。</td>
</tr>
<tr>
<td>-XX:SurvivorRatio</td>
<td>Eden区与Survivor区的大小比值</td>
<td></td>
<td>设置为8,则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10</td>
</tr>
<tr>
<td>-XX:+DisableExplicitGC</td>
<td>关闭System.gc()</td>
<td></td>
<td>这个参数需要严格的测试</td>
</tr>
<tr>
<td>-XX:PretenureSizeThreshold</td>
<td>对象超过多大是直接在旧生代分配</td>
<td>0</td>
<td>单位字节 新生代采用Parallel ScavengeGC时无效另一种直接在旧生代分配的情况是大的数组对象,且数组中无外部引用对象.</td>
</tr>
<tr>
<td>-XX:ParallelGCThreads</td>
<td>并行收集器的线程数</td>
<td></td>
<td>此值最好配置与处理器数目相等 同样适用于CMS</td>
</tr>
<tr>
<td>-XX:MaxGCPauseMillis</td>
<td>每次年轻代垃圾回收的最长时间(最大暂停时间)</td>
<td></td>
<td>如果无法满足此时间,JVM会自动调整年轻代大小,以满足此值.</td>
</tr>
</tbody>
</table>
<p>其实还有一些打印及CMS方面的参数，这里就不以一一列举了</p>
<h2 id="四-关于jvm调优的一些方面">四、关于JVM调优的一些方面</h2>
<p>根据刚刚涉及的jvm的知识点，我们可以尝试对JVM进行调优，主要就是堆内存那块</p>
<p>所有线程共享数据区大小=新生代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m。所以java堆中增大年轻代后，将会减小年老代大小（因为老年代的清理是使用fullgc，所以老年代过小的话反而是会增多fullgc的）。此值对系统性能影响较大，Sun官方推荐配置为java堆的3/8。</p>
<h3 id="41-调整最大堆内存和最小堆内存">4.1 调整最大堆内存和最小堆内存</h3>
<p>-Xmx –Xms：指定java堆最大值（默认值是物理内存的1/4(&lt;1GB)）和初始java堆最小值（默认值是物理内存的1/64(&lt;1GB))</p>
<p>默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制.，默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制。简单点来说，你不停地往堆内存里面丢数据，等它剩余大小小于40%了，JVM就会动态申请内存空间不过会小于-Xmx，如果剩余大小大于70%，又会动态缩小不过不会小于–Xms。就这么简单</p>
<p>开发过程中，通常会将 -Xms 与 -Xmx两个参数配置成相同的值，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源。</p>
<p>我们执行下面的代码</p>
<pre><code class="language-java">System.out.println(&quot;Xmx=&quot; + Runtime.getRuntime().maxMemory() / 1024.0 / 1024 + &quot;M&quot;);    //系统的最大空间
System.out.println(&quot;free mem=&quot; + Runtime.getRuntime().freeMemory() / 1024.0 / 1024 + &quot;M&quot;);  //系统的空闲空间
System.out.println(&quot;total mem=&quot; + Runtime.getRuntime().totalMemory() / 1024.0 / 1024 + &quot;M&quot;);  //当前可用的总空间
</code></pre>
<p>注意：此处设置的是Java堆大小，也就是新生代大小 + 老年代大小</p>
<figure data-type="image" tabindex="12"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/5e7b352c16d74c789c665af46d3a2509-new-imagedd645dae-307d-4572-b6e2-b5a9925a46cd.png" alt="" loading="lazy"></figure>
<p>设置一个VM options的参数</p>
<pre><code>-Xmx20m -Xms5m -XX:+PrintGCDetails
</code></pre>
<figure data-type="image" tabindex="13"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/fe99e355f4754fa4be7427cb65261f3d-new-imagebb5cf485-99f8-43eb-8809-2a89e6a1768e.png" alt="" loading="lazy"></figure>
<p>再次启动main方法</p>
<figure data-type="image" tabindex="14"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/300539f6560043dd8a3fe085d28420e6-new-image3c581a2e-196f-4b01-90f1-c27731b4610b.png" alt="" loading="lazy"></figure>
<p>这里GC弹出了一个Allocation Failure分配失败，这个事情发生在PSYoungGen，也就是年轻代中</p>
<p>这时候申请到的内存为18M，空闲内存为4.214195251464844M</p>
<p>我们此时创建一个字节数组看看，执行下面的代码</p>
<pre><code class="language-java">byte[] b = new byte[1 * 1024 * 1024];
System.out.println(&quot;分配了1M空间给数组&quot;);
System.out.println(&quot;Xmx=&quot; + Runtime.getRuntime().maxMemory() / 1024.0 / 1024 + &quot;M&quot;);  //系统的最大空间
System.out.println(&quot;free mem=&quot; + Runtime.getRuntime().freeMemory() / 1024.0 / 1024 + &quot;M&quot;);  //系统的空闲空间
System.out.println(&quot;total mem=&quot; + Runtime.getRuntime().totalMemory() / 1024.0 / 1024 + &quot;M&quot;);
</code></pre>
<figure data-type="image" tabindex="15"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/bdd717d0a3394be7a733760052773374-new-image371b5d59-0020-4091-9874-603c0ab0073d.png" alt="" loading="lazy"></figure>
<p>此时free memory就又缩水了，不过total memory是没有变化的。Java会尽可能将total mem的值维持在最小堆内存大小</p>
<pre><code class="language-java">byte[] b = new byte[10 * 1024 * 1024];
System.out.println(&quot;分配了10M空间给数组&quot;);
System.out.println(&quot;Xmx=&quot; + Runtime.getRuntime().maxMemory() / 1024.0 / 1024 + &quot;M&quot;);  //系统的最大空间
System.out.println(&quot;free mem=&quot; + Runtime.getRuntime().freeMemory() / 1024.0 / 1024 + &quot;M&quot;);  //系统的空闲空间
System.out.println(&quot;total mem=&quot; + Runtime.getRuntime().totalMemory() / 1024.0 / 1024 + &quot;M&quot;);  //当前可用的总空间
</code></pre>
<figure data-type="image" tabindex="16"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/0fd7550ae2144adca8ed2ede12d5fb96-new-image0c31ff20-289d-4088-8c67-a846d0c5d1e0.png" alt="" loading="lazy"></figure>
<p>这时候我们创建了一个10M的字节数据，这时候最小堆内存是顶不住的。我们会发现现在的total memory已经变成了15M，这就是已经申请了一次内存的结果。</p>
<p>此时我们再跑一下这个代码</p>
<pre><code class="language-java">System.gc();
System.out.println(&quot;Xmx=&quot; + Runtime.getRuntime().maxMemory() / 1024.0 / 1024 + &quot;M&quot;);    //系统的最大空间
System.out.println(&quot;free mem=&quot; + Runtime.getRuntime().freeMemory() / 1024.0 / 1024 + &quot;M&quot;);  //系统的空闲空间
System.out.println(&quot;total mem=&quot; + Runtime.getRuntime().totalMemory() / 1024.0 / 1024 + &quot;M&quot;);  //当前可用的总空间
</code></pre>
<figure data-type="image" tabindex="17"><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/4cc44b5d5d1c40c48640ece6a296b1ac-new-image4b57baf6-085b-4150-9c60-ac51b0f815d7.png" alt="" loading="lazy"></figure>
<p>此时我们手动执行了一次fullgc，此时total memory的内存空间又变回5.5M了，此时又是把申请的内存释放掉的结果。</p>
<h3 id="42-调整新生代和老年代的比值">4.2 调整新生代和老年代的比值</h3>
<p>-XX:NewRatio --- 新生代（eden+2*Survivor）和老年代（不包含永久区）的比值</p>
<p>例如：-XX:NewRatio=4，表示新生代:老年代=1:4，即新生代占整个堆的1/5。在Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。</p>
<h3 id="43-调整survivor区和eden区的比值">4.3 调整Survivor区和Eden区的比值</h3>
<p>-XX:SurvivorRatio（幸存代）--- 设置两个Survivor区和eden的比值</p>
<p>例如：8，表示两个Survivor:eden=2:8，即一个Survivor占年轻代的1/10</p>
<h3 id="44-设置年轻代和老年代的大小">4.4 设置年轻代和老年代的大小</h3>
<p>-XX:NewSize --- 设置年轻代大小</p>
<p>-XX:MaxNewSize --- 设置年轻代最大值</p>
<p>可以通过设置不同参数来测试不同的情况，反正最优解当然就是官方的Eden和Survivor的占比为8:1:1，然后在刚刚介绍这些参数的时候都已经附带了一些说明，感兴趣的也可以看看。反正最大堆内存和最小堆内存如果数值不同会导致多次的gc，需要注意。</p>
<h3 id="45-小总结">4.5 小总结</h3>
<p>根据实际事情调整新生代和幸存代的大小，官方推荐新生代占java堆的3/8，幸存代占新生代的1/10</p>
<p>在OOM时，记得Dump出堆，确保可以排查现场问题，通过下面命令你可以输出一个.dump文件，这个文件可以使用VisualVM或者Java自带的Java VisualVM工具。</p>
<pre><code>-Xmx20m -Xms5m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=你要输出的日志路径
</code></pre>
<p>一般我们也可以通过编写脚本的方式来让OOM出现时给我们报个信，可以通过发送邮件或者重启程序等来解决。</p>
<h3 id="46-永久区的设置">4.6 永久区的设置</h3>
<pre><code>-XX:PermSize -XX:MaxPermSize
</code></pre>
<p>初始空间（默认为物理内存的1/64）和最大空间（默认为物理内存的1/4）。也就是说，jvm启动时，永久区一开始就占用了PermSize大小的空间，如果空间还不够，可以继续扩展，但是不能超过MaxPermSize，否则会OOM。</p>
<p>tips：如果堆空间没有用完也抛出了OOM，有可能是永久区导致的。堆空间实际占用非常少，但是永久区溢出 一样抛出OOM。</p>
<h3 id="47-jvm的栈参数调优">4.7 JVM的栈参数调优</h3>
<h4 id="471-调整每个线程栈空间的大小">4.7.1 调整每个线程栈空间的大小</h4>
<p>可以通过-Xss：调整每个线程栈空间的大小</p>
<p>JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。在相同物理内存下,减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右</p>
<h4 id="472-设置线程栈的大小">4.7.2 设置线程栈的大小</h4>
<pre><code>-XXThreadStackSize：
    设置线程栈的大小(0 means use default stack size)
</code></pre>
<p>这些参数都是可以通过自己编写程序去简单测试的，这里碍于篇幅问题就不再提供demo了</p>
<h3 id="48-可以直接跳过了jvm其他参数介绍">4.8 (可以直接跳过了)JVM其他参数介绍</h3>
<p>形形色色的参数很多，就不会说把所有都扯个遍了，因为大家其实也不会说一定要去深究到底。</p>
<h4 id="481-设置内存页的大小">4.8.1 设置内存页的大小</h4>
<pre><code>-XXThreadStackSize：
    设置内存页的大小，不可设置过大，会影响Perm的大小
</code></pre>
<h4 id="482-设置原始类型的快速优化">4.8.2 设置原始类型的快速优化</h4>
<pre><code>-XX:+UseFastAccessorMethods：
    设置原始类型的快速优化
</code></pre>
<h4 id="483-设置关闭手动gc">4.8.3 设置关闭手动GC</h4>
<pre><code>-XX:+DisableExplicitGC：
    设置关闭System.gc()(这个参数需要严格的测试)
</code></pre>
<h4 id="484-设置垃圾最大年龄">4.8.4 设置垃圾最大年龄</h4>
<pre><code>-XX:MaxTenuringThreshold
    设置垃圾最大年龄。如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代.
    对于年老代比较多的应用,可以提高效率。如果将此值设置为一个较大值,
    则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活时间,
    增加在年轻代即被回收的概率。该参数只有在串行GC时才有效.
</code></pre>
<h4 id="485-加快编译速度">4.8.5 加快编译速度</h4>
<pre><code>-XX:+AggressiveOpts
</code></pre>
<p>加快编译速度</p>
<h4 id="486-改善锁机制性能">4.8.6 改善锁机制性能</h4>
<pre><code>-XX:+UseBiasedLocking
</code></pre>
<h4 id="487-禁用垃圾回收">4.8.7 禁用垃圾回收</h4>
<pre><code>-Xnoclassgc
</code></pre>
<h4 id="488-设置堆空间存活时间">4.8.8 设置堆空间存活时间</h4>
<pre><code>-XX:SoftRefLRUPolicyMSPerMB
    设置每兆堆空闲空间中SoftReference的存活时间，默认值是1s。
</code></pre>
<h4 id="489-设置对象直接分配在老年代">4.8.9 设置对象直接分配在老年代</h4>
<pre><code>-XX:PretenureSizeThreshold
    设置对象超过多大时直接在老年代分配，默认值是0。
</code></pre>
<h4 id="4810-设置tlab占eden区的比例">4.8.10 设置TLAB占eden区的比例</h4>
<pre><code>-XX:TLABWasteTargetPercent
    设置TLAB占eden区的百分比，默认值是1% 。 
</code></pre>
<h4 id="4811设置是否优先ygc">4.8.11设置是否优先YGC</h4>
<pre><code>-XX:+CollectGen0First
    设置FullGC时是否先YGC，默认值是false。
</code></pre>
<h2 id="finally">finally</h2>
<p>真的扯了很久这东西，参考了多方的资料，有极客时间的《深入拆解虚拟机》和《Java核心技术面试精讲》，也有百度，也有自己在学习的一些线上课程的总结。希望对你有所帮助，谢谢。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Big Data]]></title>
        <id>https://xuetongyao.github.io/post/big-data/</id>
        <link href="https://xuetongyao.github.io/post/big-data/">
        </link>
        <updated>2022-07-27T12:35:54.000Z</updated>
        <content type="html"><![CDATA[<div align="center">  
<img src="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/logo.jpg" width=""/>
</br>
<p><strong>日更原创大数据领域文章&amp;大数据行业最新动态</strong> </br></p>
<p><strong>打造价值40万Offer朋友圈,数据人的宝藏朋友圈</strong> </br></p>
<p>关注<a href="#%E6%89%AB%E6%88%91%E5%85%B3%E6%B3%A8%E5%85%AC%E4%BC%97%E5%8F%B7">公众号</a>~<br>
加我<a href="#%E6%89%AB%E6%88%91%E5%85%B3%E6%B3%A8%E5%85%AC%E4%BC%97%E5%8F%B7">好友</a>~</p>
</div>
<h2 id="大数据成神之路目录">大数据成神之路目录</h2>
<ul>
<li>图片打不开，点<a href="https://blog.csdn.net/u013411339/article/details/113097759">这里</a></li>
</ul>
<ul>
<li><a href="https://mp.weixin.qq.com/s/MAwD-UJgvIa_dZjmaykqrQ">八千里路云和月|从零到大数据专家学习路径指南</a></li>
<li><a href="https://mp.weixin.qq.com/s/xh4SEX9t-fRVdoiAl0KKSQ">我们在学习Flink的时候，到底在学习什么?</a></li>
<li><a href="https://mp.weixin.qq.com/s/pN0AqNJuFnlLjNW2OonGtA">我们在学习Spark的时候，到底在学习什么？</a></li>
</ul>
<h3 id="大数据开发基础篇">大数据开发基础篇</h3>
<table>
<thead>
<tr>
<th style="text-align:center">🎿Java基础</th>
<th style="text-align:center">📝NIO</th>
<th style="text-align:center">📖并发</th>
<th style="text-align:center">🎸JVM</th>
<th style="text-align:center">💵分布式</th>
<th style="text-align:center">💾Zookeeper</th>
<th style="text-align:center">👊RPC</th>
<th style="text-align:center">🎨Netty</th>
<th style="text-align:center">💻Linux</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="#%E4%B8%80Java%E5%9F%BA%E7%A1%80">Java基础</a></td>
<td style="text-align:center"><a href="#%E4%BA%8CNIO%E5%9F%BA%E7%A1%80">NIO</a></td>
<td style="text-align:center"><a href="#%E4%B8%89Java%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8">并发容器</a></td>
<td style="text-align:center"><a href="#%E5%9B%9BJVM%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E5%92%8C%E9%9D%A2%E8%AF%95%E7%82%B9">JVM</a></td>
<td style="text-align:center"><a href="#%E4%BA%94%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80%E5%92%8C%E5%8E%9F%E7%90%86">分布式</a></td>
<td style="text-align:center"><a href="#%E5%85%AD%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80-zookeeper">zookeeper</a></td>
<td style="text-align:center"><a href="#%E4%B8%83%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80-RPC">RPC</a></td>
<td style="text-align:center"><a href="#%E5%85%AB%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%9F%B3%E4%B9%8B%E7%BD%91%E8%B7%AF%E9%80%9A%E4%BF%A1-Netty">Netty</a></td>
<td style="text-align:center"><a href="/Linux%E5%9F%BA%E7%A1%80/Linux%E5%9F%BA%E7%A1%80%E5%92%8C%E5%91%BD%E4%BB%A4.md">Linux</a></td>
</tr>
</tbody>
</table>
<br/>
<h3 id="大数据框架学习篇">大数据框架学习篇</h3>
<table>
    <tr>
      <th><img width="50px" src="pictures/hadoop.jpg"></th>
      <th><img width="50px" src="pictures/hive.jpg"></th>
      <th><img width="50px" src="pictures/spark.jpg"></th>
      <th><img width="50px" src="pictures/flink.png"></th>
      <th><img width="50px" src="pictures/hbase.png"></th>
      <th><img width="50px" src="pictures/kafka.png"></th>
      <th><img width="50px" src="pictures/zookeeper.jpg"></th>
    </tr>
    <tr>
      <td align="center"><a href="#一hadoop">Hadoop</a></td>
      <td align="center"><a href="#二hive">Hive</a></td>
      <td align="center"><a href="#三spark">Spark</a></td>
      <td align="center"><a href="#四flink">Flink</a></td>
      <td align="center"><a href="#五hbase">HBase</a></td>
      <td align="center"><a href="#六kafka">Kafka</a></td>
      <td align="center"><a href="#七zookeeper">Zookeeper</a></td>
    </tr>
  </table>
<br/>
<h3 id="大数据开发实战进阶篇">大数据开发实战进阶篇</h3>
<p>这里的文章主要是我平时发表在公众号，博客等的文章，精心挑选，以飨读者。</p>
<table>
    <tr>
      <th><img width="50px" src="pictures/flink.png"></th>
      <th><img width="50px" src="pictures/spark.jpg"></th>
      <th><img width="50px" src="pictures/kafka.png"></th>
      <th><img width="50px" src="pictures/olap.jpg"></th>
    </tr>
    <tr>
      <td align="center"><a href="#Flink实战合集">Flink实战进阶</a></td>
      <td align="center"><a href="#Spark实战合集">Spark实战进阶</a></td>
      <td align="center"><a href="#Kafka实战合集">Kafka实战进阶</a></td>
      <td align="center"><a href="#数据仓库实战合集">OLAP实战进阶</a></td>
    </tr>
  </table>
<br/>
<h3 id="大数据开发面试篇">大数据开发面试篇</h3>
<table>
    <tr>
      <th><img width="50px" src="pictures/olap.jpg"></th>
      <th><img width="50px" src="pictures/olap.jpg"></th>
    </tr>
    <tr>
      <td align="center"><a href="#面试系列合集">面试系列合集</a></td>
      <td align="center"><a href="#大数据算法">大数据算法</a></td>
    </tr>
  </table>
<br/> 
<h3 id="公众号2021年大数据精品文章合集">公众号2021年大数据精品文章合集</h3>
<table>
    <tr>
      <th><img width="50px" src="pictures/bg.jpg"></th>
      <th><img width="50px" src="pictures/bg.jpg"></th>
      <th><img width="50px" src="pictures/bg.jpg"></th>
    </tr>
    <tr>
      <td align="center"><a href="#2020精品文章合集">2020精品文章合集</a></td>
      <td align="center"><a href="#2021精品文章合集">2021精品文章合集</a></td>
      <td align="center"><a href="#硬刚系列文章合集">硬刚系列文章合集</a></td>
    </tr>
  </table>
<br/> 
<h2 id="第一部分-大数据开发基础篇">第一部分: 大数据开发基础篇</h2>
<h3 id="一-java基础">一、Java基础</h3>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(%E5%A4%9A%E7%BA%BF%E7%A8%8B).md">大数据成神之路-Java高级特性增强(多线程)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(Synchronized%E5%85%B3%E9%94%AE%E5%AD%97).md">大数据成神之路-Java高级特性增强(Synchronized关键字)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(volatile%E5%85%B3%E9%94%AE%E5%AD%97).md">大数据成神之路-Java高级特性增强(volatile关键字)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(%E9%94%81).md">大数据成神之路-Java高级特性增强(锁)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6).md">大数据成神之路-Java高级特性增强(ArrayList/Vector)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA.md">大数据成神之路-Java高级特性增强(LinkedList)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(HashMap).md">大数据成神之路-Java高级特性增强(HashMap)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(HashSet).md">大数据成神之路-Java高级特性增强(HashSet)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(LinkedHashMap).md">大数据成神之路-Java高级特性增强(LinkedHashMap)</a></li>
</ul>
<h3 id="二-nio基础">二、NIO基础</h3>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA-NIO.md">大数据成神之路-Java高级特性增强-NIO大纲</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/NIO%E6%A6%82%E8%A7%88.md">NIO概览</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/Java%20NIO%E4%B9%8BBuffer(%E7%BC%93%E5%86%B2%E5%8C%BA).md">Java NIO之Buffer(缓冲区)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/Java%20NIO%E4%B9%8BChannel(%E9%80%9A%E9%81%93).md">Java NIO之Channel(通道)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/Java%20NIO%E4%B9%8BSelector(%E9%80%89%E6%8B%A9%E5%99%A8).md">ava NIO之Selector(选择器)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA/Java%20NIO%E4%B9%8B%E6%8B%A5%E6%8A%B1Path%E5%92%8CFiles.md">Java NIO之拥抱Path和Files</a></li>
</ul>
<h3 id="三-java并发容器">三、Java并发容器</h3>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E5%A4%A7%E7%BA%B2).md">大数据成神之路-Java高级特性增强(并发容器大纲)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(LinkedBlockingQueue).md">大数据成神之路-Java高级特性增强(LinkedBlockingQueue)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(LinkedBlockingDeque).md">大数据成神之路-Java高级特性增强(LinkedBlockingDeque)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(CopyOnWriteArraySet).md">大数据成神之路-Java高级特性增强(CopyOnWriteArraySet)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(CopyOnWriteArrayList).md">大数据成神之路-Java高级特性增强(CopyOnWriteArrayList)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(ConcurrentSkipListSet).md">大数据成神之路-Java高级特性增强(ConcurrentSkipListSet)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(ConcurrentSkipListMap).md">大数据成神之路-Java高级特性增强(ConcurrentSkipListMap)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(ConcurrentLinkedQueue).md">大数据成神之路-Java高级特性增强(ConcurrentLinkedQueue)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(ConcurrentHashMap).md">大数据成神之路-Java高级特性增强(ConcurrentHashMap)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF-Java%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%A2%9E%E5%BC%BA(ArrayBlockingQueue).md">大数据成神之路-Java高级特性增强(ArrayBlockingQueue)</a></li>
</ul>
<h3 id="四-jvm深度解析和面试点">四、JVM深度解析和面试点</h3>
<h5 id="先来10篇基础热身">先来10篇基础热身</h5>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84.md">JVM内存结构</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/HotSpot%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AF%B9%E8%B1%A1%E6%8E%A2%E7%A7%98.md">HotSpot虚拟机对象探秘</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AD%96%E7%95%A5%E4%B8%8E%E7%AE%97%E6%B3%95.md">垃圾收集策略与算法</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/HotSpot%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8.md">HotSpot垃圾收集器</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6%E7%AD%96%E7%95%A5.md">内存分配与回收策略</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/JVM%20%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98.md">JVM性能调优</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84.md">类文件结构</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%9A%84%E6%97%B6%E6%9C%BA.md">类加载的时机</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%9A%84%E8%BF%87%E7%A8%8B.md">类加载的过程</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8.md">类加载器</a></li>
</ul>
<h5 id="再来5篇详细解说">再来5篇详细解说</h5>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/jvm%E7%B3%BB%E5%88%97(%E4%B8%80)java%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6.md">java类的加载机制</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/jvm%E7%B3%BB%E5%88%97(%E4%BA%8C)JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84.md">JVM内存结构</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/jvm%E7%B3%BB%E5%88%97(%E4%B8%89)GC%E7%AE%97%E6%B3%95%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8.md">GC算法 垃圾收集器</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/jvm%E7%B3%BB%E5%88%97(%E5%9B%9B)jvm%E8%B0%83%E4%BC%98-%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8%EF%BC%88jps%20jstat%20jmap%20jhat%20jstack%20jinfo%EF%BC%89.md">jvm调优-命令大全</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/JVM/jvm%E7%B3%BB%E5%88%97(%E4%BA%94)Java%20GC%20%E5%88%86%E6%9E%90.md">Java GC 分析</a></li>
</ul>
<h3 id="五-分布式理论基础和原理">五、分布式理论基础和原理</h3>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.md">分布式系统的一些基本概念</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80%E4%B8%80%EF%BC%9A%20%E4%B8%80%E8%87%B4%E6%80%A7%E3%80%812PC%E5%92%8C3PC.md">分布式系统理论基础一： 一致性、2PC和3PC</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80%E4%BA%8C-CAP.md">分布式系统理论基础二-CAP</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80%E4%B8%89-%E6%97%B6%E9%97%B4%E3%80%81%E6%97%B6%E9%92%9F%E5%92%8C%E4%BA%8B%E4%BB%B6%E9%A1%BA%E5%BA%8F.md">分布式系统理论基础三-时间、时钟和事件顺序</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%BF%9B%E9%98%B6%20-%20Paxos.md">分布式系统理论进阶 - Paxos</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%BF%9B%E9%98%B6%20-%20Raft%E3%80%81Zab.md">分布式系统理论进阶 - Raft、Zab</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%BF%9B%E9%98%B6%EF%BC%9A%E9%80%89%E4%B8%BE%E3%80%81%E5%A4%9A%E6%95%B0%E6%B4%BE%E5%92%8C%E7%A7%9F%E7%BA%A6.md">分布式系统理论进阶：选举、多数派和租约</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md">分布式锁的解决方案</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88(%E4%BA%8C).md">分布式锁的解决方案(二)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md">分布式事务的解决方案</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%94%9F%E6%88%90%E5%99%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.md">分布式ID生成器解决方案</a></li>
</ul>
<h3 id="六-大数据框架开发基础-zookeeper">六、大数据框架开发基础-Zookeeper</h3>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/zookeeeper/zk%E5%AE%89%E8%A3%85%E5%92%8C%E8%BF%90%E8%A1%8C.md">安装和运行</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/zookeeeper/zk%E6%9C%8D%E5%8A%A1.md">zookeeper服务</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/zookeeeper/ZooKeeper%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F.md">zookeeper应用程序</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/zookeeeper/zk%E5%BC%80%E5%8F%91%E5%AE%9E%E4%BE%8B.md">zookeeper开发实例</a></li>
<li><a href="http://www.importnew.com/23237.html">zookeeper集群构建</a></li>
</ul>
<h3 id="七-大数据框架开发基础-rpc">七、大数据框架开发基础-RPC</h3>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/RPC/RPC%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D.md">RPC简单介绍</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/RPC/RPC%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E6%A1%86%E6%9E%B6.md">RPC的原理和框架</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/RPC/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84RPC.md">手把手教你实现一个简单的RPC</a></li>
</ul>
<h3 id="八-大数据框架基石之网路通信-netty">八、大数据框架基石之网路通信-Netty</h3>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/%E5%85%B3%E4%BA%8ENetty%E6%88%91%E4%BB%AC%E9%83%BD%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E4%BB%80%E4%B9%88.md">关于Netty我们都需要知道什么</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/Netty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E6%A6%82%E8%BF%B0%E7%AF%87.md">Netty源码解析-概述篇</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/Netty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%901-Buffer.md">Netty源码解析1-Buffer</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/Netty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%902-Reactor.md">Netty源码解析2-Reactor</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/Netty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%903-Pipeline.md">Netty源码解析3-Pipeline</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/Netty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%904-Handler%E7%BB%BC%E8%BF%B0.md">Netty源码解析4-Handler综述</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/Netty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%905-ChannelHandler.md">Netty源码解析5-ChannelHandler</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/Netty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%906-ChannelHandler%E5%AE%9E%E4%BE%8B%E4%B9%8BLoggingHandler.md">Netty源码解析6-ChannelHandler实例之LoggingHandler</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/Netty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%907-ChannelHandler%E5%AE%9E%E4%BE%8B%E4%B9%8BTimeoutHandler.md">Netty源码解析7-ChannelHandler实例之TimeoutHandler</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/Netty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%908-ChannelHandler%E5%AE%9E%E4%BE%8B%E4%B9%8BCodecHandler.md">Netty源码解析8-ChannelHandler实例之CodecHandler</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Netty/Netty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%909-ChannelHandler%E5%AE%9E%E4%BE%8B%E4%B9%8BMessageToByteEncoder.md">Netty源码解析9-ChannelHandler实例之MessageToByteEncoder</a></li>
</ul>
<h2 id="第二部分大数据框架学习篇">第二部分:大数据框架学习篇</h2>
<h3 id="一-hadoop">一、Hadoop</h3>
<ol>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hadoop-HDFS.md">分布式文件存储系统 —— HDFS</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hadoop-MapReduce.md">分布式计算框架 —— MapReduce</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hadoop-YARN.md">集群资源管理器 —— YARN</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/Hadoop%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.md">Hadoop 单机伪集群环境搭建</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/Hadoop%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.md">Hadoop 集群环境搭建</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/HDFS%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4.md">HDFS 常用 Shell 命令</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/HDFS-Java-API.md">HDFS Java API 的使用</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/%E5%9F%BA%E4%BA%8EZookeeper%E6%90%AD%E5%BB%BAHadoop%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4.md">基于 Zookeeper 搭建 Hadoop 高可用集群</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Hadoop/Hadoop%E6%9E%81%E7%AE%80%E5%85%A5%E9%97%A8.md">Hadoop级简入门</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Hadoop/MapReduce%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%92%8C%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86.md">MapReduce编程模型和计算框架架构原理</a></li>
</ol>
<h3 id="二-hive">二、Hive</h3>
<ol>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hive%E7%AE%80%E4%BB%8B%E5%8F%8A%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5.md">Hive 简介及核心概念</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/Linux%E7%8E%AF%E5%A2%83%E4%B8%8BHive%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2.md">Linux 环境下 Hive 的安装部署</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/HiveCLI%E5%92%8CBeeline%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8.md">Hive CLI 和 Beeline 命令行的基本使用</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hive%E5%B8%B8%E7%94%A8DDL%E6%93%8D%E4%BD%9C.md">Hive 常用 DDL 操作</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hive%E5%88%86%E5%8C%BA%E8%A1%A8%E5%92%8C%E5%88%86%E6%A1%B6%E8%A1%A8.md">Hive 分区表和分桶表</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hive%E8%A7%86%E5%9B%BE%E5%92%8C%E7%B4%A2%E5%BC%95.md">Hive 视图和索引</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hive%E5%B8%B8%E7%94%A8DML%E6%93%8D%E4%BD%9C.md">Hive常用 DML 操作</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hive%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E8%AF%A6%E8%A7%A3.md">Hive 数据查询详解</a></li>
</ol>
<h3 id="三-spark">三、Spark</h3>
<p><strong>Spark Core :</strong></p>
<ol>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spark%E7%AE%80%E4%BB%8B.md">Spark 简介</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/Spark%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.md">Spark 开发环境搭建</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spark_RDD.md">弹性式数据集 RDD</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spark_Transformation%E5%92%8CAction%E7%AE%97%E5%AD%90.md">RDD 常用算子详解</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spark%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F%E4%B8%8E%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4.md">Spark 运行模式与作业提交</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spark%E7%B4%AF%E5%8A%A0%E5%99%A8%E4%B8%8E%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F.md">Spark 累加器与广播变量</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/Spark%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.md">基于 Zookeeper 搭建 Spark 高可用集群</a></li>
</ol>
<p><strong>Spark SQL :</strong></p>
<ol>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/SparkSQL_Dataset%E5%92%8CDataFrame%E7%AE%80%E4%BB%8B.md">DateFrame 和 DataSet </a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spark_Structured_API%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8.md">Structured API 的基本使用</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/SparkSQL%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E6%BA%90.md">Spark SQL 外部数据源</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/SparkSQL%E5%B8%B8%E7%94%A8%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0.md">Spark SQL 常用聚合函数</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/SparkSQL%E8%81%94%E7%BB%93%E6%93%8D%E4%BD%9C.md">Spark SQL JOIN 操作</a></li>
</ol>
<p><strong>Spark Streaming ：</strong></p>
<ol>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spark_Streaming%E4%B8%8E%E6%B5%81%E5%A4%84%E7%90%86.md">Spark Streaming 简介</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spark_Streaming%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C.md">Spark Streaming 基本操作</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spark_Streaming%E6%95%B4%E5%90%88Flume.md">Spark Streaming 整合 Flume</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spark_Streaming%E6%95%B4%E5%90%88Kafka.md">Spark Streaming 整合 Kafka</a></li>
</ol>
<h2 id="四-flink">四、Flink</h2>
<ol>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Flink%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E7%BB%BC%E8%BF%B0.md">Flink 核心概念综述</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Flink%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.md">Flink 开发环境搭建</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Flink_Data_Source.md">Flink Data Source</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Flink_Data_Transformation.md">Flink Data Transformation</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Flink_Data_Sink.md">Flink Data Sink</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Flink_Windows.md">Flink 窗口模型</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Flink%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86%E4%B8%8E%E6%A3%80%E6%9F%A5%E7%82%B9%E6%9C%BA%E5%88%B6.md">Flink 状态管理与检查点机制</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/Flink_Standalone_Cluster.md">Flink Standalone 集群部署</a></li>
</ol>
<h4 id="flink当前最火的实时计算引擎-入门篇">Flink当前最火的实时计算引擎-入门篇</h4>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/Flink%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83(%E5%85%A5%E9%97%A8%E7%AF%871)-Flink%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F.md">Flink从入门到放弃(入门篇1)-Flink是什么</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/Flink%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83(%E5%85%A5%E9%97%A8%E7%AF%872)-%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%26%E6%9E%84%E5%BB%BA%E7%AC%AC%E4%B8%80%E4%B8%AAFlink%E5%BA%94%E7%94%A8.md">Flink从入门到放弃(入门篇2)-本地环境搭建&amp;构建第一个Flink应用</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/Flink%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83(%E5%85%A5%E9%97%A8%E7%AF%873)-DataSetAPI.md">Flink从入门到放弃(入门篇3)-DataSetAPI</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/Flink%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83(%E5%85%A5%E9%97%A8%E7%AF%874)-DataStreamAPI.md">Flink从入门到放弃(入门篇4)-DataStreamAPI</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/Flink%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.md">Flink集群部署</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/6-Flink%E9%87%8D%E5%90%AF%E7%AD%96%E7%95%A5.md">Flink重启策略</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/7-Flink%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98.md">Flink的分布式缓存</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/8-Flink%E4%B8%AD%E7%9A%84%E7%AA%97%E5%8F%A3.md">Flink中的窗口</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/9-Flink%E4%B8%AD%E7%9A%84Time.md">Flink中的Time</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/10-Flink%E9%9B%86%E7%BE%A4%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8(%E6%90%AD%E5%BB%BA%E7%AF%87%E8%A1%A5%E5%85%85).md">Flink集群搭建的HA</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/11-%E6%97%B6%E9%97%B4%E6%88%B3%E5%92%8C%E6%B0%B4%E5%8D%B0.md">Flink中的时间戳和水印</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/12-Broadcast%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F.md">Flink广播变量</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/13-Flink-Kafka-Connector.md">Flink-Kafka-Connector</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/14-Flink-Table-%26-SQL.md">Flink-Table-&amp;-SQL实战</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/15-Flink%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%E4%B9%8B%E5%AE%9E%E6%97%B6%E7%83%AD%E9%94%80%E6%8E%92%E8%A1%8C.md">15-Flink实战项目之实时热销排行</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/16-Flink-Redis-Sink.md">16-Flink-Redis-Sink</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink/17-Flink%E6%B6%88%E8%B4%B9Kafka%E5%86%99%E5%85%A5Mysql.md">17-Flink消费Kafka写入Mysql</a></li>
</ul>
<h4 id="flink当前最火的实时计算引擎-放弃篇">Flink当前最火的实时计算引擎-放弃篇</h4>
<ul>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink%E6%BC%AB%E8%B0%88%E7%B3%BB%E5%88%97/Apache-Flink%E6%BC%AB%E8%B0%88%E7%B3%BB%E5%88%97(1)-%E6%A6%82%E8%BF%B0.md">Flink漫谈系列1-概述</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink%E6%BC%AB%E8%B0%88%E7%B3%BB%E5%88%97/Apache-Flink-%E6%BC%AB%E8%B0%88%E7%B3%BB%E5%88%97(02)-Watermark.md">Flink漫谈系列2-watermark</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Flink%E6%BC%AB%E8%B0%88%E7%B3%BB%E5%88%97/Apache-Flink-%E6%BC%AB%E8%B0%88%E7%B3%BB%E5%88%97(03)-State.md">Flink漫谈系列3-state</a></li>
</ul>
<h2 id="五-hbase">五、HBase</h2>
<ol>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hbase%E7%AE%80%E4%BB%8B.md">Hbase 简介</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hbase%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.md">HBase 系统架构及数据结构</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/HBase%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.md">HBase 基本环境搭建 (Standalone /pseudo-distributed mode)</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/HBase%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.md">HBase 集群环境搭建</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hbase_Shell.md">HBase 常用 Shell 命令</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hbase_Java_API.md">HBase Java API</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hbase%E8%BF%87%E6%BB%A4%E5%99%A8%E8%AF%A6%E8%A7%A3.md">Hbase 过滤器详解</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hbase%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E8%AF%A6%E8%A7%A3.md">HBase 协处理器详解</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hbase%E5%AE%B9%E7%81%BE%E4%B8%8E%E5%A4%87%E4%BB%BD.md">HBase 容灾与备份</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Hbase%E7%9A%84SQL%E4%B8%AD%E9%97%B4%E5%B1%82_Phoenix.md">HBase的 SQL 中间层 —— Phoenix</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Spring+Mybtais+Phoenix%E6%95%B4%E5%90%88.md">Spring/Spring Boot 整合 Mybatis + Phoenix</a></li>
</ol>
<h2 id="六-kafka">六、Kafka</h2>
<p><strong>Kafka基本原理 ：</strong></p>
<ol>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Kafka%E7%AE%80%E4%BB%8B.md">Kafka 简介</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/%E5%9F%BA%E4%BA%8EZookeeper%E6%90%AD%E5%BB%BAKafka%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4.md">基于 Zookeeper 搭建 Kafka 高可用集群</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E8%AF%A6%E8%A7%A3.md">Kafka 生产者详解</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%A6%E8%A7%A3.md">Kafka 消费者详解</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Kafka%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6.md">深入理解 Kafka 副本机制</a></li>
</ol>
<p><strong>分布式消息队列Kafka原理及与流式计算的集成 ：</strong></p>
<ol>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Kafka/Apache-Kafka%E7%AE%80%E4%BB%8B.md">Apache-Kafka简介</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Kafka/Apache-Kafka%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5.md">Apache-Kafka核心概念</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Kafka/Apache-Kafka%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8.md">Apache-Kafka安装和使用</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Kafka/Apache-Kafka%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.md">Apache-Kafka编程实战</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Kafka/Apache-Kafka%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E5%92%8C%E6%B5%81%E7%A8%8B(%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8).md">Apache-Kafka核心组件和流程(副本管理器)</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Kafka/Apache-Kafka%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E5%92%8C%E6%B5%81%E7%A8%8B-%E5%8D%8F%E8%B0%83%E5%99%A8.md">Apache-Kafka核心组件和流程-协调器</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Kafka/Apache-Kafka%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E5%92%8C%E6%B5%81%E7%A8%8B-%E6%8E%A7%E5%88%B6%E5%99%A8.md">Apache-Kafka核心组件和流程-控制器</a></li>
<li><a href="https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/Kafka/Apache-Kafka%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E5%92%8C%E6%B5%81%E7%A8%8B-%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E5%99%A8.md">Apache-Kafka核心组件和流程-日志管理器</a></li>
</ol>
<h2 id="七-zookeeper">七、Zookeeper</h2>
<ol>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Zookeeper%E7%AE%80%E4%BB%8B%E5%8F%8A%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5.md">Zookeeper 简介及核心概念</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/installation/Zookeeper%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83%E5%92%8C%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.md">Zookeeper 单机环境和集群环境搭建</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Zookeeper%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4.md">Zookeeper 常用 Shell 命令</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Zookeeper_Java%E5%AE%A2%E6%88%B7%E7%AB%AFCurator.md">Zookeeper Java 客户端 —— Apache Curator</a></li>
<li><a href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/Zookeeper_ACL%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6.md">Zookeeper  ACL 权限控制</a></li>
</ol>
<h2 id="八-大数据算法">八、大数据算法</h2>
<h4 id="大数据算法">大数据算法</h4>
<p><a href="https://blog.csdn.net/u013411339/article/details/113429172">大数据算法</a></p>
<h2 id="第三部分大数据开发实战进阶篇">第三部分:大数据开发实战进阶篇</h2>
<h3 id="一-flink实战进阶文章合集">一、Flink实战进阶文章合集</h3>
<h4 id="flink实战合集">Flink实战合集</h4>
<p><a href="%E5%AE%9E%E6%88%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/Flink%E5%AE%9E%E6%88%98.md">点我查看Flink实战合集</a></p>
<ol>
<li><a href="https://mp.weixin.qq.com/s/fnx2GnbCWNcaptVPsSp7dw">菜鸟供应链实时技术架构演进</a></li>
<li><a href="https://mp.weixin.qq.com/s/s6YFOINMw9TKg-QVOkZT9A">趣头条实战-基于Flink+ClickHouse构建实时数据平台</a></li>
<li><a href="https://mp.weixin.qq.com/s/NLwYpjzNgkR8O5zRg7RCoQ">ApacheFlink新场景-OLAP引擎</a></li>
<li><a href="https://mp.weixin.qq.com/s/d_jzHb-b7LEGNz1CN34zMg">说说Flink DataStream的八种物理分区逻辑</a></li>
<li><a href="https://mp.weixin.qq.com/s/eHPQx3kGKnhXeZpLhUNvng">State Processor API：如何读取，写入和修改 Flink 应用程序的状态</a></li>
<li><a href="https://mp.weixin.qq.com/s/Q4k0xgPCOUQ-A2DQ-XaJgw">Flink滑动窗口原理与细粒度滑动窗口的性能问题</a></li>
<li><a href="https://mp.weixin.qq.com/s/Ppz5740WTB7lTTLHNL72Tg">基于Flink快速开发实时TopN</a></li>
<li><a href="https://mp.weixin.qq.com/s/kLjEceslHQxDDi3mRrjR-g">使用 Apache Flink 开发实时 ETL</a></li>
<li><a href="https://mp.weixin.qq.com/s/kZQRQBVjYiXKfMhKM7SSqQ">Flink Source/Sink探究与实践：RocketMQ数据写入HBase</a></li>
<li><a href="https://mp.weixin.qq.com/s/GDylIWCDnjpX9_X6T9NmMA">Spark/Flink广播实现作业配置动态更新</a></li>
<li><a href="https://mp.weixin.qq.com/s/A6CIPsGf-aCWXkB7O-toVw">Flink全链路延迟的测量方式</a></li>
<li><a href="https://mp.weixin.qq.com/s/5BlCzguYiEP1h48jwkos2w">Flink原理-Flink中的数据抽象及数据交换过程</a></li>
<li><a href="https://mp.weixin.qq.com/s/UkpkS_JiRGR0ibZKYechbg">Flink SQL Window源码全解析</a></li>
<li><a href="https://mp.weixin.qq.com/s/e-lyViKV4NPmOVwA5Jn6Qw">Flink DataStream维度表Join的简单方案</a></li>
<li><a href="https://mp.weixin.qq.com/s/cBMrF814jGtEFdve0Lrr6g">Apache Flink的内存管理</a></li>
<li><a href="https://mp.weixin.qq.com/s/e0BQoY5Y79NHhcQ9MqltFQ">Flink1.9整合Kafka实战</a></li>
<li><a href="https://mp.weixin.qq.com/s/KbhmJCW80UmeFwRxM3jerg">Apache Flink在小米的发展和应用</a></li>
<li><a href="https://mp.weixin.qq.com/s/BPzOBz7oTfn2_yW8tevEEw">基于Kafka+Flink+Redis的电商大屏实时计算案例</a></li>
<li><a href="https://mp.weixin.qq.com/s/TsU_5N0Csfw-afN9AdAihw">Flink实战-壳找房基于Flink的实时平台建设</a></li>
<li><a href="https://mp.weixin.qq.com/s/0M8XLTgpj6jWNcokNhyxAw">用Flink取代Spark Streaming！知乎实时数仓架构演进</a></li>
<li><a href="https://mp.weixin.qq.com/s/Oom-TaEsT6GKGs95dJil5Q">Flink实时数仓-美团点评实战</a></li>
<li><a href="https://mp.weixin.qq.com/s/13w43iYT3-riIj757HPGxw">来将可留姓名？Flink最强学习资源合集!</a></li>
<li><a href="https://mp.weixin.qq.com/s/0VXqbzLBj5rZjjf4jAc3UQ">数据不撒谎，Flink-Kafka性能压测全记录!</a></li>
<li><a href="https://mp.weixin.qq.com/s/2_8uOdDJwzYxUP-NLh6VhA">菜鸟在物流场景中基于Flink的流计算实践</a></li>
<li><a href="https://mp.weixin.qq.com/s/Rhgt33y102WzR9-Zq15iVQ">基于Flink构建实时数据仓库</a></li>
<li><a href="https://mp.weixin.qq.com/s/sjRV_F9tXEfqKL_00rJc7w">Flink/Spark 如何实现动态更新作业配置</a></li>
</ol>
<h3 id="二-spark实战进阶文章合集">二、Spark实战进阶文章合集</h3>
<h4 id="spark实战合集">Spark实战合集</h4>
<p><a href="%E5%AE%9E%E6%88%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/Spark%E5%AE%9E%E6%88%98.md">点我查看Spark实战合集</a></p>
<ol>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486986&amp;idx=1&amp;sn=422d1a3c11c72ff97b32cc01142839f4&amp;chksm=fd3d489fca4ac1895242ab94b932b12c65dc57b5f3a16acc7084dc8a189e9026290245a64c4f&amp;token=1999457569&amp;lang=zh_CN#rd">如果你在准备面试，好好看看这130道题</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486981&amp;idx=1&amp;sn=9c8fc4c127d7e6108ac4e171e750d490&amp;chksm=fd3d4890ca4ac186614f0dda8ffb2d35693a925b03861a01769c898652b53d0d436bca05ea12&amp;token=1999457569&amp;lang=zh_CN#rd">ORC文件存储格式的深入探究</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486938&amp;idx=1&amp;sn=83347b444fc721442d2b4e1a58eca0e8&amp;chksm=fd3d4b4fca4ac2597abd4a39a21dea83220858ae5efd1ae287b471bb9970f165b4854426f4c2&amp;token=1999457569&amp;lang=zh_CN#rd">基于SparkStreaming+Kafka+HBase实时点击流案例</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486931&amp;idx=1&amp;sn=9c3f3d6a677ed2aa6cc508046ca6da78&amp;chksm=fd3d4b46ca4ac25044d6033458d3b43e7d1f50f447bded4eed8b246991cf620c91919c51e35b&amp;token=1999457569&amp;lang=zh_CN#rd">HyperLogLog函数在Spark中的高级应用</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486931&amp;idx=2&amp;sn=1c5987f3bad7a805895484ebfd683e11&amp;chksm=fd3d4b46ca4ac250d31502a76f0cfd02ebea29d1161b9e9faec23ea6aa8947d0dd7d4268427f&amp;token=1999457569&amp;lang=zh_CN#rd">我们常说的海量小文件的根源是什么？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486904&amp;idx=1&amp;sn=5f4b673a87497a9c1dc9d7ce253994f3&amp;chksm=fd3d4b2dca4ac23b9850c54d62ebe8be5920cbd4a491a46a0325e1fbbd91f6b1aef9adf2f638&amp;token=1999457569&amp;lang=zh_CN#rd">Structured Streaming | Apache Spark中处理实时数据的声明式API</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486765&amp;idx=1&amp;sn=516a32e8c1e9842606a7670862ec7e97&amp;chksm=fd3d4bb8ca4ac2ae24e315083cdb195fdf897e1c3cce69d2c94183d5c20c1af1bfbe0e5480fd&amp;token=1999457569&amp;lang=zh_CN#rd">Spark面对OOM问题的解决方法及优化总结</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486761&amp;idx=1&amp;sn=959aaa5266307a64181631ba1ae46e86&amp;chksm=fd3d4bbcca4ac2aad8a3958da40c22e565997180c635bb6c32a9b4aa7e82a74a56423320c65a&amp;token=1999457569&amp;lang=zh_CN#rd">Spark 动态资源分配(Dynamic Resource Allocation) 解析</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486668&amp;idx=1&amp;sn=981028fdcf937ba45b3914e2d48b94db&amp;chksm=fd3d4a59ca4ac34f089ff1dce9542a0f481a73439acec9223fa2d776ff3f2eaec498cc543d06&amp;token=1999457569&amp;lang=zh_CN#rd">Apache Spark在海致大数据平台中的优化实践</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486644&amp;idx=1&amp;sn=d2637a1e918c2b1be4c9fe3d74f75a92&amp;chksm=fd3d4a21ca4ac3377cc8836939cc041cf934bb57f73b6b618fd1de608495d86e278c1c7e4cdc&amp;token=1999457569&amp;lang=zh_CN#rd">Spark/Flink广播实现作业配置动态更新</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486629&amp;idx=2&amp;sn=54d05858d659756a46b9be36b7b63ee5&amp;chksm=fd3d4a30ca4ac326f69ba9b7cf6a82418afd31193e96aa28346779264a7d8a1df4c7a3a31fba&amp;token=1999457569&amp;lang=zh_CN#rd">Spark SQL读数据库时不支持某些数据类型的问题</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486586&amp;idx=1&amp;sn=e35def6429adaada0910b91eed8d7b1f&amp;chksm=fd3d4aefca4ac3f9918d57b947d4bc8f71afd9d7666ffe28e3660e5efab332c714bef0879a90&amp;token=1999457569&amp;lang=zh_CN#rd">这个面试问题很难么 | 如何处理大数据中的数据倾斜</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486582&amp;idx=1&amp;sn=7b6291dedb2e6892342e1ed705bdfb2e&amp;chksm=fd3d4ae3ca4ac3f591f297635c0ff8e63e3deb6d6aec72c8fb18e19f8f6fcdb5cd2abcd37d09&amp;token=1999457569&amp;lang=zh_CN#rd">Spark难点 | Join的实现原理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486577&amp;idx=1&amp;sn=49fd0138ad9837192b6eb78cbdc478e6&amp;chksm=fd3d4ae4ca4ac3f2aec91f40435d1eb55a9e497fe7d8ab9ad52396838f467879ac56cb83c9c2&amp;token=1999457569&amp;lang=zh_CN#rd">面试注意点 | Spark&amp;Flink的区别拾遗</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486514&amp;idx=1&amp;sn=a3c3084b8a797a0889d7583fb10d70c9&amp;chksm=fd3d4aa7ca4ac3b12416ba8269041032a515b7a4e71bda1709e359a15a04df4f638738c6e01a&amp;token=1999457569&amp;lang=zh_CN#rd">Spark Checkpoint的运行原理和源码实现</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486505&amp;idx=1&amp;sn=91316d3aa5a99945ccd992c0a98e500d&amp;chksm=fd3d4abcca4ac3aa26f051504244239ff1ab48eb71cf01c14f689eb4767c121b1477d93b60ea&amp;token=1999457569&amp;lang=zh_CN#rd">阿里云Spark Shuffle的优化</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486485&amp;idx=1&amp;sn=999b84e0ac87f2aa1be4870921279a21&amp;chksm=fd3d4a80ca4ac39695d9307582ff58938180d0c5b12f6db84ddae933edb345b0cbe46f6284ed&amp;token=1999457569&amp;lang=zh_CN#rd">使用Kafka+Spark+Cassandra构建实时处理引擎</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486477&amp;idx=1&amp;sn=21394cca8fe279bbc2032d48f65672f6&amp;chksm=fd3d4a98ca4ac38e3bf9700cfe65131fffadbbf9493ccc658b3e7be97ddb6665ad41a70f67f9&amp;token=1999457569&amp;lang=zh_CN#rd">基于HBase和Spark构建企业级数据处理平台</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486419&amp;idx=1&amp;sn=3bc8af144370a602817ca87415fe525d&amp;chksm=fd3d4d46ca4ac450ec6f1ac84b2f3162071eb85221464bdb1976178ca2363cd2acb3d63d401c&amp;token=1999457569&amp;lang=zh_CN#rd">SparkSQL在字节跳动的应用实践和优化实战</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486369&amp;idx=1&amp;sn=9a760114ed2c7509e191ad29370eecce&amp;chksm=fd3d4d34ca4ac4222d310c37fb67bcaafd5425e1a16c43434c4d1fea403756e266de21b83181&amp;token=1999457569&amp;lang=zh_CN#rd">SparkRDD转DataSet/DataFrame的一个深坑</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486332&amp;idx=1&amp;sn=ecbe21981c5c36f6c420755e8d63fb8f&amp;chksm=fd3d4de9ca4ac4ff1b11093432f444c9e4f66c45a6e01155d69cface70456fb418a98163757d&amp;token=1999457569&amp;lang=zh_CN#rd">Spark和Flink的状态管理State的区别和应用</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486328&amp;idx=1&amp;sn=b5d53e0007032114fb277e440e5ce4bf&amp;chksm=fd3d4dedca4ac4fbb5026338af7dbbfe1d845fdc11e7e2279035dddc8ff0b6dd24c32be129ce&amp;token=1999457569&amp;lang=zh_CN#rd">Kafka+Spark Streaming管理offset的几种方法</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486322&amp;idx=2&amp;sn=00ddcd16109249e45a70233d5ef959ba&amp;chksm=fd3d4de7ca4ac4f15f85d9a2873c5d1070af3bb929479bd66f7a0dc89ac0777b6960cbce5970&amp;token=1999457569&amp;lang=zh_CN#rd">从 PageRank Example谈Spark应用程序调优</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485574&amp;idx=1&amp;sn=723c02562ee1f44e88c389d6ac8a2c87&amp;chksm=fd3d4e13ca4ac705ad892ada2c68792c906946f271bb1e6afd15a93749f8f87d0ea967ba2d37&amp;token=1999457569&amp;lang=zh_CN#rd">Spark调优|SparkSQL参数调优</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485507&amp;idx=1&amp;sn=2cab7a3714ce4e16351b8edcde95e777&amp;chksm=fd3d4ed6ca4ac7c058d820f36b2d03c3ccddc293e1035b6897e99544e55931f6cd6a2f343647&amp;token=1999457569&amp;lang=zh_CN#rd">Flink/Spark 如何实现动态更新作业配置</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485361&amp;idx=1&amp;sn=8348203b6f17662a64fa5d412de97296&amp;chksm=fd3d4124ca4ac8329bac00fae705f37c08236d583e9900f268796d463be9323d82ba4b8b1554&amp;token=1999457569&amp;lang=zh_CN#rd">Stream SQL的执行原理与Flink的实现</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485321&amp;idx=1&amp;sn=13e73673fb29bd134ab79e03a369288c&amp;chksm=fd3d411cca4ac80ac68204d18aee55b95cadde7bf18cc2f8a549fc0b6ff4ec4db570190566c3&amp;token=1999457569&amp;lang=zh_CN#rd">Spark将Dataframe数据写入Hive分区表的方案</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485316&amp;idx=1&amp;sn=8a7a02023f15324885de7a5c93d4dd94&amp;chksm=fd3d4111ca4ac807f34e1fa03023494d46f3770c035290ddefe1333419453a9258f504584aee&amp;token=1999457569&amp;lang=zh_CN#rd">Spark中几种ShuffleWriter的区别你都知道吗？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485217&amp;idx=1&amp;sn=3ce9fa8ad179c008754873129e51fbe7&amp;chksm=fd3d41b4ca4ac8a25957fc9541437e6546fc2926df2908bad5adbd30a6cecf9f797fef74f894&amp;token=1999457569&amp;lang=zh_CN#rd">SparkSQL的3种Join实现</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485138&amp;idx=1&amp;sn=8f71070470c8963e7c973b5f10bf3c03&amp;chksm=fd3d4047ca4ac951981f7f0fa08f9f6a1821270441b5008da28115b67020b01ef2936b5f1e88&amp;token=1999457569&amp;lang=zh_CN#rd">周期性清除Spark Streaming流状态的方法</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485119&amp;idx=1&amp;sn=fd172b1f9c9ef99eac2ed976a7d4459f&amp;chksm=fd3d402aca4ac93ced929dfb9b3d785fa5e00d82939b4ea7ed31e68096b87f31a0d11c5f7414&amp;token=1999457569&amp;lang=zh_CN#rd">Structured Streaming之状态存储解析</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485105&amp;idx=1&amp;sn=0bea228e6845d04739937b75bd2f8d9a&amp;chksm=fd3d4024ca4ac9322cae55569b7bdc6d8546dc9c4583f25801d3820ab3b30094c50816c7c1c8&amp;token=1999457569&amp;lang=zh_CN#rd">Spark SQL重点知识总结</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485058&amp;idx=1&amp;sn=4d3b5c25ca1fdf1f0fb0cd99959d2371&amp;chksm=fd3d4017ca4ac90140442dfc6032346d5841d6705bd92441ad3d0a0366db346752a6b154b976&amp;token=1999457569&amp;lang=zh_CN#rd">SparkSQL极简入门</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485051&amp;idx=1&amp;sn=a1a70cad450634ceae44d4e14a4fc3ef&amp;chksm=fd3d40eeca4ac9f8901a93271683811da05c62e7a6f1d2825378c32542ef2edf9947273a601a&amp;token=1999457569&amp;lang=zh_CN#rd">Spark Shuffle在网易的优化</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247484999&amp;idx=1&amp;sn=f9cf6eae39bc1d54faaa144357731d2f&amp;chksm=fd3d40d2ca4ac9c4e886bd0208521c45dbab98e9cfd34826e6808d414bcd66f203f0359382e1&amp;token=1999457569&amp;lang=zh_CN#rd">广告点击数实时统计：Spark StructuredStreaming + Redis Streams</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247484972&amp;idx=1&amp;sn=ff9a2925c31e07b558504be17937872b&amp;chksm=fd3d40b9ca4ac9afe2cce8ff4a6c50724a146b87d2d05d87d6dcdfb34a177f3be4d5ba79b492&amp;token=1999457569&amp;lang=zh_CN#rd">Spark内存调优</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247484959&amp;idx=1&amp;sn=2173f71a32e16b510f047fa716549bc2&amp;chksm=fd3d408aca4ac99cef4ec3079d9c7376c14f457e80f814e1494f5324612b553fb5487783a486&amp;token=1999457569&amp;lang=zh_CN#rd">Structured Streaming 实现思路与实现概述</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247484956&amp;idx=1&amp;sn=9182a40fcf1fced04acee81aa9261bfe&amp;chksm=fd3d4089ca4ac99f23952f0d627db4600a81808d98b1a635ae40e06c939e4a229a47d666de47&amp;token=1999457569&amp;lang=zh_CN#rd">Spark之数据倾斜调优</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247484766&amp;idx=1&amp;sn=8d0aeaa1166a9338df9f28bb47959f4a&amp;chksm=fd3d43cbca4acadd0dfc9e753ca4fe1cc2ca49060d886b359bdf3537809015b04f82b4be27ac&amp;token=1999457569&amp;lang=zh_CN#rd">你不得不知道的知识-零拷贝</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247484751&amp;idx=1&amp;sn=11315f599b39eac96c17a78da2fa1258&amp;chksm=fd3d43daca4acaccc624947f5fa84f650e7f61d8638feda67db07cacf51bc985faae74cc94c3&amp;token=1999457569&amp;lang=zh_CN#rd">Spark Streaming消费Kafka数据的两种方案</a></li>
</ol>
<h3 id="三-kafka实战进阶文章合集">三、Kafka实战进阶文章合集</h3>
<h4 id="kafka实战合集">Kafka实战合集</h4>
<p><a href="%E5%AE%9E%E6%88%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/Kafka%E5%AE%9E%E6%88%98.md">点我查看Kafka实战合集</a></p>
<h3 id="四-数据仓库实战系列">四、数据仓库实战系列</h3>
<h4 id="数据仓库实战合集">数据仓库实战合集</h4>
<p><a href="%E5%AE%9E%E6%88%98%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93.md">点我查看数据仓库实战合集</a></p>
<h3 id="五-olap实战文章系列">五、OLAP实战文章系列</h3>
<h3 id="六-硬刚系列文章合集">六、硬刚系列文章合集</h3>
<h4 id="硬刚系列文章合集">硬刚系列文章合集</h4>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247503995&amp;idx=1&amp;sn=ead9bbd4ea821c94efc1e18875c1722c&amp;chksm=fd3e96eeca491ff8e0b6a0e1ad3c9ada5365457dd730ce9e19339803504ae10d8108c296fc27&amp;token=935192335&amp;lang=zh_CN&amp;scene=21#wechat_redirect">《硬刚Presto|Presto原理&amp;调优&amp;面试&amp;实战全面升级版》</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247503879&amp;idx=2&amp;sn=bd009e298f2bdf9bb8abc9271b515143&amp;chksm=fd3e9692ca491f84722c922000754aafc4d5a271b0ee40d525ce177de3c4442ef83b5ade8e05&amp;scene=21&amp;token=935192335&amp;lang=zh_CN#wechat_redirect">《硬刚Apache Iceberg | 技术调研&amp;在各大公司的实践应用大总结》</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247503675&amp;idx=1&amp;sn=3ee6af64d0126c78b48cad219308f81e&amp;chksm=fd3e89aeca4900b8b8954e9569ee3c0877881fac8c792bfafc22e7e9d3e8524da8eb860d33d8&amp;scene=21#wechat_redirect">《硬刚ClickHouse | 4万字长文ClickHouse基础&amp;实践&amp;调优全视角解析》</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247503576&amp;idx=1&amp;sn=f9fc428799e0fcc78e94360e1cec7b95&amp;chksm=fd3e884dca49015b6d38c437f603b4deffeeb0cefafd32d358a891bfe820f734116100395bba&amp;scene=21#wechat_redirect">《硬刚数据仓库|SQL Boy的福音之数据仓库体系建模&amp;实施&amp;注意事项小总结》</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247502750&amp;idx=1&amp;sn=bd9a9173d060dc4e4ebd49c8efc6acfe&amp;chksm=fd3e8d0bca49041dea84da93910e5efdc4935e520525c09887c986691377aeb48e5cf7fb5667&amp;scene=21#wechat_redirect">《硬刚Hive | 4万字基础调优面试小总结》</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247503741&amp;idx=1&amp;sn=e5039be93123f2e337013756a818bfc3&amp;chksm=fd3e89e8ca4900fe603b63c5722a6fb8a32bd63d6ba23e0028851948a71b877eb1f742d95087&amp;scene=21#wechat_redirect">《硬刚用户画像(一) | 标签体系下的用户画像建设小指南》</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489571&amp;idx=1&amp;sn=56a634d66fb689907b4ab51ed2d3707a&amp;chksm=fd3d5eb6ca4ad7a0cc5fa4f895354e58ed7f2cb8558369ed6149560a5e7fca97b8545036fe87&amp;scene=21#wechat_redirect">《硬刚用户画像(二) | 基于大数据的用户画像构建小百科全书》</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247504460&amp;idx=1&amp;sn=897f9cebaade7861b110fec0a34fc38b&amp;chksm=fd3e94d9ca491dcf85f611c6772703973035ce05e81defdc8d05597f2c478554e063aaa60f00&amp;scene=21#wechat_redirect">《我们在学习Spark的时候，到底在学习什么？</a>》</li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247499604&amp;idx=1&amp;sn=d938dfb30d221774704982d2938b30c1&amp;chksm=fd3eb9c1ca4930d76a391241333de461ca22d2aa27472eab3cffab1564872ae37f1b48fe2d3c&amp;token=935192335&amp;lang=zh_CN&amp;scene=21#wechat_redirect">《我们在学习Flink的时候，到底在学习什么？》</a></li>
</ul>
<h3 id="七-2020精品文章合集">七、2020精品文章合集</h3>
<h4 id="2020精品文章合集">2020精品文章合集</h4>
<p><strong>实时计算篇</strong></p>
<ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486904&amp;idx=1&amp;sn=5f4b673a87497a9c1dc9d7ce253994f3&amp;chksm=fd3d4b2dca4ac23b9850c54d62ebe8be5920cbd4a491a46a0325e1fbbd91f6b1aef9adf2f638&amp;scene=21#wechat_redirect">Structured Streaming | Apache Spark中处理实时数据的声明式API</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486931&amp;idx=1&amp;sn=9c3f3d6a677ed2aa6cc508046ca6da78&amp;chksm=fd3d4b46ca4ac25044d6033458d3b43e7d1f50f447bded4eed8b246991cf620c91919c51e35b&amp;scene=21#wechat_redirect">HyperLogLog函数在Spark中的高级应用</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486938&amp;idx=1&amp;sn=83347b444fc721442d2b4e1a58eca0e8&amp;chksm=fd3d4b4fca4ac2597abd4a39a21dea83220858ae5efd1ae287b471bb9970f165b4854426f4c2&amp;scene=21#wechat_redirect">基于SparkStreaming+Kafka+HBase实时点击流案例</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486938&amp;idx=1&amp;sn=83347b444fc721442d2b4e1a58eca0e8&amp;chksm=fd3d4b4fca4ac2597abd4a39a21dea83220858ae5efd1ae287b471bb9970f165b4854426f4c2&amp;scene=21#wechat_redirect">基于Flink SQL构建实时数据仓库</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486945&amp;idx=1&amp;sn=f973d74b58d81e96db2bff431c39b2e2&amp;chksm=fd3d4b74ca4ac2629b9f79232a56d8209627e32ebbfb72ca269bf49c863fdf6f3418f6dee5db&amp;scene=21#wechat_redirect">Flink异步之矛-锋利的Async I/O</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492891&amp;idx=2&amp;sn=c86bb4c8a3f96d1e5740e4b16d3638d0&amp;chksm=fd3ea38eca492a9841b34a64a10272c83252bb9815dd164d038248fc71bda7119b266afa5c20&amp;scene=21#wechat_redirect">Spark SQL快速入门系列之Hive</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492891&amp;idx=2&amp;sn=c86bb4c8a3f96d1e5740e4b16d3638d0&amp;chksm=fd3ea38eca492a9841b34a64a10272c83252bb9815dd164d038248fc71bda7119b266afa5c20&amp;scene=21#wechat_redirect">基于SparkStreaming+Kafka+HBase实时点击流案例</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487074&amp;idx=2&amp;sn=02fc69f890ee9922df1ad6b831f448e5&amp;chksm=fd3d48f7ca4ac1e1377befc32a25e97120c1dde9dcb38fa940834302238eb1ad5ceb8b504e7e&amp;scene=21#wechat_redirect">三万字长文 | Spark性能优化实战手册</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487182&amp;idx=1&amp;sn=e69012117af61a623e30e60c0c356444&amp;chksm=fd3d485bca4ac14d360cff2d1e2e78105d350d71daf9b84d911d95b5cc639c528969a5c2fa71&amp;scene=21#wechat_redirect">Flink整合OozieShellAction提交任务带Kerberos认证</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487182&amp;idx=1&amp;sn=e69012117af61a623e30e60c0c356444&amp;chksm=fd3d485bca4ac14d360cff2d1e2e78105d350d71daf9b84d911d95b5cc639c528969a5c2fa71&amp;scene=21#wechat_redirect">Spark源码阅读的正确打开方式</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487224&amp;idx=1&amp;sn=340d084b84ae4d49de9f46a7974e8a4c&amp;chksm=fd3d486dca4ac17b31a221ff1cdcd3920035eeb9f480c00955268686623d512b516214efb3a6&amp;scene=21#wechat_redirect">消息队列常见面试问题小集合</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487242&amp;idx=1&amp;sn=b118be66baa230df95c317d0d14c8a4a&amp;chksm=fd3d499fca4ac089102e0eec2c8248174c43724115a610802e89f5a54d4dfee53aa5d27e8417&amp;scene=21#wechat_redirect">Flink1.10和Hive集成一些需要注意的点</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487259&amp;idx=1&amp;sn=ab3b02eb7e835831cfceb248ae63880a&amp;chksm=fd3d498eca4ac098eac6864ff1f198575ab2822e26f0cbd18f7b666beb660ddef3e3790ab581&amp;scene=21#wechat_redirect">Flink事件时间、水印和迟到数据处理</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487268&amp;idx=2&amp;sn=743482009dab625b6b9316e02e793c7f&amp;chksm=fd3d49b1ca4ac0a7d9ffcde9cb9f76d0850ee67ed7861ee24bf5ded980b03bd3ca4d0c86442e&amp;scene=21#wechat_redirect">Flink使用Broadcast State实现流处理配置实时更新</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487268&amp;idx=1&amp;sn=d2417bd649586c4d6dd73e91ec75538e&amp;chksm=fd3d49b1ca4ac0a7bba4431b4206a84bb13e0dcea01d293a46ae7f69e5fe829e9b37cc46716b&amp;scene=21#wechat_redirect">实战 | MySQL Binlog通过Canal同步HDFS</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487283&amp;idx=2&amp;sn=193b0544edb293fe0795dcfe7caf36ef&amp;chksm=fd3d49a6ca4ac0b01c6f3fb7b93151936bef494ed06e236131a5bd4f86735a35e9c530c1229f&amp;scene=21#wechat_redirect">Flink最难知识点再解析 | 时间/窗口/水印/迟到数据处理</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487330&amp;idx=1&amp;sn=fd95cc865937188ee19944d8b643e6ab&amp;chksm=fd3d49f7ca4ac0e17207d2e543b8803444b34b92a777acdec10cf4f63efef87480fb6e5e5543&amp;scene=21#wechat_redirect">Hive on Spark参数调优姿势小结</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487346&amp;idx=3&amp;sn=4426fc62ba4d0895bf66858fcf6b3873&amp;chksm=fd3d49e7ca4ac0f112b05522f1897c97bdfa9a0278041e085768fd9faa8cfbd0e3e1b840f861&amp;scene=21#wechat_redirect">Flink Logback日志与邮件报警配置</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487346&amp;idx=2&amp;sn=971ffca7e79325e6cd3105eda31af4e1&amp;chksm=fd3d49e7ca4ac0f191f516079b5e1e9451bdd924b4b8fbb8d690c1661e58b7e2dd353c657cdb&amp;scene=21#wechat_redirect">Kafka设计-恰好一次和事务消息</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487357&amp;idx=1&amp;sn=55e0bf4b45ac7f7cae6aadae69e39ace&amp;chksm=fd3d49e8ca4ac0fe6780ac5cf753809e7fa0f0cb73cc70bb8246b1901765199f968bd84fc7b2&amp;scene=21#wechat_redirect">基于Canal和Kafka实现MySQL的Binlog近实时同步</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487364&amp;idx=2&amp;sn=63567772a41545834791a7ab2696e4d4&amp;chksm=fd3d4911ca4ac00729a17a37f70819d861ec9dde65df2f91406fbde7cae188594e386bff82ce&amp;scene=21#wechat_redirect">一个基于RabbitMQ的可复用的事务消息方案</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487387&amp;idx=1&amp;sn=8b769ead6d7407ac490af0fb1b147598&amp;chksm=fd3d490eca4ac0183f13910819092bb22b454f2390f44fc40dc8bf15e91a844b18ec587dd97e&amp;scene=21#wechat_redirect">Spark性能优化总结</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487410&amp;idx=1&amp;sn=24dc08c17ac3d3ac7aaedef9359417d1&amp;chksm=fd3d4927ca4ac0313bdd8999e4760dd6ad0a0471d1fce91493920a08480428d78972ff6f6bdd&amp;scene=21#wechat_redirect">Flink常见异常和错误信息小结</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487410&amp;idx=1&amp;sn=24dc08c17ac3d3ac7aaedef9359417d1&amp;chksm=fd3d4927ca4ac0313bdd8999e4760dd6ad0a0471d1fce91493920a08480428d78972ff6f6bdd&amp;scene=21#wechat_redirect">Spark SQL快速入门系列之Hive</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489363&amp;idx=1&amp;sn=677472699acb15539b4183e463cd00d2&amp;chksm=fd3d51c6ca4ad8d0c01c90a87ab4fc4f172c82b04f27fe12cee19d502ae88e7fc3182ee7a27b&amp;scene=21#wechat_redirect">实时计算双星-Flink VS Spark 部署模式对比</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487468&amp;idx=1&amp;sn=1fc593c4f8160b248a008889e098d4cb&amp;chksm=fd3d4979ca4ac06f42518f5fe94d72646395beca75bf1f06dc347b7628baaf56582605705eaa&amp;scene=21#wechat_redirect">PID算法和Spark实现反压的原理</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487480&amp;idx=2&amp;sn=a233125a9d7f665ed4b69951deb6105a&amp;chksm=fd3d496dca4ac07b283fa8ca95eee2c638d62b894e563ff40c86e69a82386c355ad7ae2ac223&amp;scene=21#wechat_redirect">关于SparkSQL的开窗函数，你应该知道这些!</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487480&amp;idx=1&amp;sn=ec2325cb27dca653269b68f7d6101a07&amp;chksm=fd3d496dca4ac07bbf25fea5a6dc4416be0a19d44ea5aeedc956c640e4acc74066898c195325&amp;scene=21#wechat_redirect">Spark SQL是如何选择join策略的？</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487491&amp;idx=1&amp;sn=4a78fdda3f40f04383f0001522e27c63&amp;chksm=fd3d5696ca4adf804713d6a7651a5a7d0fa35e0e80f453778e6fe84c40d29162bf3874691b18&amp;scene=21#wechat_redirect">Spark on Hive &amp; Hive on Spark，傻傻分不清楚</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487510&amp;idx=1&amp;sn=9d8170be7736ce6cae6e4ce983e2f65b&amp;chksm=fd3d5683ca4adf95fcb1341b6df89dacd647ae890f7db5afad1d3e5251b9ba322b812bbcf767&amp;scene=21#wechat_redirect">来看看一个大二学生的Spark练习题</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491813&amp;idx=1&amp;sn=b0b76b7a41ea2a61705949496f07d03d&amp;chksm=fd3ea670ca492f66da69213c0e74798687b4551102f035da0e973dcb8e92ffdb4d9f75e40c71&amp;scene=21#wechat_redirect">Flink 自定义触发器实现带超时时间的 CountWindow</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491836&amp;idx=2&amp;sn=3eacfa2e3f136f0314012bd4976ee883&amp;chksm=fd3ea669ca492f7fefeb1a8b47af5f53f080512178cfacd9978218b11cbb9c75b078e45f12dd&amp;scene=21#wechat_redirect">Spark Kafka 基于Direct自己管理offset</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491871&amp;idx=1&amp;sn=207b4283b8c75e3883d3af21e36d4ef5&amp;chksm=fd3ea78aca492e9c442c68377a12d2cc7e4c967f30a24c55b1cc0191b916f7f3f9697bc187f1&amp;scene=21#wechat_redirect">Apache Kylin | 麒麟出没，必有祥瑞</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491884&amp;idx=2&amp;sn=a13485ac6594e464fad3f1c64771b4e2&amp;chksm=fd3ea7b9ca492eaf0b71a2a841168451c3ce9080f66d5e08838ea922299797d60e5d477265c5&amp;scene=21#wechat_redirect">Flink 参数配置和常见参数调优</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491911&amp;idx=1&amp;sn=ba027a574fd1a531cb3bec943c949363&amp;chksm=fd3ea7d2ca492ec49f636ab5162b7d9f09730cfa9e4b9ff03589ca9eb1cf564c899aaef79ab3&amp;scene=21#wechat_redirect">利用InfluxDB+Grafana搭建Flink on YARN作业监控大屏</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491992&amp;idx=2&amp;sn=c7942a1ccc921ef5c3a1403752cc81fd&amp;chksm=fd3ea70dca492e1be3e51372fe6414f7f740f0f822d99f1444530da8b1e1dadbf18fe957d8b8&amp;scene=21#wechat_redirect">网站日志实时分析之Flink处理实时热门和PVUV统计</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491992&amp;idx=1&amp;sn=08e4afd7c2a21d6948b7fd7c2351eff0&amp;chksm=fd3ea70dca492e1b51347fb31567a205e5c501d08ed130788e43ab8750316c99b14e7d4bd049&amp;scene=21#wechat_redirect">大数据量下的集合过滤—Bloom Filter</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492025&amp;idx=2&amp;sn=91cf0d75fcf8ce47ea4df45e012e23bb&amp;chksm=fd3ea72cca492e3a206d5ea5efec625b7c9eb63991fa1dc4ccbae21d6f3742eb8e0382bf09fc&amp;scene=21#wechat_redirect">实时数仓链路分享：kafka =&gt;SparkStreaming=&gt;kudu集成kerberos</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492025&amp;idx=2&amp;sn=91cf0d75fcf8ce47ea4df45e012e23bb&amp;chksm=fd3ea72cca492e3a206d5ea5efec625b7c9eb63991fa1dc4ccbae21d6f3742eb8e0382bf09fc&amp;scene=21#wechat_redirect">Flink CEP 原理和案例详解</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487531&amp;idx=1&amp;sn=183d114f36a697eb7df595fa24fec31c&amp;chksm=fd3d56beca4adfa830cdbd99cf0adde30c7622c3541252cdf172ca0b66e60ae475e7796fdc96&amp;scene=21#wechat_redirect">ProcessFunction：Flink最底层API使用踩坑记录</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487665&amp;idx=2&amp;sn=b6efbb6d5efb6e0b0b978fe8a1515f56&amp;chksm=fd3d5624ca4adf32609d3950c0265420e6b75989f8d0e89bf68ceda2495d0e1d1bc4db2f37ec&amp;scene=21#wechat_redirect">Flink 1.10之改进的TaskManager内存模型与配置</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487716&amp;idx=2&amp;sn=d9a765695a803b124857db4da4834118&amp;chksm=fd3d5671ca4adf67a5a0b1880548ea9273336638ee073866f672d4edc85c3ff39e42de69e350&amp;scene=21#wechat_redirect">打通实时流处理log4j-flume-kafka-structured-streaming</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487761&amp;idx=2&amp;sn=9bad34ba9f0c59200f9b10e09b3e7dce&amp;chksm=fd3d5784ca4ade9214b723ed29d6662efd690a52b7e7f667a09690df1e9be2ed6302fb6d7cc1&amp;scene=21#wechat_redirect">如何设计实时数据平台（设计篇）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487795&amp;idx=2&amp;sn=464480d4e075688ab389502e32ef0611&amp;chksm=fd3d57a6ca4adeb0d31080c92b4f98f3187db6201eebb2be5c161b46c8da1806a275543cbbb7&amp;scene=21#wechat_redirect">如何设计实时数据平台（技术篇）</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488182&amp;idx=1&amp;sn=5bbdf75fbad79d01cdb9de65d32f8d39&amp;chksm=fd3d5423ca4add357c23ead5c0fd9818ca3406e341bd91ab33b1a50c6cd27af86dc3b8d90594&amp;scene=21#wechat_redirect">SparkSQL内核解析-执行全过程概述</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488207&amp;idx=1&amp;sn=2148863c2624465675f8bf6650b5843b&amp;chksm=fd3d545aca4add4c39d828872f206cf198b13fe4f7026ad2725b62068f92e0f7853d3f28dd73&amp;scene=21#wechat_redirect">SparkSQL内核解析之逻辑计划</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488580&amp;idx=2&amp;sn=590724dcc514a3f16e0221265858ddde&amp;chksm=fd3d52d1ca4adbc71de9a818b902e9e3e0d1ac2aef374f7f2eecbce3965179066d8e2e041f94&amp;scene=21#wechat_redirect">Flink-1.10中的StreamingFileSink相关特性</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488638&amp;idx=1&amp;sn=8a122c4b3d455292e13e5da1778de6e6&amp;chksm=fd3d52ebca4adbfd4fe4860a90db3d3cfb0fa0048a896342a6ef6eb919c7dae6e3ade0d4f94e&amp;scene=21#wechat_redirect">Kafka下的生产消费者模式与订阅发布模式</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489143&amp;idx=1&amp;sn=3bc211306e107113789f617d39454ee9&amp;chksm=fd3d50e2ca4ad9f45d6302299f35ab3d0423fd170f5959b7acd1826a289c7f4ee2db7cd52460&amp;scene=21#wechat_redirect">Kafka+Spark Streaming如何保证exactly once语义</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489166&amp;idx=1&amp;sn=7bd32ccc732d9c7e5392b5f3e9ab14e2&amp;chksm=fd3d501bca4ad90dba7326060b08bb09b1523b27ca1bd7254fcd1e86d7ae3b4c8ae18c637e3a&amp;scene=21#wechat_redirect">Flink之实时统计热门商品的TopN</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490000&amp;idx=1&amp;sn=984a48afb840b57343d00dfe19335b5c&amp;chksm=fd3d5f45ca4ad6539ba1e979de8f60d29ee003414dfcbb8b34c07e86aa3f15a353303215b076&amp;scene=21#wechat_redirect">SparkSQL的自适应执行-Adaptive Execution</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490024&amp;idx=2&amp;sn=e4822af63cc067d3f5486acd5a668ad8&amp;chksm=fd3d5f7dca4ad66ba406333b2ef2802fda513a0c6852a315f5e6760b321825ab5737eb52d87a&amp;scene=21#wechat_redirect">Kafka KSQL实战</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492241&amp;idx=1&amp;sn=8899979a87a17d9d4ed5ddf901e1a615&amp;chksm=fd3ea404ca492d124e3404fe0d019c6642b90ebc146f2c0f500b82109f4056f7abd36413a38b&amp;scene=21#wechat_redirect">ELK+FileBeat+Kafka分布式系统搭建图文教程</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492293&amp;idx=2&amp;sn=f9354cc4d1ce1541c2aaae99a758437c&amp;chksm=fd3ea450ca492d464331a96746135e9f4ef0205ee968abbcf7a6c4c837b5e1632ef107739f54&amp;scene=21#wechat_redirect">HDFS应用场景、原理、基本架构及使用方法</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492293&amp;idx=1&amp;sn=c14bde7878c5b28cd3698f5a8df735ba&amp;chksm=fd3ea450ca492d46fd9f1bdf3e6f45bed2c8839cc314e1239e73bb5f7daff3a067e4dc5ab914&amp;scene=21#wechat_redirect">数据模型⽆法复⽤，归根结底还是设计问题</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492923&amp;idx=1&amp;sn=6b5a0594031c40ff0e543aa6d9740cc6&amp;chksm=fd3ea3aeca492ab887f8b95a711d3c1bbbd4c2438d941efe42329d713569bb42482342dd92ba&amp;scene=21#wechat_redirect">Hadoop支持Lzo压缩配置及案例</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492168&amp;idx=3&amp;sn=fac9d36291779f58afdf42035d7202a3&amp;chksm=fd3ea4ddca492dcb252d2173f3b247f78552d068eac429f8f10c45e9fff0fbf2d87e0a33d671&amp;scene=21#wechat_redirect">快看 | Java连接集成Kerberos的HA HDFS方案</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491557&amp;idx=2&amp;sn=ba688e1f3b70198975cc57fd845fa337&amp;chksm=fd3d5970ca4ad0668cacb9c1623423fecccdc685e02de5dbf95249f8daf191c2dc732fa9bfc3&amp;scene=21#wechat_redirect">Kafka消费者分区分配策略及自定义分配策略</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492168&amp;idx=2&amp;sn=e460dc527658b327af8437074cc6ac99&amp;chksm=fd3ea4ddca492dcb50a0196d9b65b46b5e90f605f09c4b8307d377955aa1bfbe4a38df33ffb5&amp;scene=21#wechat_redirect">Spark Streaming整合log4j、Flume与Kafka的案例</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491813&amp;idx=2&amp;sn=557cc24073bef28f4f3589b63f71c967&amp;chksm=fd3ea670ca492f660d96498041568c59c60a6390d75931a032d05c53af017451b60a1b9fba49&amp;scene=21#wechat_redirect">面试必知的 Spark SQL 几种 Join 实现</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490732&amp;idx=3&amp;sn=e1ed5667cd2e2f4f2f49c86ca20f40b8&amp;chksm=fd3d5a39ca4ad32f239ed2002503b01bce90c091e636764d35371a1971c46d8a2d24662ff146&amp;scene=21#wechat_redirect">Flink在大规模状态数据集下的checkpoint调优</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490732&amp;idx=2&amp;sn=e2771a1b14403478b801b02c28eedd03&amp;chksm=fd3d5a39ca4ad32f031fc13032168907af08507f8e448d9a9bc786ac8602ba84c400a0f65722&amp;scene=21#wechat_redirect">Write-Ahead Log(WAL预写日志)的工作原理</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490749&amp;idx=1&amp;sn=c9ef0b3010bd1196efcef9df546985d6&amp;chksm=fd3d5a28ca4ad33e2f1d9f20629fb5b1f7049760ded0d6eb9f935751bd78c7b41a188ff6bc42&amp;scene=21#wechat_redirect">Kafka常见的导致重复消费原因和解决方案</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490768&amp;idx=2&amp;sn=7f78bd89f41d189aa4eee7d9de47359d&amp;chksm=fd3d5a45ca4ad353f036260db7be1d5b91075d2de415745350b5d26c05162c53b092f1cd7de6&amp;scene=21#wechat_redirect">Spark-submit 参数调优完整攻略</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490798&amp;idx=1&amp;sn=2c0d6cceb9f1028ac1f2eb8192711c02&amp;chksm=fd3d5a7bca4ad36d442069b4403a7a201c67a1cc72799de3664b63d360b559e58daacb86f396&amp;scene=21#wechat_redirect">Kafka数据可靠性保证三板斧-ACK/ISR/HW</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490873&amp;idx=1&amp;sn=2da5f475f178bda5ee5a74dc0306b25e&amp;chksm=fd3d5bacca4ad2bab06dc1d526e28b71e714d499929a85675f2d40f5ec0d72200f54d42e038d&amp;scene=21#wechat_redirect">Spark常见错误问题汇总</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490905&amp;idx=2&amp;sn=18196db069e5740503ee6be0907fafc2&amp;chksm=fd3d5bccca4ad2da28a3ef31d17181f91bdedf4079ffea830328e726e0959011161fc41c8b86&amp;scene=21#wechat_redirect">HBase操作组件：Hive、Phoenix、Lealone</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490966&amp;idx=2&amp;sn=f8f2ee62b1aa8353e0f3bba18a8c2f5e&amp;chksm=fd3d5b03ca4ad2151a4c5898683a7eee080088760c4eca5d46df8eb619f01e8d44628cdead9e&amp;scene=21#wechat_redirect">Redis系列 | 缓存穿透、击穿、雪崩、预热、更新、降级</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490966&amp;idx=1&amp;sn=e81972c99e2792f449085d03715304b1&amp;chksm=fd3d5b03ca4ad215cea217195cce7b29fd3150250e4d134c37ff57dabec52b8d849f62e0ca36&amp;scene=21#wechat_redirect">Kafka工作流程及文件存储机制</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491086&amp;idx=2&amp;sn=68f9365aff2a66846143b20943c4b138&amp;chksm=fd3d589bca4ad18d971f9ef6709da0217f63ec12615f0ef54c6327ca7568dccfac1a79628cbc&amp;scene=21#wechat_redirect">Redis6.0主从、哨兵、集群搭建和原理</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491086&amp;idx=2&amp;sn=68f9365aff2a66846143b20943c4b138&amp;chksm=fd3d589bca4ad18d971f9ef6709da0217f63ec12615f0ef54c6327ca7568dccfac1a79628cbc&amp;scene=21#wechat_redirect">Spark Streaming官方编程指南</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492401&amp;idx=1&amp;sn=88a3634793c0a3b86e48c5cfe21f6ba3&amp;chksm=fd3ea5a4ca492cb2f298af0a3605fcfe80928057ab24c26e697c11e0c82654636f2ce5190776&amp;scene=21#wechat_redirect">【从0开始の全记录】Flume+Kafka+Spark+Spring Boot 统计网页访问量项目</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492426&amp;idx=1&amp;sn=5cc1326f8cdec7f54eedea656acb89c5&amp;chksm=fd3ea5dfca492cc98f89e32b2291d5439896d119fec077cafa65b36fbf46a875d9f3c0996fd4&amp;scene=21#wechat_redirect">Spark+Kudu的广告业务项目实战笔记(一)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492558&amp;idx=1&amp;sn=82382cfce0d052380d1c4096951402a2&amp;chksm=fd3ea55bca492c4dea78c0e039e2c1993cdf0bd22f56fb97f9445645033140d34cf520aab697&amp;scene=21#wechat_redirect">大数据入门：Spark+Kudu的广告业务项目实战笔记(二)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492558&amp;idx=2&amp;sn=995b7887879a439dd0dac0d801d82e4d&amp;chksm=fd3ea55bca492c4dd856e6084a727a15359cac7f5278ac0bbbdacd57aec55296d3979bee5f09&amp;scene=21#wechat_redirect">大数据入门：Spark+Kudu的广告业务项目实战笔记(三)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492558&amp;idx=3&amp;sn=d2273c79be1d99270d41270a2b12d872&amp;chksm=fd3ea55bca492c4dbbc8ccaafc5375fbff8c01101cfca029f5f36d29985201001b83856204d6&amp;scene=21#wechat_redirect">大数据入门：Spark+Kudu的广告业务项目实战笔记(四)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492558&amp;idx=4&amp;sn=e5f0d6e8168c2c51eafe4952dc41ba19&amp;chksm=fd3ea55bca492c4d6261bfe591627118f2c203bb70ed86a43d03ef2b4d7cc952eef2b93a3235&amp;scene=21#wechat_redirect">大数据入门：Spark+Kudu的广告业务项目实战笔记(五)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492558&amp;idx=5&amp;sn=9fd6dcc935f6d73a4c57166bc94212be&amp;chksm=fd3ea55bca492c4d1b0d477f02a7f2f40b3944068720db7f7452a165719f6979fee0b1d48eb0&amp;scene=21#wechat_redirect">大数据入门：Spark+Kudu的广告业务项目实战笔记(六)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492648&amp;idx=2&amp;sn=eaef19686a06d04efaf3d6f17a5ca0ba&amp;chksm=fd3ea2bdca492bab691ce6e47d81387ba0a0cdc2350265ef5eb58e38b466237c549267022eb3&amp;scene=21#wechat_redirect">Flink 1.11新特性之SQL Hive Streaming简单示例</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492699&amp;idx=3&amp;sn=fb58aad4cc9cd6aad71ab581816f0d0b&amp;chksm=fd3ea2ceca492bd8c7bb490611e1d930b5833ede83d198e61555bc3fdd5687c2a513e700a800&amp;scene=21#wechat_redirect">SparkSQL 整体运行架构和底层实现</a></li>
</ul>
<p><strong>离线计算篇</strong></p>
<ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486981&amp;idx=1&amp;sn=9c8fc4c127d7e6108ac4e171e750d490&amp;chksm=fd3d4890ca4ac186614f0dda8ffb2d35693a925b03861a01769c898652b53d0d436bca05ea12&amp;scene=21#wechat_redirect">ORC文件存储格式的深入探究</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486981&amp;idx=1&amp;sn=9c8fc4c127d7e6108ac4e171e750d490&amp;chksm=fd3d4890ca4ac186614f0dda8ffb2d35693a925b03861a01769c898652b53d0d436bca05ea12&amp;scene=21#wechat_redirect">Hadoop支持Lzo压缩配置及案例</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487175&amp;idx=1&amp;sn=c00064434ee03bef0b6aa07d2b9033a4&amp;chksm=fd3d4852ca4ac144a310dc7d901bdf262e3c929ef7ab414e4de03602ed83b3901c098a00145b&amp;scene=21#wechat_redirect">神策数据分享 | 标签体系应用与建设(文末附下载链接)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487204&amp;idx=1&amp;sn=f344eb2641175828815075cd6e57520e&amp;chksm=fd3d4871ca4ac167e7cd49e7938936e861ca5c14f048730487a7b225561e1794cd5d9e69905d&amp;scene=21#wechat_redirect">环形缓冲区-Hadoop Shuffle过程中的利器</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487233&amp;idx=1&amp;sn=dae402bafe49cf98f1b112bca384d7e1&amp;chksm=fd3d4994ca4ac08275d0a3c57efbfcaca370edeec62e7b5cc982f7299c2937103b7dea1af782&amp;scene=21#wechat_redirect">eBay | 实践Hadoop任务的性能翻倍之路</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487287&amp;idx=1&amp;sn=e632bbf074c0d2c64a892a481872c6e7&amp;chksm=fd3d49a2ca4ac0b4aa36391a8f36f24e49ebcf645a0da96042b76bb582f9d218aa9a57edfb7f&amp;scene=21#wechat_redirect">PDFT/Paxos/Raft-分布式一致性协议解析</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487294&amp;idx=2&amp;sn=03c969be724fe60b0b14f921cbcec8f6&amp;chksm=fd3d49abca4ac0bdda91ceab31deca10f2059e2e37e34e60e17f54f358ab25c7c7bb93d4b840&amp;scene=21#wechat_redirect">谈谈经典限流方法—漏桶、令牌桶与Guava RateLimiter的实现</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487294&amp;idx=1&amp;sn=8b808225b1b792e892ab737485492ac6&amp;chksm=fd3d49abca4ac0bdc9ecc3eb45bc89c2cb8f4af7f3a66c0e9e6290d374279fd0569049996143&amp;scene=21#wechat_redirect">轻量级异步屏障快照（ABS）算法解析</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487297&amp;idx=2&amp;sn=c5ef9a22eb4c3e3da9e5fc32fe90c949&amp;chksm=fd3d49d4ca4ac0c29d739867fae2fe796ee9a2fc1aa29b85c30d34efbb167ac885e134af2053&amp;scene=21#wechat_redirect">Hadoop小文件利器Ozone</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487297&amp;idx=2&amp;sn=c5ef9a22eb4c3e3da9e5fc32fe90c949&amp;chksm=fd3d49d4ca4ac0c29d739867fae2fe796ee9a2fc1aa29b85c30d34efbb167ac885e134af2053&amp;scene=21#wechat_redirect">数据指标体系建设</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487338&amp;idx=1&amp;sn=00e93834aef4c73cd3cd2a487e3e6cc9&amp;chksm=fd3d49ffca4ac0e948bb40ba97c5da9e7fa3ffb78afb6001f9d06603e6ac1938d7f06b5ee38d&amp;scene=21#wechat_redirect">Hbase FAQ热门问答小集合</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487369&amp;idx=1&amp;sn=6ad49150d939209cc59965be922ae5ed&amp;chksm=fd3d491cca4ac00a82671803f60c1848932bc45aa649dcfe4f0f765fe24cc364a1bab81ec550&amp;scene=21#wechat_redirect">设计HBase RowKey需要注意的二三事</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487378&amp;idx=2&amp;sn=f9d4400a0677a70a8df94cc0530831e3&amp;chksm=fd3d4907ca4ac011d278ad227be1c902f1ab9408e227f27c6082cfc2580e74fe1788365f97b1&amp;scene=21#wechat_redirect">HBase优化笔记</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487391&amp;idx=2&amp;sn=420d44df8c68349212df31fa4471576d&amp;chksm=fd3d490aca4ac01c7536e0f628cd82be97d5d9dba1b9619a0c637795731813cc36acb8c52079&amp;scene=21#wechat_redirect">HBase生产环境优化不完全指南</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487395&amp;idx=1&amp;sn=7fdb8625da8cccd43ceb07ea6554fe92&amp;chksm=fd3d4936ca4ac020bdc48bdb7cfb55564e8d2cd99c39e785ce0d7eb86cb75b347bcf5914d0c9&amp;scene=21#wechat_redirect">Hive SQL50道练习题</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487410&amp;idx=2&amp;sn=c6be05a74ac472b962583a2228996316&amp;chksm=fd3d4927ca4ac031a2b1976393d12c6a78ea81817aded17ee2fd57dcc6f22cd1c4272d3f0e1b&amp;scene=21#wechat_redirect">Hive on Spark参数调优小结</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487523&amp;idx=1&amp;sn=6719f902998dd24a0904444d49f72ec7&amp;chksm=fd3d56b6ca4adfa0a3279696b65467093e4035e94df802e7d44c64853634c1a387c3fc99e989&amp;scene=21#wechat_redirect">Hadoop(CDH)分布式环境搭建(简单易懂,绝对有效)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487527&amp;idx=1&amp;sn=e9dee7c31da53fd9a27acc49e41e4753&amp;chksm=fd3d56b2ca4adfa49fdc66d49c746359632b85714a1edd4986c3028fbc7a0228650fa4c41ee8&amp;scene=21#wechat_redirect">ConcurrentHashMap锁机制进化的考量</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492803&amp;idx=2&amp;sn=b7a718dea53b5912149fe61f9f396fe1&amp;chksm=fd3ea256ca492b40cf52f812cef0c437610350777d17022edf264e2b7ee6f7b30164e9f84039&amp;scene=21#wechat_redirect">HBASE列族不能太多的真相</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492803&amp;idx=1&amp;sn=04283aa0913674e158a8519120fc14cd&amp;chksm=fd3ea256ca492b40f60ac90eee4d23f9c2b8156a9c83439297317efcb826b32779b762f554e4&amp;scene=21#wechat_redirect">基于ClickHouse的用户行为分析实践</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492822&amp;idx=1&amp;sn=175f6febc758a56c7aa680f5b953de08&amp;chksm=fd3ea243ca492b55e723f64a81f8b334b97cbe3c80cd72da0e5695380f33f25c74b9b7996978&amp;scene=21#wechat_redirect">HBase的系统架构全视角解读</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492864&amp;idx=1&amp;sn=597c5e992305482d2d49f801b10e8efd&amp;chksm=fd3ea395ca492a839c9c53c6fdd5056d9cec123ebc0c7acc578569480140c3cd6bb7762ebf43&amp;scene=21#wechat_redirect">Kylin Cube构建原理+调优</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492923&amp;idx=1&amp;sn=6b5a0594031c40ff0e543aa6d9740cc6&amp;chksm=fd3ea3aeca492ab887f8b95a711d3c1bbbd4c2438d941efe42329d713569bb42482342dd92ba&amp;scene=21#wechat_redirect">Hadoop支持Lzo压缩配置及案例</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492943&amp;idx=1&amp;sn=fcd6d6e67b7ff0792976b063374306ac&amp;chksm=fd3ea3daca492acc631a0db5d99c82603d7935888e13ea086a5825651132396f3d48db20c5b5&amp;scene=21#wechat_redirect">Apache Hudi 架构设计和基本概念</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492943&amp;idx=1&amp;sn=fcd6d6e67b7ff0792976b063374306ac&amp;chksm=fd3ea3daca492acc631a0db5d99c82603d7935888e13ea086a5825651132396f3d48db20c5b5&amp;scene=21#wechat_redirect">HiveSQL常用优化方法全面总结</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488182&amp;idx=2&amp;sn=b2b8e50829f5706295fa5b5201743621&amp;chksm=fd3d5423ca4add3516c141897124468ce51bfa86f599dd499e728bfcf18d8928fafaabac4d4f&amp;scene=21#wechat_redirect">MapReduce性能优化大纲</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487582&amp;idx=1&amp;sn=6882c98d94b6e3a52132b30ff4e404ef&amp;chksm=fd3d56cbca4adfddcbaf2ded2f540a2b32cf4e0cace93a4a4f6a2b00a0482f80deaa55f6e8f1&amp;scene=21#wechat_redirect">从NoSQL运动谈分布式系统的CAP、BASE理论</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487609&amp;idx=2&amp;sn=5b5fc64b4c2628f77cfd902228ec78cf&amp;chksm=fd3d56ecca4adffa3d66802fcb091468f96a51730b4a095b6de32842d7325165f797da8b1bf7&amp;scene=21#wechat_redirect">HDFS读写数据过程原理分析</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487665&amp;idx=1&amp;sn=5a0a007f58a7c9a6872a4b7c65683f08&amp;chksm=fd3d5624ca4adf32159835c42768938c2e455c8354d1ca1bef731ab320a378eb8af002e3cd96&amp;scene=21#wechat_redirect">数据中台建设五步法</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488083&amp;idx=2&amp;sn=30a40939a9ba29a2c55a1c973433e8f4&amp;chksm=fd3d54c6ca4addd0224cd352085966896d45d02e110db5c90142947053f3a7af21b7c1b6673e&amp;scene=21#wechat_redirect">Step by Step 实现基于 Cloudera 5.8.2 的企业级安全大数据平台 - Kerberos的整合</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488492&amp;idx=1&amp;sn=6059d4f245afad8230ee71a96e8a3d4e&amp;chksm=fd3d5579ca4adc6f9b66549757ea8e3ac6bacdcdd17185ac87073f6fbbc88827d0b789606aa3&amp;scene=21#wechat_redirect">一篇文章全面了解监控知识体系</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491557&amp;idx=1&amp;sn=3641e76946290e82f393f2660c07c8dd&amp;chksm=fd3d5970ca4ad0666a3b2449f3d0444177aec2afdc7fd15998a8f006c99d5bb41e28f916fab7&amp;scene=21#wechat_redirect">Sqoop 使用shell命令的各种参数的配置及使用方法</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491603&amp;idx=2&amp;sn=339b7498e6c632cc5663625ef13c5dc1&amp;chksm=fd3ea686ca492f90e7085a444431dea40c1e7f30884b5df283b695f30d4f591a9dfaec32c7b5&amp;scene=21#wechat_redirect">Hive小知识之分桶抽样</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491647&amp;idx=1&amp;sn=51dd15b000803c1ab1d4cea67fc02e81&amp;chksm=fd3ea6aaca492fbc6fc2fe34f39cb31a585b3c53b02ca0304e7edf63680521ba7036a0bbfdce&amp;scene=21#wechat_redirect">数据仓库和数据集市建模体系化总结</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491759&amp;idx=1&amp;sn=2d0b25585442176b0ad74235fe799611&amp;chksm=fd3ea63aca492f2cf8f482a0f5bc88ed3034124d90d0234991a67a9ab1dd4e0086c60e0a83e8&amp;scene=21#wechat_redirect">Phoenix(云HBase SQL)核心功能原理及应用场景介绍</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492053&amp;idx=1&amp;sn=594dd94d1bf6d692680d77107d83794a&amp;chksm=fd3ea740ca492e56c2a838e8f6656dc7c9dea787add1c801b6ed379554162c696fcc5e625c1a&amp;scene=21#wechat_redirect">基于实际业务场景下的Flume部署</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492958&amp;idx=1&amp;sn=1ef59283fddfcffa14425d8d51af6f81&amp;chksm=fd3ea3cbca492add3660dc37a37b458694cd285ae061884bb8aecbba2725fab3baee89608eba&amp;scene=21#wechat_redirect">斗转星移 | 三万字总结Kafka各个版本差异</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490378&amp;idx=1&amp;sn=f45be2b9cb97e896afb1ded5d6c37fcc&amp;chksm=fd3d5ddfca4ad4c90ae2a6c75eee49d5c894d44c3603a94bf117807091467162f2b843e0c43e&amp;scene=21#wechat_redirect">Spark SQL自定义函数UDF、UDAF聚合函数以及开窗函数的使用</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490581&amp;idx=2&amp;sn=d819fc83a5f553687b5c79bd64cc9843&amp;chksm=fd3d5a80ca4ad39607611d9dc07613b1a5da27570f7b8331e17400a6bf6a4285fbe9ce942a42&amp;scene=21#wechat_redirect">SparkSQL用UDAF实现Bitmap函数</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490065&amp;idx=1&amp;sn=e8e9539eecc25ef7a5f8703fac277be3&amp;chksm=fd3d5c84ca4ad5925f407f84546146a4e8f75d97b58adb98f9dca32ab8aa90b14e9d2211e0c9&amp;scene=21#wechat_redirect">一文了解Kafka核心概念和角色</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490160&amp;idx=1&amp;sn=a0bf8702286a348d6e486be62d07751e&amp;chksm=fd3d5ce5ca4ad5f34f643f46662ef37067c1199c28ca4b15ec958bb51b68edc992d3e99ff922&amp;scene=21#wechat_redirect">Apache Spark 内存管理详解</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490460&amp;idx=3&amp;sn=b2d23ba7b20ea8cf2d155999ec879b75&amp;chksm=fd3d5d09ca4ad41f1f7328d91bac921168207e5a5e1f4af78b9a392f626ab26c72998cd5457e&amp;scene=21#wechat_redirect">经典限流方法——漏桶、令牌桶与Guava RateLimiter的实现</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490460&amp;idx=2&amp;sn=8491948f284d3bc53a4c3be7f285aae7&amp;chksm=fd3d5d09ca4ad41f797ca0b584b83668c78cf5f449207b42dcdb49e90dcd558b759b249be498&amp;scene=21#wechat_redirect">ZooKeeper在HBase集群中的作用</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490581&amp;idx=3&amp;sn=cbf752e85e3cf865e5a673965f020bbd&amp;chksm=fd3d5a80ca4ad39616be9a8d0c6daddfe72f69993a43d322fcdd1966f566bae38b836753aa95&amp;scene=21#wechat_redirect">从B+树到LSM树，及LSM树在HBase中的应用</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490581&amp;idx=1&amp;sn=57492e477ea3360e53eac23a20c3b0ad&amp;chksm=fd3d5a80ca4ad396b7b11cf00ca2a87ff1097692c527208ad6ada9151da88edd6542161c4bc6&amp;scene=21#wechat_redirect">Hadoop Namenode元数据持久化机制与SecondaryNamenode的作用详解</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490610&amp;idx=1&amp;sn=f435639d0392156082a997411bf42f6c&amp;chksm=fd3d5aa7ca4ad3b1a239b8ac29f156ce7b6198cee7ec613e44dc27579b8bcf27fede954a2883&amp;scene=21#wechat_redirect">干掉ELK | 使用Prometheus+Grafana搭建监控平台</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488854&amp;idx=1&amp;sn=5b1419b1813e4695c0750445078012d4&amp;chksm=fd3d53c3ca4adad5e0852f1d44e9fb0592bf82e7c635a2900dff196bb5172443e9ce5dccd07b&amp;scene=21#wechat_redirect">盘点：SQL on Hadoop中用到的主要技术</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489143&amp;idx=2&amp;sn=c25af83fc4bdeb42fb7d4236669489e4&amp;chksm=fd3d50e2ca4ad9f474758e8e5b004a531fded129a5ed5bc7bc549e50f3e72872c4048628d288&amp;scene=21#wechat_redirect">用HiveSQL计算连续天数问题的方法</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489342&amp;idx=2&amp;sn=5354a5fcb497f9a2294b61c707838411&amp;chksm=fd3d51abca4ad8bde70e5980531cf3e63ba314ba000df4df7e10420a093c3f1f80063094c854&amp;scene=21#wechat_redirect">浅谈Linux cgroup机制与YARN的CPU资源隔离</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489415&amp;idx=2&amp;sn=303860edceafc625b97fdeae6e8e7acf&amp;chksm=fd3d5112ca4ad804637f73ccd9d1177d5bb3521f0cda68cbabccd7fe2ab7047f4fd05563e6c2&amp;scene=21#wechat_redirect">京东JDHBase异地多活实践</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489433&amp;idx=1&amp;sn=cfe0e855bf0addfd06599cc4c4a6f61c&amp;chksm=fd3d510cca4ad81a87c0a2f81e74eabbf55928e38ec605e8870ea96dc0bc5926302de51200ae&amp;scene=21#wechat_redirect">Kafka的分区数是不是越多越好？</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490187&amp;idx=2&amp;sn=c8cb0f332019d1bf73ac6d92ed913dbc&amp;chksm=fd3d5c1eca4ad5089cb8949fd1ee6e51c7d8622cf691edfc759836591435f9246a0b729a6b2b&amp;scene=21#wechat_redirect">一文俯瞰Elasticsearch核心原理</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490378&amp;idx=2&amp;sn=e3f62731d911f230463581dae96f7c49&amp;chksm=fd3d5ddfca4ad4c9847a8effc42e9a63e019e2e25712706bc0c3816237bb9bd76fec411bdf2e&amp;scene=21#wechat_redirect">不可不说的Java&quot;锁&quot;事</a></li>
</ul>
<p><strong>数据仓库篇</strong></p>
<ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486890&amp;idx=1&amp;sn=004a86c329439558a4f234fa21744173&amp;chksm=fd3d4b3fca4ac229c6af919153949d4bc60c603635fc432d5695c4ee14c61bd6408a6188ef22&amp;scene=21#wechat_redirect">一文了解数据库和数据仓库</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486892&amp;idx=2&amp;sn=8e9a2c30a596cde9713601a22875af63&amp;chksm=fd3d4b39ca4ac22f082760e7d4c8e0c4c7979e7431f9063215a8669cc5724adcc843df01b1e0&amp;scene=21#wechat_redirect">数据仓库系统的实现与使用(含OLAP重点讲解)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487196&amp;idx=1&amp;sn=313ceebfbf288e309f8e5da00451af5b&amp;chksm=fd3d4849ca4ac15f800f6eebc95e597e47cafad3bfe1e0413f83db88ea7530448ad55b5d7680&amp;scene=21#wechat_redirect">Data Lake 三剑客—Delta、Hudi、Iceberg 对比分析</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489275&amp;idx=2&amp;sn=1c9783692bc3f9cceb3f403702057744&amp;chksm=fd3d506eca4ad978f6d28a3f933b68367d80566e93a391617996f42c60d1398912c0a73908a7&amp;scene=21#wechat_redirect">数据也有温度？Elasticsearch 5.x 版本中的冷热数据架构</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489301&amp;idx=1&amp;sn=aa613e6311ae45487286c24f2134aa8d&amp;chksm=fd3d5180ca4ad89606221360a1e7e35f5259d5a2eea4c1b4cf3e0fd0cee2d74b6579ea043546&amp;scene=21#wechat_redirect">数据冷热分离技术</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490610&amp;idx=2&amp;sn=c1751ded1965049fabd61df82484c4b3&amp;chksm=fd3d5aa7ca4ad3b140d5ce00fa06b75e3577cb5bf9e3a944f25ca49c74e03072a03562d635cc&amp;scene=21#wechat_redirect">冷热数据分离 | Alluxio元数据管理策略</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490691&amp;idx=2&amp;sn=2c8059004ba6086edb34e901efa5fdc0&amp;chksm=fd3d5a16ca4ad30038888daa1ebf8f65be386cd3ba7ae2ba4fadc1f1eed24a9edc863ef10dc1&amp;scene=21#wechat_redirect">数据之眼 | 数据探查服务的设计</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247490691&amp;idx=1&amp;sn=e77e2a1058cf3b9e7015a6451331e406&amp;chksm=fd3d5a16ca4ad300b30467cf550015b6c2474ff18f5093dc1f2a954f1115dc4ee3fc33aeda99&amp;scene=21#wechat_redirect">元数据存储系统管理演变升级</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492241&amp;idx=2&amp;sn=a1a1c35ac0a71d648ac773b700c0478b&amp;chksm=fd3ea404ca492d128493132600f9cebb2b34a3dc395fe4eb6db02d9a018ace5adcd171f6941a&amp;scene=21#wechat_redirect">数据湖 | 一文读懂Data Lake的概念、特征、架构与案例</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488529&amp;idx=1&amp;sn=bc81e0fb68c13626c9202f1942fb3a80&amp;chksm=fd3d5284ca4adb922308718382820ac48e4dcdf819ef8d2b672ee919cf6b67c4aa7a70053539&amp;scene=21#wechat_redirect">用户行为数据采集系统</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488580&amp;idx=3&amp;sn=6152e6acfe7b600c8d8e4a2138c37aa9&amp;chksm=fd3d52d1ca4adbc72ea737f35c9512fa8a3ef9e9733c14c57c1b269a6798e5a04dd285912d77&amp;scene=21#wechat_redirect">创业公司数据仓库的建设</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487697&amp;idx=1&amp;sn=b085af6dd063fa66d017ae8f96bc94af&amp;chksm=fd3d5644ca4adf52f0bc616917ff1a817328ed1bb39a01a04fc839164a2705cf92e0ddcad6dd&amp;scene=21#wechat_redirect">Kylin使用Spark构建Cube</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488311&amp;idx=1&amp;sn=f6a8c052d49c6abb0fc7956a2066f4c2&amp;chksm=fd3d55a2ca4adcb4d5f1f5250013fb38aae2e75510f95364cbb58d4ea4f985b0dac7869b5fba&amp;scene=21#wechat_redirect">实时统计分析系统-Apache Druid</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489054&amp;idx=2&amp;sn=2ec1061def576779947d31eee1c5ce74&amp;chksm=fd3d508bca4ad99d7ea476c9ea70da6df33e3099a55faace760233e6833e8086ac26036420a9&amp;scene=21#wechat_redirect">Elasticsearch索引和检索优化与压测监控总结</a></li>
</ul>
<p><strong>面试题篇</strong></p>
<ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486931&amp;idx=2&amp;sn=1c5987f3bad7a805895484ebfd683e11&amp;chksm=fd3d4b46ca4ac250d31502a76f0cfd02ebea29d1161b9e9faec23ea6aa8947d0dd7d4268427f&amp;scene=21#wechat_redirect">我们常说的海量小文件的根源是什么？</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486986&amp;idx=1&amp;sn=422d1a3c11c72ff97b32cc01142839f4&amp;chksm=fd3d489fca4ac1895242ab94b932b12c65dc57b5f3a16acc7084dc8a189e9026290245a64c4f&amp;scene=21#wechat_redirect">如果你在准备面试，好好看看这130道题</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486992&amp;idx=1&amp;sn=8950101b408b0e02b7957f6d74c9cd74&amp;chksm=fd3d4885ca4ac193a28d3f10f9d25c39ec57c294d51961cac69fdf8bacbcac46a989342d2136&amp;scene=21#wechat_redirect">你可能需要知道的Kafka面试题与部分答案整理</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487021&amp;idx=2&amp;sn=bbfa3fb95e4fa3d0b6ae90a8933119ed&amp;chksm=fd3d48b8ca4ac1ae0542948f3abaa00e69ca7b20806699c7a8dec7a13ddfb79a981ca3b45c90&amp;scene=21#wechat_redirect">28道关于ZooKeeper的面试题</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487177&amp;idx=2&amp;sn=dea2d55951494a5bf4438ec5a888bdd7&amp;chksm=fd3d485cca4ac14ac7ae87e6a8bf11d988e068c3548762cab91f11f45855431e8f759e131a76&amp;scene=21#wechat_redirect">【数据白皮书重磅分享】推荐|埋点|用研|标签</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487297&amp;idx=1&amp;sn=9b007050efaf50f17e3f46915c70f4ea&amp;chksm=fd3d49d4ca4ac0c2b0e25aae9e4aba71c9cc18e6f388d1dd6615791a7d2432445c32d0039eaa&amp;scene=21#wechat_redirect">一份优秀的简历该长成什么样</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487309&amp;idx=2&amp;sn=a33cc56116cb7891145394f9c5353be3&amp;chksm=fd3d49d8ca4ac0ce28cd0a543109d60db47e8be60d63c6951fa30e4ab4c812f9025286fa5c37&amp;scene=21#wechat_redirect">1万2千字长文助力春招 | Netty面试篇</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487314&amp;idx=1&amp;sn=f832be362c7c2ea877c48d47923434c5&amp;chksm=fd3d49c7ca4ac0d1444e8352b35ea3a706cdf496add814cf0fe3aa4844f4c25dc2f4d6c269f1&amp;scene=21#wechat_redirect">消息队列面面观</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487326&amp;idx=1&amp;sn=1ba5867700bdfb5ad7f808a245ae3b1f&amp;chksm=fd3d49cbca4ac0dd7d8401e1226ff054441709af6f0cacc3ceeab7354ac6f7452592239efb06&amp;scene=21#wechat_redirect">关于技术面试的一点点体会</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487334&amp;idx=1&amp;sn=ce3453c1b63d6932438c8412fc5454d3&amp;chksm=fd3d49f3ca4ac0e5ab43ecb1cc9be9320232bb0234b3c43b0903eca9e225c338b5c6990923cc&amp;scene=21#wechat_redirect">早点建立自己的知识体系</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487414&amp;idx=2&amp;sn=2afda2b854a4f875159a43903bb7b337&amp;chksm=fd3d4923ca4ac035b7627c9a32b7fa003f817176d959aae98770416cf3a55384efdde060b03f&amp;scene=21#wechat_redirect">Filter(过滤)|Project(映射)|Pushdowns(谓词下推)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487449&amp;idx=3&amp;sn=5b3d8564d1c84b14f9d941c96d8f6a27&amp;chksm=fd3d494cca4ac05a83b67a04ac5497bb13ecf79a3a5044083d0bf9e93d8bdacd357fa1ffce1e&amp;scene=21#wechat_redirect">阅读源码｜Spark 与 Flink 的 RPC 实现</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487449&amp;idx=1&amp;sn=2cc97bf6669416267c25a7a46192b706&amp;chksm=fd3d494cca4ac05a25e3e91a52d105bba187896cdf322ebbf82b7ce88db8f8a3ed25070cad77&amp;scene=21#wechat_redirect">三万六千字通关MySQL面试</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487458&amp;idx=1&amp;sn=11e0b029998ecdeccda8e18c1e43f980&amp;chksm=fd3d4977ca4ac0613b5a32d6bed036231239f40021afa15a0b45cab6426a9afdcca7e9d7844c&amp;scene=21#wechat_redirect">深入理解CAP理论和适用场景</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487464&amp;idx=1&amp;sn=c7358495832da5e4bf4807691be6ef29&amp;chksm=fd3d497dca4ac06b1caa9b6a0746d01dd4dd44203d57e929193fa79053232c13b1668615f8e7&amp;scene=21#wechat_redirect">HDFS的SecondaryNameNode作用，你别答错了</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491086&amp;idx=1&amp;sn=f2f9bd1a55064ec7abf63666bf54be61&amp;chksm=fd3d589bca4ad18d6e3f353c1d63cee77650d176b582c3f84b7ead45170e0c5523a0a472b1eb&amp;scene=21#wechat_redirect">Kafka三种可视化监控管理工具Monitor/Manager/Eagle</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491138&amp;idx=1&amp;sn=f42cac6584ca4c3b74f232e897b33206&amp;chksm=fd3d58d7ca4ad1c19e851a02b88e6e8350e29e8a57f71acc5def38bc14ed5a0f5110122f9927&amp;scene=21#wechat_redirect">Kafka体系架构详细分解</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491138&amp;idx=2&amp;sn=a67e3044fd368e61a0290679e2765661&amp;chksm=fd3d58d7ca4ad1c1cf2c6e79747b77005dd811e6d385c7b67a3970e6de74fbd1f307f06a658a&amp;scene=21#wechat_redirect">Kafka笔记—可靠性、幂等性和事务</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491138&amp;idx=1&amp;sn=f42cac6584ca4c3b74f232e897b33206&amp;chksm=fd3d58d7ca4ad1c19e851a02b88e6e8350e29e8a57f71acc5def38bc14ed5a0f5110122f9927&amp;scene=21#wechat_redirect">Kafka体系架构详细分解</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491176&amp;idx=1&amp;sn=81b44db6db3cb014dc9002ba840ad283&amp;chksm=fd3d58fdca4ad1ebdb2aa17b6ffce1794daef5def22cdc84a7f280a107cba966658293cb14b6&amp;scene=21#wechat_redirect">Kafka面试题系列(进阶篇)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491156&amp;idx=2&amp;sn=e18e2ae54f08ee34749fdb314652c2fe&amp;chksm=fd3d58c1ca4ad1d777b950bf01f33f36dff4e8bc55779f3a1a50019136fd6d345148188e41db&amp;scene=21#wechat_redirect">Kafka面试题系列(基础篇)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492699&amp;idx=2&amp;sn=776b93fb683a004d58d432d9b6b551b4&amp;chksm=fd3ea2ceca492bd8f72e397ec63b331aa129f74f803be9f922633df01fdb552adb75371d3dad&amp;scene=21#wechat_redirect">面试知识点 | Kafka的数据存储与索引设计</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489094&amp;idx=1&amp;sn=76958401eb4fab0a69447b37bda2b4c9&amp;chksm=fd3d50d3ca4ad9c5330d003ee5c8265e8a49f04bbccd9a9513cf2ec2f983b6d45842dae41c30&amp;scene=21#wechat_redirect">面试必考点:HBase Compaction机制</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488393&amp;idx=1&amp;sn=f820923ae3e782b509911f787a455a91&amp;chksm=fd3d551cca4adc0a1caa74c53e628b5cf0a5ebe5a0d5584f899c550068eab70b483e5b796f6d&amp;scene=21#wechat_redirect">ZooKeeper需要关注的点</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491256&amp;idx=2&amp;sn=34535df6790951e7de0e08bdfceed108&amp;chksm=fd3d582dca4ad13bc76b32b252995a979cd9ae888d510e2201e6c1a2ac169c1cccbf30009ab4&amp;scene=21#wechat_redirect">MySQL中InnoDB及索引深入剖析</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491256&amp;idx=1&amp;sn=0bd327392de5e2241b550a12eda43f29&amp;chksm=fd3d582dca4ad13bf53916a5e693a93e2c526b63be165f06732f04940e1d8517803c1e81a322&amp;scene=21#wechat_redirect">Kafka面试题系列(进阶篇2)</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491276&amp;idx=1&amp;sn=133e0d6bcf897ae288a83f1ac6e7456c&amp;chksm=fd3d5859ca4ad14f7d5e9898a335e78e1a9cf163303818e9a61eeb5785b4a02a12c5b86e5f1c&amp;scene=21#wechat_redirect">MySql的Binlog日志工具分析：Canal、Maxwell、Databus、DTS</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491365&amp;idx=3&amp;sn=a1efd7804ceeeb5b5980ade4a7c75d90&amp;chksm=fd3d59b0ca4ad0a6eedfb7333b30bf66f2f3da7a3adab8242a5c7ea949803d101b4f386b7b95&amp;scene=21#wechat_redirect">Redis中的管道Pipeline操作</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491365&amp;idx=2&amp;sn=fdb72a0d6ac9b5f4723f8362e42acd9b&amp;chksm=fd3d59b0ca4ad0a6ccf7e8ebd1ce5d931962575adba97281db5d6f5becc8f98781c543a49d4d&amp;scene=21#wechat_redirect">查看YARN任务日志的几种方式</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491453&amp;idx=2&amp;sn=df9b9bf0127e3c4648eec90ef3499306&amp;chksm=fd3d59e8ca4ad0fe12fa54cf22baea1223bfc944436e98ec89b7b61b75d1a0ed05dbf99f31ac&amp;scene=21#wechat_redirect">Yarn 使用 Cgroup 实现任务资源限制</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491453&amp;idx=1&amp;sn=49e762ec986faf408c03b4bc52634872&amp;chksm=fd3d59e8ca4ad0fe38d0827899e82865b9c913524b3c71913ffc596aad0f9292239a29f704b2&amp;scene=21#wechat_redirect">分析和定位线上作业 OOM 问题利器-MAT</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487838&amp;idx=1&amp;sn=a82d191e12dc2590fc376258965e34f6&amp;chksm=fd3d57cbca4adedd518eb3944835a2629e9e9cb77ec5fdaf127d87b6a7bb847780b700115020&amp;scene=21#wechat_redirect">浅谈ZooKeeper中Kafka相关信息的存储</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488882&amp;idx=1&amp;sn=62cc37f20fdce1193f2400507b7d478a&amp;chksm=fd3d53e7ca4adaf181d221711806599b49e165d3b73b1913fb703ff24aa23e95526413549897&amp;scene=21#wechat_redirect">JVM架构体系与GC命令小总结</a></li>
</ul>
<p><strong>其他</strong></p>
<ul>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487021&amp;idx=1&amp;sn=b9c9feaceae4d6315b801c021964c9cf&amp;chksm=fd3d48b8ca4ac1aea20937d29058ab1ebabd480bf15e37a41dec52d4c7d712342be7f963f33e&amp;scene=21#wechat_redirect">腾讯如何用Elasticsearch挖掘万亿数据价值？</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487555&amp;idx=1&amp;sn=4f46c221e6830c25371ed239bb7bb12c&amp;chksm=fd3d56d6ca4adfc08dc936586a9d82d0b44e8b584ec21dd83f081d5c7a40a1ef2d4c52733384&amp;scene=21#wechat_redirect">Apache Beam 大数据处理一站式分析</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492943&amp;idx=1&amp;sn=fcd6d6e67b7ff0792976b063374306ac&amp;chksm=fd3ea3daca492acc631a0db5d99c82603d7935888e13ea086a5825651132396f3d48db20c5b5&amp;scene=21#wechat_redirect">Apache Hudi 架构设计和基本概念</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492943&amp;idx=1&amp;sn=fcd6d6e67b7ff0792976b063374306ac&amp;chksm=fd3ea3daca492acc631a0db5d99c82603d7935888e13ea086a5825651132396f3d48db20c5b5&amp;scene=21#wechat_redirect">Apache Hudi 架构设计和基本概念</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486990&amp;idx=1&amp;sn=9c8a238ca63dc52af251bbf03aafc75c&amp;chksm=fd3d489bca4ac18d5fa9130df79ae4f7ccc9ad34ab99b91cc8fb80b9a2542d1987f6447d3e39&amp;scene=21#wechat_redirect">MySQL8.0发布，你熟悉又陌生的Hash Join？</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487002&amp;idx=1&amp;sn=97bd47e0f4d3ee666c1a624872a358f0&amp;chksm=fd3d488fca4ac199fbf0352b1df513d968d000a1ce4c38b3c16b480776da2827857f4a750215&amp;scene=21#wechat_redirect">转载一个看不懂的文章：F1 Query</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487043&amp;idx=1&amp;sn=91fcb6e573404cac6a89a60603cd138d&amp;chksm=fd3d48d6ca4ac1c0d325a63bb25eba3df146e423d6ff484869cb76dff970c8dd21cc1f047a6f&amp;scene=21#wechat_redirect">Apache Hudi | 统一批和近实时分析的增量处理框架</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487056&amp;idx=1&amp;sn=27f648d927c248204f449f33c8fbc8bc&amp;chksm=fd3d48c5ca4ac1d36785402c263924006ea6c4232565dca1dce490763bae5acc455aec8d537e&amp;scene=21#wechat_redirect">寻找5亿次访问中，访问次数最多的人</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487066&amp;idx=1&amp;sn=49a9a99927bb4223bb40080106cf4a91&amp;chksm=fd3d48cfca4ac1d99976d5d7cc8ba6426b02bedb61a29657d262830cb334f02aed3834d74e49&amp;scene=21#wechat_redirect">聊聊阿里巴巴的全链路压测</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487080&amp;idx=1&amp;sn=71145f8a66f3d16d1e29526f81eeeb5f&amp;chksm=fd3d48fdca4ac1eb7e00744bac1b03ac3e0e7a342675c3dc7234f182327cd2a4904a3e33d7e4&amp;scene=21#wechat_redirect">年轻人你渴望力量吗 | 我读过的一些书推荐</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487116&amp;idx=1&amp;sn=7ea20fdf1134eaceab3e36f03cb061c8&amp;chksm=fd3d4819ca4ac10fc438c8efff61f744b2e1ebfb91c85c365d5f0b43e029ae5068d319ace90d&amp;scene=21#wechat_redirect">数据算法之反转排序 | 寻找相邻单词的数量</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487212&amp;idx=1&amp;sn=a42d9dba3c7a34df7134292a26793c3f&amp;chksm=fd3d4879ca4ac16f9777aceb3ee3d09e271dab155a7ba4d27e5a07af4278b406bd10fceefc44&amp;scene=21#wechat_redirect">MySQL Binlog同步HDFS的方案</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488638&amp;idx=2&amp;sn=8850f47e776a4bd9e6945c142dd4f74d&amp;chksm=fd3d52ebca4adbfde14a5d24300338d1db4b231203f778ed242855cbbe95d17b5ffcfea735ee&amp;scene=21#wechat_redirect">循环查询数据的性能问题及优化</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488827&amp;idx=1&amp;sn=b8186e482bdf34ce24cc161df46f290c&amp;chksm=fd3d53aeca4adab8810b5f96f2c08b996ca524ca7978ada3d529f5e617c73d89a21c7bcbc544&amp;scene=21#wechat_redirect">推荐系统 embedding 技术实践总结</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489470&amp;idx=1&amp;sn=734886246f2413f72d605cad726b59f2&amp;chksm=fd3d512bca4ad83d516e5d6f0dd4c21c83867de758238277a162fecad0ec21a9eff9a3a59c23&amp;scene=21#wechat_redirect">Prometheus+Clickhouse实现业务告警</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489519&amp;idx=2&amp;sn=5c1b1a4738e2de958920d6f6adc99e95&amp;chksm=fd3d517aca4ad86cc64260dcd41cd939cde52b6c3ebf0fa5322023ef6396ecf8cb24f0c392b4&amp;scene=21#wechat_redirect">亿级用户的分布式数据存储解决方案</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489571&amp;idx=1&amp;sn=56a634d66fb689907b4ab51ed2d3707a&amp;chksm=fd3d5eb6ca4ad7a0cc5fa4f895354e58ed7f2cb8558369ed6149560a5e7fca97b8545036fe87&amp;scene=21#wechat_redirect">基于大数据的用户画像构建小百科全书</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489915&amp;idx=1&amp;sn=4c926ceac7fe3f0fd55eafa07ce0b223&amp;chksm=fd3d5feeca4ad6f8f3583a541c306575a80d1f5e846e8b8e9561cb938d86e0c3bda460eeb7c9&amp;scene=21#wechat_redirect">魅族持续交付平台建设实践</a></li>
</ul>
<h3 id="八-2021精品文章合集">八、2021精品文章合集</h3>
<h4 id="2021精品文章合集">2021精品文章合集</h4>
<p><strong>汇总部分</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/MAwD-UJgvIa_dZjmaykqrQ">八千里路云和月|从零到大数据专家学习路径指南</a></li>
<li><a href="https://mp.weixin.qq.com/s/xh4SEX9t-fRVdoiAl0KKSQ">我们在学习Flink的时候，到底在学习什么?</a></li>
<li><a href="https://mp.weixin.qq.com/s/pN0AqNJuFnlLjNW2OonGtA">我们在学习Spark的时候，到底在学习什么？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247499539&amp;idx=1&amp;sn=26b8569ae4e3d5c6c1a1b8a98807f625&amp;scene=21#wechat_redirect">一线互联网公司面试进阶全攻略</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247499250&amp;idx=1&amp;sn=ca900c226738048c28b56ae5c7b8f723&amp;chksm=fd3ebb67ca4932712f602302ddc72aa616ff462a9c11605d6becbeaf347b5e7b1b2be2172cea&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">【大数据成神之路】第一版更新完毕</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487326&amp;idx=1&amp;sn=1ba5867700bdfb5ad7f808a245ae3b1f&amp;scene=21#wechat_redirect">关于技术面试的一点点体会</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487334&amp;idx=1&amp;sn=ce3453c1b63d6932438c8412fc5454d3&amp;scene=21#wechat_redirect">早点建立自己的知识体系</a></li>
</ul>
<p><strong>专题部分</strong></p>
<p><strong>Hadoop系列</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247501553&amp;idx=1&amp;sn=487e44e8fb362e97a0d418dff62de8bb&amp;scene=21#wechat_redirect">最新Hive/Hadoop高频面试点小集合</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247484567&amp;idx=1&amp;sn=36e47d34cbdd7b5f0bf93f3bb5338c90&amp;scene=21#wechat_redirect">Hadoop所支持的几种压缩格式</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247497849&amp;idx=1&amp;sn=a82f9787765436b5514fe77aa6aa020f&amp;scene=21#wechat_redirect">【大数据面试之对线面试官】MapReduce/HDFS/YARN面试题70连击</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487464&amp;idx=1&amp;sn=c7358495832da5e4bf4807691be6ef29&amp;scene=21#wechat_redirect">HDFS的SecondaryNameNode作用，你别答错了</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491453&amp;idx=2&amp;sn=df9b9bf0127e3c4648eec90ef3499306&amp;scene=21#wechat_redirect">Yarn 使用 Cgroup 实现任务资源限制</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491365&amp;idx=2&amp;sn=fdb72a0d6ac9b5f4723f8362e42acd9b&amp;scene=21#wechat_redirect">查看YARN任务日志的几种方式</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247498514&amp;idx=2&amp;sn=76808f8610e57360aced9c08b6e93c11&amp;chksm=fd3ebd87ca49349155ddc062a4d812980f4b0075c65d448200136acdc903d86f2fc078972d72&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">大数据哔哔集20210106 - Hadoop3.0有哪些新特性</a></li>
</ul>
<p><strong>Hive系列</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247493923&amp;idx=1&amp;sn=bdb745dc04af43e1dc9e476cd1d67a86&amp;scene=21#wechat_redirect">Hive性能调优 | 数据倾斜</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247484617&amp;idx=1&amp;sn=cd734b7b04e0278f4445a09204d6a2bf&amp;scene=21#wechat_redirect">面试必备技能-HiveSQL优化</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247494838&amp;idx=1&amp;sn=5f2aeba4509603bf50742987aff54469&amp;chksm=fd3eaa23ca492335ae6e436806fd8de3da919766c80d661bb468c17a61559d034a2a16b2ec93&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">Hive常用参数调优十二板斧</a></li>
</ul>
<p><strong>HBase</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247489094&amp;idx=1&amp;sn=76958401eb4fab0a69447b37bda2b4c9&amp;scene=21#wechat_redirect">面试必考点:HBase Compaction机制</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247497379&amp;idx=1&amp;sn=f712373bc5d4826f255f8b47c4e7ff71&amp;chksm=fd3eb036ca493920840f1c7808124b07e838c17b33b7f0188fa78fbb9877fdd8cade45563ec8&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">Hbase性能优化百科全书</a></li>
</ul>
<p><strong>ES等</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247494711&amp;idx=1&amp;sn=4846c2665cce5eb20e4a98af0b1b6ac6&amp;chksm=fd3eaaa2ca4923b4619a40d63a89b0818b22df8f98e68d4382ac77a56f921a93f14ef1aeeaf2&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">触类旁通Elasticearch之吊打同行系列：原理篇</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247494765&amp;idx=1&amp;sn=600f78c4cdf5875ed9524e737c55a8fb&amp;chksm=fd3eaaf8ca4923ee3aa3907538f3b7fe06eca67b49003a6002f5d65e80800645914497d9159b&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">触类旁通ElasticSearch之吊打同行系列：操作篇</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247494808&amp;idx=1&amp;sn=67aa00f4fff4486825bea7a5bd3956c5&amp;chksm=fd3eaa0dca49231b88c5a1bbb083bd9ea89aa20b1d1d4edb0f409ad4a192fcd6d87eaafba346&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">触类旁通Elasticearch之吊打同行系列：搜索篇</a></li>
</ul>
<p><strong>Kafka/消息队列</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492699&amp;idx=2&amp;sn=776b93fb683a004d58d432d9b6b551b4&amp;scene=21#wechat_redirect">面试知识点 | Kafka的数据存储与索引设计</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491156&amp;idx=2&amp;sn=e18e2ae54f08ee34749fdb314652c2fe&amp;scene=21#wechat_redirect">Kafka面试题系列(基础篇)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491176&amp;idx=1&amp;sn=81b44db6db3cb014dc9002ba840ad283&amp;scene=21#wechat_redirect">Kafka面试题系列(进阶篇)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491256&amp;idx=1&amp;sn=0bd327392de5e2241b550a12eda43f29&amp;scene=21#wechat_redirect">Kafka面试题系列(进阶篇2)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485312&amp;idx=2&amp;sn=97c7d499760154a98cd1bfa416697a42&amp;scene=21#wechat_redirect">关于MQ面试的几件小事 | 消息队列的用途、优缺点、技术选型</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485321&amp;idx=3&amp;sn=2e6769937df43c3555213bb17d8605fe&amp;scene=21#wechat_redirect">关于MQ面试的几件小事 | 如何保证消息不丢失</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485321&amp;idx=2&amp;sn=73e56ed1f46fd3337e13ee359631adc9&amp;scene=21#wechat_redirect">关于MQ面试的几件小事 | 如何保证消息按顺序执行</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485184&amp;idx=1&amp;sn=19680883eb2b9739f834d743e5304179&amp;scene=21#wechat_redirect">一道真实的阿里面试题 | 如何保证消息队列的高可用</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486992&amp;idx=1&amp;sn=8950101b408b0e02b7957f6d74c9cd74&amp;scene=21#wechat_redirect">你可能需要知道的Kafka面试题与部分答案整理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487314&amp;idx=1&amp;sn=f832be362c7c2ea877c48d47923434c5&amp;scene=21#wechat_redirect">消息队列面面观</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491086&amp;idx=1&amp;sn=f2f9bd1a55064ec7abf63666bf54be61&amp;scene=21#wechat_redirect">Kafka三种可视化监控管理工具Monitor/Manager/Eagle</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491138&amp;idx=1&amp;sn=f42cac6584ca4c3b74f232e897b33206&amp;scene=21#wechat_redirect">Kafka体系架构详细分解</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491138&amp;idx=2&amp;sn=a67e3044fd368e61a0290679e2765661&amp;scene=21#wechat_redirect">Kafka笔记—可靠性、幂等性和事务</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491138&amp;idx=1&amp;sn=f42cac6584ca4c3b74f232e897b33206&amp;scene=21#wechat_redirect">Kafka体系架构详细分解</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491176&amp;idx=1&amp;sn=81b44db6db3cb014dc9002ba840ad283&amp;scene=21#wechat_redirect">Kafka面试题系列(进阶篇)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491156&amp;idx=2&amp;sn=e18e2ae54f08ee34749fdb314652c2fe&amp;scene=21#wechat_redirect">Kafka面试题系列(基础篇)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492699&amp;idx=2&amp;sn=776b93fb683a004d58d432d9b6b551b4&amp;scene=21#wechat_redirect">面试知识点 | Kafka的数据存储与索引设计</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492958&amp;idx=1&amp;sn=1ef59283fddfcffa14425d8d51af6f81&amp;chksm=fd3ea3cbca492add3660dc37a37b458694cd285ae061884bb8aecbba2725fab3baee89608eba&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">斗转星移 | 三万字总结Kafka各个版本差异</a></li>
</ul>
<p><strong>Spark</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491813&amp;idx=2&amp;sn=557cc24073bef28f4f3589b63f71c967&amp;scene=21#wechat_redirect">面试必知的 Spark SQL 几种 Join 实现</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486577&amp;idx=1&amp;sn=49fd0138ad9837192b6eb78cbdc478e6&amp;scene=21#wechat_redirect">面试注意点 | Spark&amp;Flink的区别拾遗</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247501609&amp;idx=2&amp;sn=d92b8fee97a0832ae6aa8dab82a7a9c3&amp;chksm=fd3e81bcca4908aa29f2d1bf4145f3163933a74a5f70b6b13f33811488c57517cb660fb92f84&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">Spark如何协调来完成整个Job的运行详解</a></li>
<li><a href="https://blog.csdn.net/u013411339/article/details/100179471">独孤九剑-Spark面试80连击(上)</a></li>
<li><a href="https://blog.csdn.net/u013411339/article/details/100179469">独孤九剑-Spark面试80连击(下)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247501217&amp;idx=1&amp;sn=75ab0ec8b505b87aac9ee37e2328db9b&amp;chksm=fd3e8334ca490a226fbe5e779de27c43fd806f6c6d64e66d9efd8429a7f4b3acc9f4447a9157&amp;scene=21#wechat_redirect">Spark的Cache和Checkpoint区别和联系拾遗</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247501259&amp;idx=1&amp;sn=8716f0fcb9b85d36bdfe69039983c518&amp;chksm=fd3e835eca490a48cb02d75e7d5183961461546510c0c4b9f7edee01954c92f9bf2de4432a53&amp;scene=21#wechat_redirect">Spark Job 逻辑执行图和数据依赖解析</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247501309&amp;idx=1&amp;sn=2a3edaed6845031acac7cc5c377bdd53&amp;chksm=fd3e8368ca490a7e2b580983aba4aff7c6acadfba5f4863a776ed6cc3f63839353dbc935344e&amp;scene=21#wechat_redirect">Spark Job 物理执行图详解</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247501347&amp;idx=1&amp;sn=1809c8d80c4af0772b7eef999e2b84d7&amp;chksm=fd3e80b6ca4909a028b29e014fb1e7a1de10203277baa57ded90507668fd429d8ae6690c31aa&amp;scene=21#wechat_redirect">Spark Shuffle过程详解</a></li>
</ul>
<p><strong>Flink</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247497541&amp;idx=1&amp;sn=521d3f59d7c5bfe56607ccc0867c7575&amp;scene=21#wechat_redirect">【大数据面试题】Flink企业级面试题60连击</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486150&amp;idx=1&amp;sn=691f8cab1ba9d72984c8e0250ab24b79&amp;chksm=fd3d4c53ca4ac545eb01a6781c4317bc3a3f5e5c2129bd2d57e5e2ea53edcbeeae2acd2a4ed6&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">全网第一|Flink学习面试灵魂40问答案</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485260&amp;idx=1&amp;sn=7af0f27520b6fd74adf424d4d64f032d&amp;scene=21#wechat_redirect">面试别人说他熟悉Flink，我问了他Flink如何实现exactly-once语义</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487449&amp;idx=3&amp;sn=5b3d8564d1c84b14f9d941c96d8f6a27&amp;scene=21#wechat_redirect">阅读源码｜Spark与Flink的RPC实现</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247501028&amp;idx=1&amp;sn=40e36b5e0c58d909e7933622de0e53d0&amp;chksm=fd3e8271ca490b6753b9c34671c4cf07c88ca953ddbe723abf5e28324f5248044f372f48abd4&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">Flink性能调优小小总结</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247500470&amp;idx=1&amp;sn=a9ddfabd545a52e463dbc728fdaa872d&amp;chksm=fd3e8423ca490d3578b802859924a5de96038e5f114788443f10763b90cea4955ff352982e5a&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">生产上的坑才是真的坑 | 盘一盘Flink那些经典线上问题</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247499604&amp;idx=1&amp;sn=d938dfb30d221774704982d2938b30c1&amp;chksm=fd3eb9c1ca4930d76a391241333de461ca22d2aa27472eab3cffab1564872ae37f1b48fe2d3c&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">我们在学习Flink的时候，到底在学习什么？</a></li>
</ul>
<p><strong>数据仓库/数据湖</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247501955&amp;idx=2&amp;sn=0732c077a76a99b67bafa57e3dedbf3e&amp;chksm=fd3e8e16ca4907003d62f768b629f7f2a99c14f073cdd4a117559ec755d5876eec814a3fd9f7&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">数据湖存储架构选型</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247501798&amp;idx=1&amp;sn=ee75c1c067833cf0cb285e99e71a91e4&amp;chksm=fd3e8173ca4908655af05c56447dd728d14f0cdde511b4675c4ba12bbbb293e9060a7911972a&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">数据湖架构、战略和分析的8大错误认知</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247500604&amp;idx=1&amp;sn=75e2492e954fbaac868afacc9397328d&amp;chksm=fd3e85a9ca490cbfd5d10b6feb743ad172f09bc87c357bdc88b5be8b8fc39a7ee3581c3a0f81&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">数据湖在大数据典型场景下应用调研个人笔记</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247496181&amp;idx=1&amp;sn=90753808e8dd92a6d9fb95d29a9925a2&amp;chksm=fd3eb760ca493e769275c92e26812154314222849bc96dde2ed6ca2b568ceaef493f277864c5&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">数据湖VS数据仓库？湖仓一体了解一下</a></li>
</ul>
<p><strong>后端相关</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487449&amp;idx=1&amp;sn=2cc97bf6669416267c25a7a46192b706&amp;scene=21#wechat_redirect">三万六千字通关MySQL面试</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491453&amp;idx=1&amp;sn=49e762ec986faf408c03b4bc52634872&amp;scene=21#wechat_redirect">分析和定位线上作业 OOM 问题利器-MAT</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487838&amp;idx=1&amp;sn=a82d191e12dc2590fc376258965e34f6&amp;scene=21#wechat_redirect">浅谈ZooKeeper中Kafka相关信息的存储</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488882&amp;idx=1&amp;sn=62cc37f20fdce1193f2400507b7d478a&amp;scene=21#wechat_redirect">JVM架构体系与GC命令小总结</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487458&amp;idx=1&amp;sn=11e0b029998ecdeccda8e18c1e43f980&amp;scene=21#wechat_redirect">深入理解CAP理论和适用场景</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247488393&amp;idx=1&amp;sn=f820923ae3e782b509911f787a455a91&amp;scene=21#wechat_redirect">ZooKeeper需要关注的点</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491256&amp;idx=2&amp;sn=34535df6790951e7de0e08bdfceed108&amp;scene=21#wechat_redirect">MySQL中InnoDB及索引深入剖析</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247491276&amp;idx=1&amp;sn=133e0d6bcf897ae288a83f1ac6e7456c&amp;scene=21#wechat_redirect">MySql的Binlog日志工具分析：Canal、Maxwell、Databus、DTS</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247495156&amp;idx=1&amp;sn=3502f333eaaf19eccef2a721ab1fead1&amp;chksm=fd3eab61ca4922771033e47326464bda019b6d99d3d6f8a81b4cc5ca6bcddbc9307a0ca91eaa&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">一致性协议算法-2PC、3PC、Paxos、Raft、ZAB、NWR超详细解析</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247495088&amp;idx=1&amp;sn=f3e8460921135780a1e38fdfd163f909&amp;chksm=fd3eab25ca492233ea3dae78b07db1f601b70155cdfd371df51beb4cacb2191fd9d383212999&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">MySQL数据库性能优化史诗级大总结</a></li>
</ul>
<p><strong>不便分类的其他</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247495750&amp;idx=1&amp;sn=125e5a1800beeeb9faddd5c614136fec&amp;scene=21#wechat_redirect">十道海量数据处理面试题</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486586&amp;idx=1&amp;sn=e35def6429adaada0910b91eed8d7b1f&amp;scene=21#wechat_redirect">这个面试问题很难么 | 如何处理大数据中的数据倾斜</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247485151&amp;idx=1&amp;sn=665e5e284934aecd2fcf3d69e26e3b52&amp;scene=21#wechat_redirect">面试系列：十个海量数据处理方法大总</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486931&amp;idx=2&amp;sn=1c5987f3bad7a805895484ebfd683e11&amp;scene=21#wechat_redirect">我们常说的海量小文件的根源是什么？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487021&amp;idx=2&amp;sn=bbfa3fb95e4fa3d0b6ae90a8933119ed&amp;scene=21#wechat_redirect">28道关于ZooKeeper的面试题</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487177&amp;idx=2&amp;sn=dea2d55951494a5bf4438ec5a888bdd7&amp;scene=21#wechat_redirect">【数据白皮书重磅分享】推荐|埋点|用研|标签</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487309&amp;idx=2&amp;sn=a33cc56116cb7891145394f9c5353be3&amp;scene=21#wechat_redirect">1万2千字长文助力春招 | Netty面试篇</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487414&amp;idx=2&amp;sn=2afda2b854a4f875159a43903bb7b337&amp;scene=21#wechat_redirect">Filter(过滤)|Project(映射)|Pushdowns(谓词下推)</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247495807&amp;idx=1&amp;sn=d23efef601586506e00435889a8e1657&amp;chksm=fd3eb6eaca493ffcc18ccfc6c1112124be13486d8778427099e37b4ed536be1ffe1348f55131&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">代达罗斯之殇-大数据领域小文件问题解决攻略</a></li>
</ul>
<p><strong>面试综合系列</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247497893&amp;idx=1&amp;sn=50837fcfceaf6df459936c2b4af36d3d&amp;scene=21#wechat_redirect">【对线面试官】阿里面试经历，有些人走一步看一步就挂了</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487326&amp;idx=1&amp;sn=1ba5867700bdfb5ad7f808a245ae3b1f&amp;scene=21#wechat_redirect">关于技术面试的一点点体会</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486054&amp;idx=1&amp;sn=a9385d955df56d5834f6575748bd5277&amp;scene=21#wechat_redirect">助力秋招-独孤九剑破剑式 | 10家企业面试真题</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247486986&amp;idx=1&amp;sn=422d1a3c11c72ff97b32cc01142839f4&amp;scene=21#wechat_redirect">如果你在准备面试，好好看看这130道题</a></li>
</ul>
<p><strong>简历系列</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247487297&amp;idx=1&amp;sn=9b007050efaf50f17e3f46915c70f4ea&amp;scene=21#wechat_redirect">一份优秀的简历该长成什么样</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;mid=2247492974&amp;idx=1&amp;sn=2d2a3ff8e805072df331dea7a94a7541&amp;chksm=fd3ea3fbca492aed6d43990896edbe806a47a16e15c1541378528792e87f8df84c9b43e5a6d9&amp;token=1917475764&amp;lang=zh_CN&amp;scene=21#wechat_redirect">你过来，我给你看个宝贝</a></li>
</ul>
<h4 id="面试系列合集">面试系列合集</h4>
<hr>
<h4 id="一-hadoop-2">一、Hadoop</h4>
<ol>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89.md">Hadoop面试题总结（一）</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94HDFS.md">Hadoop面试题总结（二）——HDFS</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94MapReduce.md">Hadoop面试题总结（三）——MapReduce</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94YARN.md">Hadoop面试题总结（四）——YARN</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98.md">Hadoop面试题总结（五）——优化问题</a></li>
</ol>
<h4 id="二-zookeeper">二、Zookeeper</h4>
<ol>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Zookeeper%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/Zookeeper.md">Zookeeper面试题总结（一）</a></li>
</ol>
<h4 id="三-hive">三、Hive</h4>
<ol>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Hive%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/Hive%EF%BC%88%E4%B8%80%EF%BC%89.md">Hive面试题总结（一）</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Hive%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/Hive%EF%BC%88%E4%BA%8C%EF%BC%89.md">Hive面试题总结（二）</a></li>
</ol>
<h4 id="四-hbase">四、HBase</h4>
<ol>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/HBase%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/HBase.md">HBase面试题总结（一）</a></li>
</ol>
<h4 id="五-flume">五、Flume</h4>
<ol>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Flume%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Flume.md">Flume面试题总结（一）</a></li>
</ol>
<h4 id="六-kafka-2">六、Kafka</h4>
<ol>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Kafka%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Kafka%EF%BC%88%E4%B8%80%EF%BC%89.md">Kafka面试题总结（一）</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Kafka%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Kafka%EF%BC%88%E4%BA%8C%EF%BC%89.md">Kafka面试题总结（二）</a></li>
</ol>
<h4 id="七-spark">七、Spark</h4>
<ol>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Spark%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Spark%EF%BC%88%E4%B8%80%EF%BC%89.md">Spark面试题总结（一）</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Spark%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Spark%EF%BC%88%E4%BA%8C%EF%BC%89.md">Spark面试题总结（二）</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Spark%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Spark%EF%BC%88%E4%B8%89%EF%BC%89.md">Spark面试题总结（三）</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Spark%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Spark%EF%BC%88%E5%9B%9B%EF%BC%89.md">Spark面试题总结（四）</a></li>
</ol>
<p><strong>Spark性能优化：</strong></p>
<ol start="5">
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Spark%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Spark%E8%B0%83%E4%BC%98/%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C.md">Spark面试题总结（五）——几种常见的数据倾斜情况及调优方式</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Spark%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Spark%E8%B0%83%E4%BC%98/Shuffle%E9%85%8D%E7%BD%AE%E8%B0%83%E4%BC%98.md">Spark面试题总结（六）——Shuffle配置调优</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Spark%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Spark%E8%B0%83%E4%BC%98/%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E8%B0%83%E4%BC%98.md">Spark面试题总结（七）——程序开发调优</a></li>
<li><a href="%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/Spark%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/Spark%E8%B0%83%E4%BC%98/%E8%B5%84%E6%BA%90%E8%B0%83%E4%BC%98.md">Spark面试题总结（八）——运行资源调优</a></li>
</ol>
<p>本系列的大纲会根据实际情况进行调整，欢迎大家关注~</p>
<h2 id="声明">声明</h2>
<p>文档中参考引用了大量网络上的博客和文章，大部分给出了出处，有些没写，如果造成了侵权行为，请您联系我，立即删除~</p>
<h2 id="扫我关注公众号">扫我关注公众号</h2>
<p>关注公众号：每天定时推送Hadoop/Spark/Flink等最新的<strong>大数据领域最新动态和精品技术文章</strong>!</p>
<div align="center"> <img width="350px" src="qrcodes/wechat01.png"/> </div>
<p><strong>扫我加我好友,打造价值40万Offer朋友圈!</strong></p>
<div align="center"> <img width="350px" src="qrcodes/个人微信.jpg"/> </div>
<h2 id="如果对你有用欢迎请我喝杯咖啡">如果对你有用，欢迎请我喝杯咖啡</h2>
<p>备注Gitub，感谢您～</p>
<div align="center"> <img width="350px" src="qrcodes/wechat02.jpeg"/> </div>
<h2 id="扫我加群">扫我加群</h2>
<p>备注<strong>来自GitHub加群</strong>，小助手会拉你进大数据讨论组，一起学习交流，期待你的到来~</p>
<div align="center"> <img width="350px" src="qrcodes/个人微信.jpg"/> </div>
<h2 id="为什么有这个文档">为什么有这个文档</h2>
<ul>
<li>以前这里只是几个txt文档</li>
<li>是我面试腾讯阿里美团等公司大数据开发工程师的过程中总结出来的大数据开发的必知必会的知识点~</li>
<li>后续更新在微信公众号更新，欢迎关注~</li>
</ul>
<h2 id="言而总之">言而总之</h2>
<p><strong>大数据成神之路</strong> 该系列文章将为希望从事大数据开发或者由后端转型为大数据开发的工程师们指出需要学习的知识点和路径，本系列文章同时致敬我曾经在网络上看到无数个Java和大数据系列文章，深受启发同时也收货很多。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://xuetongyao.github.io/post/hello-gridea/</id>
        <link href="https://xuetongyao.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="https://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>